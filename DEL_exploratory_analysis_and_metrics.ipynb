{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exploratory_analysis_and_metrics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJU2LUKTYt5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z9ptcywXfWX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "47f59043-d786-4c85-a55f-05b8bf8e175b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Vp4oawva6bS",
        "colab_type": "text"
      },
      "source": [
        "### Importing predicted test data csv's"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5Al8Zbsa1DT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_50=pd.read_csv('/content/drive/My Drive/fnc-1/cnn_50.csv')\n",
        "cnn_100=pd.read_csv('/content/drive/My Drive/fnc-1/cnn_100.csv')\n",
        "cnn_150=pd.read_csv('/content/drive/My Drive/fnc-1/cnn_150.csv')\n",
        "\n",
        "lstm_50=pd.read_csv('/content/drive/My Drive/fnc-1/lstm_50.csv')\n",
        "lstm_100=pd.read_csv('/content/drive/My Drive/fnc-1/lstm_100.csv')\n",
        "lstm_150=pd.read_csv('/content/drive/My Drive/fnc-1/lstm_150.csv')\n",
        "\n",
        "bi_lstm_50=pd.read_csv('/content/drive/My Drive/fnc-1/bi_lstm_50.csv')\n",
        "bi_lstm_100=pd.read_csv('/content/drive/My Drive/fnc-1/bi_lstm_100.csv')\n",
        "bi_lstm_150=pd.read_csv('/content/drive/My Drive/fnc-1/bi_lstm_150.csv')\n",
        "\n",
        "# w2v embeddings\n",
        "\n",
        "w2v_cnn_50=pd.read_csv('/content/drive/My Drive/fnc-1/w2v_cnn_50.csv')\n",
        "w2v_lstm_50=pd.read_csv('/content/drive/My Drive/fnc-1/w2v_lstm_50.csv')\n",
        "w2v_bi_lstm_50=pd.read_csv('/content/drive/My Drive/fnc-1/w2v_bi_lstm_50.csv')\n",
        "\n",
        "gradient_boosting=pd.read_csv('/content/drive/My Drive/fnc-1/gradientboost.csv')\n",
        "logistic_regression=pd.read_csv('/content/drive/My Drive/fnc-1/logistic_regression.csv')\n",
        "random_forest=pd.read_csv('/content/drive/My Drive/fnc-1/Random_Forest.csv')\n",
        "xgboost=pd.read_csv('/content/drive/My Drive/fnc-1/XGBoost.csv')\n",
        "\n",
        "bert_base=pd.read_csv('/content/drive/My Drive/fnc-1/bert_base.csv')\n",
        "\n",
        "gb_undersample=pd.read_csv('/content/drive/My Drive/fnc-1/gradient_boosting_undesample.csv')"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHr1dLtebCH_",
        "colab_type": "text"
      },
      "source": [
        "### Importing Real labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tw8zKoYazUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "real_bodies=pd.read_csv('/content/drive/My Drive/fnc-1/competition_test_bodies.csv')\n",
        "real_stances=pd.read_csv('/content/drive/My Drive/fnc-1/competition_test_stances.csv')\n",
        "\n",
        "# Importing train stances\n",
        "real_train_stances=pd.read_csv('/content/drive/My Drive/fnc-1/train_stances.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19VXQtCfbWsy",
        "colab_type": "text"
      },
      "source": [
        "## Exploratory analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6j0TJ4zcdWiQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "929d090d-22b7-41ea-85ba-8eb409025896"
      },
      "source": [
        "real_stances.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Headline</th>\n",
              "      <th>Body ID</th>\n",
              "      <th>Stance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ferguson riots: Pregnant woman loses eye after...</td>\n",
              "      <td>2008</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crazy Conservatives Are Sure a Gitmo Detainee ...</td>\n",
              "      <td>1550</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A Russian Guy Says His Justin Bieber Ringtone ...</td>\n",
              "      <td>2</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Headline  Body ID     Stance\n",
              "0  Ferguson riots: Pregnant woman loses eye after...     2008  unrelated\n",
              "1  Crazy Conservatives Are Sure a Gitmo Detainee ...     1550  unrelated\n",
              "2  A Russian Guy Says His Justin Bieber Ringtone ...        2  unrelated"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGQwvS4DbcGb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "97d75c5a-263c-4d69-f70e-96ac8a921c1d"
      },
      "source": [
        "real_stances['Stance'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['unrelated', 'agree', 'discuss', 'disagree'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvLt0Qrtc2xq",
        "colab_type": "text"
      },
      "source": [
        "### Test data distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4ryGPE7b3J6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "6a68a245-7598-44b3-fd79-f672b5bb1c14"
      },
      "source": [
        "import collections\n",
        "test_data_dist=collections.Counter(real_stances['Stance'])\n",
        "print(\"Test Data Distribution: \",collections.Counter(real_stances['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Data Distribution:  Counter({'unrelated': 18349, 'discuss': 4464, 'agree': 1903, 'disagree': 697})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waMTw75Qc5Zb",
        "colab_type": "text"
      },
      "source": [
        "## Train Data distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkK54cVMdeYh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "7bed1cc3-5f95-4c8b-eb94-44d6ae4fe0fd"
      },
      "source": [
        "real_train_stances.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Headline</th>\n",
              "      <th>Body ID</th>\n",
              "      <th>Stance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Police find mass graves with at least '15 bodi...</td>\n",
              "      <td>712</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
              "      <td>158</td>\n",
              "      <td>agree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Christian Bale passes on role of Steve Jobs, a...</td>\n",
              "      <td>137</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Headline  Body ID     Stance\n",
              "0  Police find mass graves with at least '15 bodi...      712  unrelated\n",
              "1  Hundreds of Palestinians flee floods in Gaza a...      158      agree\n",
              "2  Christian Bale passes on role of Steve Jobs, a...      137  unrelated"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNOow1WhklaH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "8759a2e1-b148-4c27-ae8a-7b9e743bb62a"
      },
      "source": [
        "real_train_stances.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49972, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0o9_7UQ0c2Lg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "6952ac69-56aa-48a5-d65a-4e2a6d4e8256"
      },
      "source": [
        "train_data_dist=collections.Counter(real_train_stances['Stance'])\n",
        "print(\"Train Data Distribution: \",collections.Counter(real_train_stances['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Data Distribution:  Counter({'unrelated': 36545, 'discuss': 8909, 'agree': 3678, 'disagree': 840})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADy2y9SIdsgV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "4b23b1a3-df3c-4bcd-8461-2e4c941e7e35"
      },
      "source": [
        "plt.bar(train_data_dist.keys(),train_data_dist.values(),color=[\n",
        "                     'seagreen', 'skyblue','pink','gray'])\n",
        "plt.xlabel(\"Stance\")\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Stance Distribution at Train set')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEWCAYAAACnlKo3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de7wWZb338c9XDoqigkqEgGJKGlqiIlBamhWC1Vaf1LSD6DaprVY+O3s81N7gqbRX6Y48lCWBnfCUSoQhGmpayEERRHS78pDgaSnIwQMK/p4/5lo6LO61uNes+143i/V9v17zWjO/ueaaa4ab+a2ZudZ1KyIwMzMrYotaN8DMzNovJxEzMyvMScTMzApzEjEzs8KcRMzMrDAnETMzK8xJxDocSedJ+lUF61st6QNpfqKkiypY988l/Vel6tvUSPq4pMdr3Q4rzknEmiTpYEl/l7RC0jJJ90s6MK07SdJ9tW5jY5LulvSmpFWSVkqaJ+kcSVs2lImIH0TE18qsa6PlIqJ7RDxZgbZvcE4j4hsRcWFr6y7QlpC0RxPrzkuJc3U61+tyy4tasp+I+FtE7FmZVpen0om+o3MSsZIkbQdMBX4G7AD0Bc4H1tSyXWU6IyK2BfoA3wGOB6ZJUiV3IqlzJetrL1IS7h4R3YFvAP9oWI6IvRvKKeNrzOYuIjx52mAChgCvNrHuQ8CbwDpgdUM54LPAQ8BK4FlgXG6bAUAAo4F/AS8D38ut7wScB/wTWAXMA/qndXsBM4BlwOPAcc20+27ga41iuwCvA59Ly+OA36b5rYDfAq8ArwJzgN7Axen43kzHeEUqH8DpwBPAU7nYHml+IvDz1N5VwD3Aro3OQefG7W3mnE4ELsqVPxWoS+diCrBzbl2QXdSfSMdyJaAmztNQ4B+p3PPAFUDXtO7eVNdrqS1fbOZ8nwTc1+h4LgbuB94A9gBOBhan8/Ek8PVc+UOBJbnlp4GzgAXACuB6YKsm9r1HOr8ryD5P1+fWlfzMAGOAt4G30rH9qdb/19r7VPMGeNo0J2C7dGGdBIwCejZav97FI8UOBT5Mdof7EeBF4Ki0ruEC+kugG7Av2V3Nh9L67wILgT0BpfU7AtuQJaSTgc7AfumCMaiJdt9NoySS4vcCl6b5cbyXRL4O/AnYmiyRHQBs11Rd6RhmkN2ddcvF8klkFfAJYEvgpw3niWaSSDPndCIpiQCHpWPfP9X9M+DeRm2bCvQgS5z1wMgmztMBwPB0TgeQXeTPbFTXHmV8TtZrczqefwF7p7q7kP1ysXv6dz2ELKHvn/vMNE4is4Gd0zleDHyjiX3/Afge2edtK+DgFG/2M0OjxOypdZNvNa2kiFgJHMx7F/56SVMk9W5mm7sjYmFEvBMRC8j+kx/SqNj5EfFGRDwMPEyWLCD7bfz7EfF4ZB6OiFeAzwFPR8SvI2JtRDwE3Awc28JDeo7sotTY22TJao+IWBcR89KxN+eHEbEsIt5oYv2fI+LeiFhDdpH7qKT+LWxvKV8GJkTEg6nuc1PdA3JlLomIVyPiX8BMYHCpitJxzkrn9GngF2z4b1XUxIhYlOp+OyL+HBH/TP+u9wB3AB9vZvvxEfFcRCwjS/Alj4Hs325XsruxNyOi4X1SpT4zVgYnEWtSRCyOiJMioh+wD9lvh//TVHlJwyTNlFQvaQXZo5WdGhV7ITf/OtA9zfcne5TV2K7AMEmvNkxkF9P3t/Bw+pI92mjsN8B0YLKk5yT9SFKXjdT1bLnrI2J12u/OLWlsE3YGnmlU9ytkx9agqfO7HkkflDRV0guSVgI/YMN/q6LWOz+SRkmalTpnvAocsZF9lXUMwP8ju7uZLWmRpH9P8Up9ZqwMTiJWloh4jOwxwD4NoRLFfk/2nL5/RGxP9m6g3JfZz5I98igVvycieuSm7hHxH+W2Pd0FHAD8rfG69Jvy+RExCPgY2W+xJzasbqLKjQ19/e5dh6TuZHdAz5G9Y4Ds0VmD/IVtY/U+R3aBbKh7G7K7qKUb2a6Uq4HHgIERsR3Z+6hKdTx49zhSr7ibgR8DvSOiBzCtEvuKiBci4tSI2JnsseRVqUfZxj4zHrq8gpxErCRJe0n6jqR+abk/cAIwKxV5EegnqWtus22BZRHxpqShwJdasMtfARdKGph69XxE0o5kz/g/KOmrkrqk6UBJHyrjGLaWdAhwG9lz9mklynxS0ocldSLrEPA28E7uGD/QgmNocETqHt0VuBCYFRHPRkQ92QX/K5I6pd+c84mz1DnN+wNwsqTB6eL8A+CB9DiqpbYlO97VkvYCGiflosfeWFey9zf1wFpJo4ARFagXScc2fD6B5WTJ4R02/pmp1LEZTiLWtFXAMOABSa+RJY9HyLrMAvwVWAS8IOnlFDsNuEDSKuC/gRtasL/LUvk7yC5u15K9uF5FdtE5nuw38ReAS8kuTE25IrXhRbLHbzeTvWB+p0TZ9wM3pX0uJuvt85u07qfAMZKWSxrfgmP5PTCW7DHWAcBXcutOJetE8ArZy+e/59aVOqfviog7gf9Kx/M8WQI6vgXtyjuLLMmvInvndX2j9eOASelx0HEF90H69/sW2b/t8rTPKUXra+RAss/n6lTntyPiyTI+M9cCg9Kx3VqhtnRYivCdnZmZFeM7ETMzK8xJxMzMCnMSMTOzwpxEzMyssA43gNxOO+0UAwYMqHUzzMzalXnz5r0cEb0axztcEhkwYABz586tdTPMzNoVSc+UivtxlpmZFeYkYmZmhTmJmJlZYU4iZmZWmJOImZkV5iRiZmaFOYmYmVlhTiJmZlaYk4iZmRXW4f5ivTX2/XHR7//ZPDx81uRaN8HMNjG+EzEzs8KcRMzMrDAnETMzK8xJxMzMCqtaEpG0laTZkh6WtEjS+Sk+UdJTkuanaXCKS9J4SXWSFkjaP1fXaElPpGl0Ln6ApIVpm/GSVK3jMTOzDVWzd9Ya4LCIWC2pC3CfpNvTuu9GxE2Nyo8CBqZpGHA1MEzSDsBYYAgQwDxJUyJieSpzKvAAMA0YCdyOmZm1iardiURmdVrskqZoZpMjgevSdrOAHpL6AIcDMyJiWUocM4CRad12ETErIgK4DjiqWsdjZmYbquo7EUmdJM0HXiJLBA+kVRenR1aXS9oyxfoCz+Y2X5JizcWXlIiXascYSXMlza2vr2/1cZmZWaaqSSQi1kXEYKAfMFTSPsC5wF7AgcAOwNnVbENqxzURMSQihvTqtcFXBJuZWUFt0jsrIl4FZgIjI+L59MhqDfBrYGgqthTon9usX4o1F+9XIm5mZm2kmr2zeknqkea7AZ8BHkvvMkg9qY4CHkmbTAFOTL20hgMrIuJ5YDowQlJPST2BEcD0tG6lpOGprhOB26p1PGZmtqFq9s7qA0yS1IksWd0QEVMl/VVSL0DAfOAbqfw04AigDngdOBkgIpZJuhCYk8pdEBHL0vxpwESgG1mvLPfMMjNrQ1VLIhGxANivRPywJsoHcHoT6yYAE0rE5wL7tK6lZmZWlP9i3czMCnMSMTOzwpxEzMysMCcRMzMrzEnEzMwKcxIxM7PCnETMzKwwJxEzMyvMScTMzApzEjEzs8KcRMzMrDAnETMzK8xJxMzMCnMSMTOzwpxEzMysMCcRMzMrzEnEzMwKcxIxM7PCnETMzKwwJxEzMyusaklE0laSZkt6WNIiSeen+G6SHpBUJ+l6SV1TfMu0XJfWD8jVdW6KPy7p8Fx8ZIrVSTqnWsdiZmalVfNOZA1wWETsCwwGRkoaDlwKXB4RewDLgVNS+VOA5Sl+eSqHpEHA8cDewEjgKkmdJHUCrgRGAYOAE1JZMzNrI1VLIpFZnRa7pCmAw4CbUnwScFSaPzItk9Z/SpJSfHJErImIp4A6YGia6iLiyYh4C5icypqZWRup6juRdMcwH3gJmAH8E3g1ItamIkuAvmm+L/AsQFq/AtgxH2+0TVPxUu0YI2mupLn19fWVODQzM6PKSSQi1kXEYKAf2Z3DXtXcXzPtuCYihkTEkF69etWiCWZmm6U26Z0VEa8CM4GPAj0kdU6r+gFL0/xSoD9AWr898Eo+3mibpuJmZtZGqtk7q5ekHmm+G/AZYDFZMjkmFRsN3Jbmp6Rl0vq/RkSk+PGp99ZuwEBgNjAHGJh6e3Ule/k+pVrHY2ZmG+q88SKF9QEmpV5UWwA3RMRUSY8CkyVdBDwEXJvKXwv8RlIdsIwsKRARiyTdADwKrAVOj4h1AJLOAKYDnYAJEbGoisdjZmaNVC2JRMQCYL8S8SfJ3o80jr8JHNtEXRcDF5eITwOmtbqxZmZWiP9i3czMCnMSMTOzwpxEzMysMCcRMzMrzEnEzMwKcxIxM7PCnETMzKwwJxEzMyvMScTMzApzEjEzs8KcRMzMrDAnETMzK8xJxMzMCnMSMTOzwpxEzMysMCcRMzMrzEnEzMwKcxIxM7PCnETMzKywqiURSf0lzZT0qKRFkr6d4uMkLZU0P01H5LY5V1KdpMclHZ6Lj0yxOknn5OK7SXogxa+X1LVax2NmZhuq5p3IWuA7ETEIGA6cLmlQWnd5RAxO0zSAtO54YG9gJHCVpE6SOgFXAqOAQcAJuXouTXXtASwHTqni8ZiZWSNVSyIR8XxEPJjmVwGLgb7NbHIkMDki1kTEU0AdMDRNdRHxZES8BUwGjpQk4DDgprT9JOCo6hyNmZmV0ibvRCQNAPYDHkihMyQtkDRBUs8U6ws8m9tsSYo1Fd8ReDUi1jaKl9r/GElzJc2tr6+vwBGZmRm0QRKR1B24GTgzIlYCVwO7A4OB54GfVLsNEXFNRAyJiCG9evWq9u7MzDqMztWsXFIXsgTyu4j4I0BEvJhb/0tgalpcCvTPbd4vxWgi/grQQ1LndDeSL29mZm2gmr2zBFwLLI6Iy3LxPrliRwOPpPkpwPGStpS0GzAQmA3MAQamnlhdyV6+T4mIAGYCx6TtRwO3Vet4zMxsQ9W8EzkI+CqwUNL8FDuPrHfVYCCAp4GvA0TEIkk3AI+S9ew6PSLWAUg6A5gOdAImRMSiVN/ZwGRJFwEPkSUtMzNrI1VLIhFxH6ASq6Y1s83FwMUl4tNKbRcRT5L13jIzsxrwX6ybmVlhTiJmZlaYk4iZmRXmJGJmZoWVlUQkfbjaDTEzs/an3DuRqyTNlnSapO2r2iIzM2s3ykoiEfFx4Mtkfzk+T9LvJX2mqi0zM7NNXtnvRCLiCeD7ZH/gdwgwXtJjkv5PtRpnZmabtnLfiXxE0uVkw7kfBnw+Ij6U5i+vYvvMzGwTVu5frP8M+BVwXkS80RCMiOckfb8qLTMzs01euUnks8AbubGstgC2iojXI+I3VWudmZlt0sp9J3In0C23vHWKmZlZB1ZuEtkqIlY3LKT5ravTJDMzay/KTSKvSdq/YUHSAcAbzZQ3M7MOoNx3ImcCN0p6jmx49/cDX6xaq8zMrF0oK4lExBxJewF7ptDjEfF29ZplZmbtQUu+lOpAYEDaZn9JRMR1VWmVmZm1C2UlEUm/AXYH5gPrUjgAJxEzsw6s3DuRIcCgiIhqNsbMzNqXcntnPUL2Mr1skvpLminpUUmLJH07xXeQNEPSE+lnzxSXpPGS6iQtaNQbbHQq/4Sk0bn4AZIWpm3GSyr1ne5mZlYl5SaRnYBHJU2XNKVh2sg2a4HvRMQgYDhwuqRBwDnAXRExELgrLQOMAgamaQxwNWRJBxgLDAOGAmMbEk8qc2puu5FlHo+ZmVVAuY+zxrW04oh4Hng+za+StBjoCxwJHJqKTQLuJhsZ+EjguvTIbJakHpL6pLIzImIZgKQZwEhJdwPbRcSsFL8OOAq4vaVtNTOzYsrt4nuPpF2BgRFxp6StgU7l7kTSAGA/4AGgd0owAC8AvdN8X+DZ3GZLUqy5+JIS8VL7H0N2d8Muu+xSbrPNzGwjyh0K/lTgJuAXKdQXuLXMbbsDNwNnRsTK/Lp011H1l/URcU1EDImIIb169ar27szMOoxy34mcDhwErIR3v6DqfRvbSFIXsgTyu4j4Ywq/mB5TkX6+lOJLyb45sUG/FGsu3q9E3MzM2ki5SWRNRLzVsCCpMxu5g0g9pa4FFkfEZblVU4CGHlajgdty8RNTL63hwIr02Gs6MEJSz/RCfQQwPa1bKWl42teJubrMzKwNlPti/R5J5wHd0nernwb8aSPbHAR8FVgoaX6KnQdcAtwg6RTgGeC4tG4acARQB7wOnAwQEcskXQjMSeUuaHjJntoxkWyY+tvxS3UzszZVbhI5BzgFWAh8neyC/6vmNoiI+8gGayzlUyXKB9ljs1J1TQAmlIjPBfZprh1mZlY95fbOegf4ZZrMzMyA8sfOeooS70Ai4gMVb5GZmbUbLRk7q8FWwLHADpVvjpmZtSdl9c6KiFdy09KI+B/gs1Vum5mZbeLKfZy1f25xC7I7k5Z8F4mZmW2Gyk0EP8nNrwWe5r2uuWZm1kGV2zvrk9VuiJmZtT/lPs76z+bWN/qLdDMz6yBa0jvrQLKhSQA+D8wGnqhGo8zMrH0oN4n0A/aPiFUAksYBf46Ir1SrYWZmtukrdwDG3sBbueW3eO97QMzMrIMq907kOmC2pFvS8lFk30poZmYdWLm9sy6WdDvw8RQ6OSIeql6zzMysPSj3cRbA1sDKiPgpsETSblVqk5mZtRPlfj3uWOBs4NwU6gL8tlqNMjOz9qHcO5GjgX8DXgOIiOeAbavVKDMzax/KTSJvpS+NCgBJ21SvSWZm1l6Um0RukPQLoIekU4E78RdUmZl1eBvtnSVJwPXAXsBKYE/gvyNiRpXbZmZmm7iNJpGICEnTIuLDgBOHmZm9q9zHWQ9KOrAlFUuaIOklSY/kYuMkLZU0P01H5NadK6lO0uOSDs/FR6ZYnaRzcvHdJD2Q4tdL6tqS9pmZWeuVm0SGAbMk/VPSAkkLJS3YyDYTgZEl4pdHxOA0TQOQNAg4Htg7bXOVpE6SOgFXAqOAQcAJqSzApamuPYDlwCllHouZmVVIs4+zJO0SEf8CDm+uXCkRca+kAWUWPxKYHBFrgKck1QFD07q6iHgytWcycKSkxcBhwJdSmUnAOODqlrbTzMyK29idyK0AEfEMcFlEPJOfCu7zjHQ3M0FSzxTrCzybK7MkxZqK7wi8GhFrG8VLkjRG0lxJc+vr6ws228zMGttYElFu/gMV2N/VwO7AYOB51v/a3aqJiGsiYkhEDOnVq1db7NLMrEPYWO+saGK+kIh4sWFe0i+BqWlxKdA/V7RfitFE/BWyv1npnO5G8uXNzKyNbOxOZF9JKyWtAj6S5ldKWiVpZUt3JqlPbvFooKHn1hTgeElbpoEdB5J9c+IcYGDqidWV7OX7lPTX8zOBY9L2o4HbWtoeMzNrnWbvRCKiU9GKJf0BOBTYSdISYCxwqKTBZHc1TwNfT/tZJOkG4FFgLXB6RKxL9ZwBTAc6ARMiYlHaxdnAZEkXAQ8B1xZtq5mZFVPul1K1WEScUCLc5IU+Ii4GLi4RnwZMKxF/kvd6cJmZWQ205PtEzMzM1uMkYmZmhTmJmJlZYU4iZmZWmJOImZkV5iRiZmaFOYmYmVlhTiJmZlaYk4iZmRXmJGJmZoU5iZiZWWFOImZmVpiTiJmZFeYkYmZmhTmJmJlZYU4iZmZWmJOImZkV5iRiZmaFOYmYmVlhVUsikiZIeknSI7nYDpJmSHoi/eyZ4pI0XlKdpAWS9s9tMzqVf0LS6Fz8AEkL0zbjJalax2JmZqVV805kIjCyUewc4K6IGAjclZYBRgED0zQGuBqypAOMBYYBQ4GxDYknlTk1t13jfZmZWZVVLYlExL3AskbhI4FJaX4ScFQufl1kZgE9JPUBDgdmRMSyiFgOzABGpnXbRcSsiAjgulxdZmbWRtr6nUjviHg+zb8A9E7zfYFnc+WWpFhz8SUl4iVJGiNprqS59fX1rTsCMzN7V81erKc7iGijfV0TEUMiYkivXr3aYpdmZh1CWyeRF9OjKNLPl1J8KdA/V65fijUX71cibmZmbaitk8gUoKGH1Wjgtlz8xNRLaziwIj32mg6MkNQzvVAfAUxP61ZKGp56ZZ2Yq8vMzNpI52pVLOkPwKHATpKWkPWyugS4QdIpwDPAcan4NOAIoA54HTgZICKWSboQmJPKXRARDS/rTyPrAdYNuD1NZmbWhqqWRCLihCZWfapE2QBOb6KeCcCEEvG5wD6taaOZmbVO1ZKImdmm5Pzzz691E2pq7NixVanXw56YmVlhTiJmZlaYk4iZmRXmJGJmZoU5iZiZWWFOImZmVpiTiJmZFeYkYmZmhTmJmJlZYU4iZmZWmJOImZkV5iRiZmaFOYmYmVlhTiJmZlaYk4iZmRXmJGJmZoU5iZiZWWFOImZmVlhNkoikpyUtlDRf0twU20HSDElPpJ89U1ySxkuqk7RA0v65ekan8k9IGl2LYzEz68hqeSfyyYgYHBFD0vI5wF0RMRC4Ky0DjAIGpmkMcDVkSQcYCwwDhgJjGxKPmZm1jU3pcdaRwKQ0Pwk4Khe/LjKzgB6S+gCHAzMiYllELAdmACPbutFmZh1ZrZJIAHdImidpTIr1jojn0/wLQO803xd4NrftkhRrKr4BSWMkzZU0t76+vlLHYGbW4XWu0X4Pjoilkt4HzJD0WH5lRISkqNTOIuIa4BqAIUOGVKxeM7OOriZ3IhGxNP18CbiF7J3Gi+kxFennS6n4UqB/bvN+KdZU3MzM2kibJxFJ20jatmEeGAE8AkwBGnpYjQZuS/NTgBNTL63hwIr02Gs6MEJSz/RCfUSKmZlZG6nF46zewC2SGvb/+4j4i6Q5wA2STgGeAY5L5acBRwB1wOvAyQARsUzShcCcVO6CiFjWdodhZmZtnkQi4klg3xLxV4BPlYgHcHoTdU0AJlS6jWZmVp5NqYuvmZm1M04iZmZWWK26+FoHdMlDL9e6CTV1zn471boJZhXnOxEzMyvMScTMzApzEjEzs8KcRMzMrDAnETMzK8xJxMzMCnMSMTOzwpxEzMysMCcRMzMrzEnEzMwKcxIxM7PCnETMzKwwJxEzMyvMScTMzApzEjEzs8L8fSJm7cU9c2vdgto6ZEitW2Al+E7EzMwKa/dJRNJISY9LqpN0Tq3bY2bWkbTrJCKpE3AlMAoYBJwgaVBtW2Vm1nG06yQCDAXqIuLJiHgLmAwcWeM2mZl1GIqIWrehMEnHACMj4mtp+avAsIg4o1G5McCYtLgn8HibNrRydgJernUj2jGfv9bx+Wud9n7+do2IXo2DHaJ3VkRcA1xT63a0lqS5EeEuKgX5/LWOz1/rbK7nr70/zloK9M8t90sxMzNrA+09icwBBkraTVJX4HhgSo3bZGbWYbTrx1kRsVbSGcB0oBMwISIW1bhZ1dTuH8nVmM9f6/j8tc5mef7a9Yt1MzOrrfb+OMvMzGrIScTMzApr1+9EOhJJhwJnRcTnmikzGNg5Iqa1sO67U90dfIS/zZekccBqYDvg3oi4s7Ytar98LtfnJLIJkdQ5Ita2oorBwBCgRUmkI6nAOW7XIuK/q1W3JJG9Z32nWvvYlFTzXLYnfpxVYZIGSHokt3yWpHGS7pZ0qaTZkv5X0sfT+pMkTZH0V+AuSdtImpDKPSRpg2FcJA2V9I+0/u+S9kxdnC8AvihpvqQvNlWXpG6SJktaLOkWoFvbnJ3KkXSrpHmSFqURCZB0Sjq3syX9UtIVKT5R0s8lPQD8SNLukv6Stv+bpL1SuV6SbpY0J00H1fAQW03S99L5uI9spIaGc3FMmr9E0qOSFkj6cYp9XtID6fNyp6TeKd5L0ox0vn8l6RlJO6XP++OSrgMeAfpL+m46fwsknZ9rz1fSv818Sb9IY9+1CwXPZW9Jt0h6OE0fa+r6kOa/latjcoodks7X/PRvsm1bH/tGRYSnCk7AAOCR3PJZwDjgbuAnKXYEcGeaPwlYAuyQln8AfCXN9wD+F9gGOBSYmuLbAZ3T/KeBm3N1XZHbd1N1/SdZd2iAjwBrgSG1PnctPM8N56sb2cWrL/A0sAPQBfhbw7kAJgJTgU5p+S5gYJofBvw1zf8eODjN7wIsrvVxtuL8HAAsBLZOn5e69FmcCBwD7Eg2/E9DD80e6WfPXOxruc/sFcC5aX4kEGTDeAwA3gGGp3UjyLqyiuyX1KnAJ4APAX8CuqRyVwEn1vo8VflcXg+cmeY7AdvTxPUhzT8HbNmojj8BB6X57qT/95vS5MdZbeuP6ec8sg9TgxkRsSzNjwD+TdJZaXkrsgta3vbAJEkDyf4zd2lif03V9QlgPEBELJC0oNjh1NS3JB2d5vsDXwXuaTiPkm4EPpgrf2NErJPUHfgYcGP29AWALdPPTwODcvHtJHWPiNVVPI5q+ThwS0S8DiCp8R/hrgDeBK6VNJXsYg/ZqA/XS+oDdAWeSvGDgaMBIuIvkpbn6nomImal+RFpeigtdwcGkv2ycgAwJ53fbsBLFTjOtlD0XB4GnAgQEeuAFZJ6NrOfBcDvJN0K3Jpi9wOXSfod8MeIWFKJA6okJ5HKW8v6jwm3ys2vST/Xsf65fy03L+ALEbHeIJENjxWSC4GZEXG0pAFkdzmlNFVX80ewiVPWyeDTwEcj4nVlHQMeI/tttykN53gL4NWIGFyizBZkv1G/WcHmbpIi+0PdocCnyH6bPoPsovcz4LKImJLO87gyqmv8+f1hRPwiX0DSN4FJEXFuBZq/SWnmXJbS3PXhs2S/4H0e+J6kD0fEJZL+TPb04n5Jh0fEYxU/iFbwO5HKexF4n6QdJW0JNNmbqgnTgW8qXekl7VeizPa8N0bYSbn4KiD/zLSpuu4FvpRi+5D9ltiebA8sTwlkL2A42WO6QyT1lNQZ+EKpDSNiJfCUpGMhexksad+0+g7gmw1llfV2a6/uBY5S9v5rW7IL07vSHdn2kfXk+79AwznIf7ZG5za5HzgubTuC7LFXKdOBf0/1I6mvpPeRPUI8Js0jaQdJu7byGNtK0XN5F/AfqUwnSdvTxPVB0hZA/4iYCZxN9u/QXdLuEbEwIi4lG+Zpr2ofbEs5iVRYRLxN9oJ7NjCD7DfklriQ7PHUAkmL0nJjPwJ+KOkh1r+jmUn2OI8b7gsAAAL1SURBVGa+pC82U9fVZB/Qxamt81rYxlr7C9A5tf8SYBbZhe8HZOf9frL3Iyua2P7LwCmSHgYW8d530HwLGJJebD4KfKNqR1BlEfEg2TP5h4HbyS5AedsCU9OjzPvI3pNBdudxo6R5rD9s+fnAiPRS+FjgBbJfWhrv9w6yd0v/kLQQuAnYNiIeBb4P3JH2OQPoU4FDrbpWnMtvA59M52EeMKiZ60Mn4Lep7EPA+Ih4FThT0iOp7rfT/jcpHvbENhsN7y/SncgtZJ0Hbql1uzYH6bfmdenRzUeBq5t4JGgdjN+J2OZknKRPkz1nvoP3Xk5a6+0C3JAeu7wFnFrj9tgmwnciZmZWmN+JmJlZYU4iZmZWmJOImZkV5iRiVkFpjKVFqZvwfEnDJJ0paetat82sGvxi3axCUtfXy4BDI2KNpJ3Ihg75O9nYZC83W4FZO+Q7EbPK6QO8HBFrAFLSOAbYGZgpaSaApKslzU13LPlRbp+WdL6kByUt1HujC3eX9OsUWyDpCyk+Qtlozg9KurHhr8TN2pLvRMwqJF3E7yMb7fVO4PqIuEfS0+TuRCTtEBHLlA2FfhfwrTQQ5tNko+b+TNJpwP4R8TVJl5KN7npm2r4n2V84/xEYFRGvSTo7lbmgbY/aOjrfiZhVSBrt9wBgDFBPNhruSSWKHifpQbLhLfYGBuXWlRrp+dPAlbn9LCcbL2wQ2aB888nGuWovY1HZZsR/sW5WQWnI77uBu9M4SPlBDJG0G9l3SBwYEcslTaS8kZ4bE9lXCJxQoaabFeI7EbMKUfYNkwNzocHAM6w/uvJ2ZEOnr0jD+48qo+oZwOm5/fQkG3TyIEl7pNg2kj7YxPZmVeMkYlY53cm+LOzRNOrqILJRca8B/iJpZkQ8TPYY6zGy0W7vL6Pei4CeaTTXh4FPRkQ92dcA/CHt6x9sgsOE2+bPL9bNzKww34mYmVlhTiJmZlaYk4iZmRXmJGJmZoU5iZiZWWFOImZmVpiTiJmZFfb/ATiW6d1LK9y3AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TumXMOrcq-on",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7a9Y1wqkeuk",
        "colab_type": "text"
      },
      "source": [
        "- Total stances: 49972\n",
        "  - unrelated: 73.1%\n",
        "  - agree: 7.3%\n",
        "  - disagree:1.6%\n",
        "  - discuss:17.8%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOCzZbzLe8TN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "dd182712-dfd5-48e1-ebf7-702fae209616"
      },
      "source": [
        "plt.bar(test_data_dist.keys(),test_data_dist.values(),color=[\n",
        "                     'seagreen', 'skyblue','pink','gray'])\n",
        "plt.xlabel(\"Stance\")\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Stance Distribution at Test set')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrkAeoJRdcD5",
        "colab_type": "text"
      },
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDzOSIJ8cUsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Adapted from https://github.com/FakeNewsChallenge/fnc-1/blob/master/scorer.py\n",
        "#Original credit - @bgalbraith\n",
        "\n",
        "LABELS = ['agree', 'disagree', 'discuss', 'unrelated']\n",
        "LABELS_RELATED = ['unrelated','related']\n",
        "RELATED = LABELS[0:3]\n",
        "\n",
        "def score_submission(gold_labels, test_labels):\n",
        "    score = 0.0\n",
        "    cm = [[0, 0, 0, 0],\n",
        "          [0, 0, 0, 0],\n",
        "          [0, 0, 0, 0],\n",
        "          [0, 0, 0, 0]]\n",
        "\n",
        "    for i, (g, t) in enumerate(zip(gold_labels, test_labels)):\n",
        "        g_stance, t_stance = g, t\n",
        "        if g_stance == t_stance:\n",
        "            score += 0.25\n",
        "            if g_stance != 'unrelated':\n",
        "                score += 0.50\n",
        "        if g_stance in RELATED and t_stance in RELATED:\n",
        "            score += 0.25\n",
        "\n",
        "        cm[LABELS.index(g_stance)][LABELS.index(t_stance)] += 1\n",
        "\n",
        "    return score, cm\n",
        "\n",
        "\n",
        "def print_confusion_matrix(cm):\n",
        "    lines = []\n",
        "    header = \"|{:^11}|{:^11}|{:^11}|{:^11}|{:^11}|\".format('', *LABELS)\n",
        "    line_len = len(header)\n",
        "    lines.append(\"-\"*line_len)\n",
        "    lines.append(header)\n",
        "    lines.append(\"-\"*line_len)\n",
        "\n",
        "    hit = 0\n",
        "    total = 0\n",
        "    for i, row in enumerate(cm):\n",
        "        hit += row[i]\n",
        "        total += sum(row)\n",
        "        lines.append(\"|{:^11}|{:^11}|{:^11}|{:^11}|{:^11}|\".format(LABELS[i],\n",
        "                                                                   *row))\n",
        "        lines.append(\"-\"*line_len)\n",
        "    print('\\n'.join(lines))\n",
        "\n",
        "\n",
        "def report_score(actual,predicted):\n",
        "    score,cm = score_submission(actual,predicted)\n",
        "    best_score, _ = score_submission(actual,actual)\n",
        "\n",
        "    print_confusion_matrix(cm)\n",
        "    print(\"Score: \" +str(score) + \" out of \" + str(best_score) + \"\\t(\"+str(score*100/best_score) + \"%)\")\n",
        "    return score*100/best_score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBjyXyc6jLzq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def calculate_f1_scores(y_true, y_predicted):\n",
        "    \n",
        "    f1_macro = f1_score(y_true, y_predicted, average='macro')\n",
        "    f1_classwise = f1_score(y_true, y_predicted, average=None, labels=[\"agree\", \"disagree\", \"discuss\", \"unrelated\"])\n",
        "\n",
        "    resultstring = \"F1 macro: {:.3f}\".format(f1_macro * 100) + \"% \\n\"\n",
        "    resultstring += \"F1 agree: {:.3f}\".format(f1_classwise[0] * 100) + \"% \\n\"\n",
        "    resultstring += \"F1 disagree: {:.3f}\".format(f1_classwise[1] * 100) + \"% \\n\"\n",
        "    resultstring += \"F1 discuss: {:.3f}\".format(f1_classwise[2] * 100) + \"% \\n\"\n",
        "    resultstring += \"F1 unrelated: {:.3f}\".format(f1_classwise[3] * 100) + \"% \\n\"\n",
        "    return resultstring"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_E5yRDYjQB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def class_repo(labels_test,preds_test):\n",
        "    eval_report = classification_report(labels_test, preds_test)\n",
        "    print('Test report', eval_report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bC_WE3uYdG5a",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating CNN 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muWIkwvScn2j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "c04a605e-d967-4979-fbcb-c5d30ffc2aba"
      },
      "source": [
        "report_score(real_stances['Stance'],cnn_50['Stance'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    65     |    449    |    397    |    992    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    30     |    132    |    101    |    434    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    153    |    551    |   1505    |   2255    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |    310    |   1323    |   1751    |   14965   |\n",
            "-------------------------------------------------------------\n",
            "Score: 5863.5 out of 11651.25\t(50.32507241712263%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50.32507241712263"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5q0AChljifv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "2b068d8b-08be-4f1a-b48a-46118ae10a01"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],cnn_50['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 32.797% \n",
            "F1 agree: 5.282% \n",
            "F1 disagree: 8.376% \n",
            "F1 discuss: 36.627% \n",
            "F1 unrelated: 80.903% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-ly-CjakUUB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "e9efcc88-6b65-4c7b-ef28-1c4252fcf1d2"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],cnn_50['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.12      0.03      0.05      1903\n",
            "    disagree       0.05      0.19      0.08       697\n",
            "     discuss       0.40      0.34      0.37      4464\n",
            "   unrelated       0.80      0.82      0.81     18349\n",
            "\n",
            "    accuracy                           0.66     25413\n",
            "   macro avg       0.34      0.34      0.33     25413\n",
            "weighted avg       0.66      0.66      0.65     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2_7Naw9RQ64",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "229575b3-78c4-47f1-c984-4feaa6dc52d6"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],cnn_50['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.6558454334395781\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgR2KQstdZHR",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating CNN 100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bQrr1oJdRBb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "a94c5fd0-77b8-4b5d-b685-0bbf9017f1b9"
      },
      "source": [
        "report_score(real_stances['Stance'],cnn_100['Stance'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    21     |    330    |    352    |   1200    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    11     |    78     |    108    |    500    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    36     |    402    |   1089    |   2937    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |    117    |    882    |   1333    |   16017   |\n",
            "-------------------------------------------------------------\n",
            "Score: 5502.0 out of 11651.25\t(47.22240102993241%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47.22240102993241"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOZkSuW8jyP3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "0edb2b91-611c-4595-bf66-66056eef0738"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],cnn_100['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 30.081% \n",
            "F1 agree: 2.011% \n",
            "F1 disagree: 6.530% \n",
            "F1 discuss: 29.649% \n",
            "F1 unrelated: 82.132% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxyQyo1ukdd_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "1bca2c2b-9020-4a5b-83f0-9d77c5ad9222"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],cnn_100['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.11      0.01      0.02      1903\n",
            "    disagree       0.05      0.11      0.07       697\n",
            "     discuss       0.38      0.24      0.30      4464\n",
            "   unrelated       0.78      0.87      0.82     18349\n",
            "\n",
            "    accuracy                           0.68     25413\n",
            "   macro avg       0.33      0.31      0.30     25413\n",
            "weighted avg       0.64      0.68      0.65     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1TU1ZCWSAFR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "6e5c1a7b-ea0e-4e81-cf43-bf6d53137024"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],cnn_100['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.6770157006256641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sM9A2UaGdgb_",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating CNN 150"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VglVFQMBdd3p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "cd68c73e-49cb-492a-badc-a36095569f55"
      },
      "source": [
        "report_score(real_stances['Stance'],cnn_150['Stance'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    49     |    259    |    396    |   1199    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    21     |    99     |    106    |    471    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    90     |    288    |   1424    |   2662    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |    250    |    984    |   2386    |   14729   |\n",
            "-------------------------------------------------------------\n",
            "Score: 5544.25 out of 11651.25\t(47.585023066194616%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47.585023066194616"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPNubdtsj1yD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "3e5d8522-5066-4a83-e833-111f4610f630"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],cnn_150['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 30.985% \n",
            "F1 agree: 4.237% \n",
            "F1 disagree: 8.509% \n",
            "F1 discuss: 32.452% \n",
            "F1 unrelated: 78.744% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnHVXH4JlAS8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "6753c1bd-86c8-4620-d34a-d313cf831167"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],cnn_150['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.12      0.03      0.04      1903\n",
            "    disagree       0.06      0.14      0.09       697\n",
            "     discuss       0.33      0.32      0.32      4464\n",
            "   unrelated       0.77      0.80      0.79     18349\n",
            "\n",
            "    accuracy                           0.64     25413\n",
            "   macro avg       0.32      0.32      0.31     25413\n",
            "weighted avg       0.63      0.64      0.63     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1p67LkygSDX6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "7ccbf60b-a64c-47f9-e213-1c3a77ce652b"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],cnn_150['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.6414433557627985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3D5nkdDdluk",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating LSTM 50 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUKOxeBxdjN2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "7c3c6a00-7e38-4489-a79b-d2b7ba903d26"
      },
      "source": [
        "report_score(real_stances['Stance'],lstm_50['Stance'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    33     |    336    |    267    |   1267    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    12     |    119    |    82     |    484    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    18     |    337    |   1545    |   2564    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |    82     |    643    |   1385    |   16239   |\n",
            "-------------------------------------------------------------\n",
            "Score: 6019.75 out of 11651.25\t(51.6661302435361%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51.6661302435361"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbhKTfEij3pz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "fa7cbcee-3b72-4efa-d98b-d2ec7af687b7"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],lstm_50['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 34.444% \n",
            "F1 agree: 3.223% \n",
            "F1 disagree: 11.163% \n",
            "F1 discuss: 39.907% \n",
            "F1 unrelated: 83.485% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onBBj6tulEcy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "8aeae51d-0f42-46ea-ef93-dd53677fbbbf"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],lstm_50['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.23      0.02      0.03      1903\n",
            "    disagree       0.08      0.17      0.11       697\n",
            "     discuss       0.47      0.35      0.40      4464\n",
            "   unrelated       0.79      0.89      0.83     18349\n",
            "\n",
            "    accuracy                           0.71     25413\n",
            "   macro avg       0.39      0.35      0.34     25413\n",
            "weighted avg       0.67      0.71      0.68     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3SdJHdRSH-x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "ad1e977b-7f75-4332-fc71-2a5a8d81b60b"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],lstm_50['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.7057805060402156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGjC-rmrdqFV",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating LSTM 100 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8mGrn2gdq9Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "61c4e50b-c66f-411b-9637-074390a2013c"
      },
      "source": [
        "report_score(real_stances['Stance'],lstm_100['Stance'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |     0     |    281    |    348    |   1274    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |     0     |    90     |    94     |    513    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |     0     |    446    |   1375    |   2643    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |     0     |   1129    |   1665    |   15555   |\n",
            "-------------------------------------------------------------\n",
            "Score: 5646.0 out of 11651.25\t(48.45831992275507%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48.45831992275507"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SxDsUdqj8z7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "65bfeccf-1042-4e82-b0ae-80fc798115dc"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],lstm_100['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 30.644% \n",
            "F1 agree: 0.000% \n",
            "F1 disagree: 6.810% \n",
            "F1 discuss: 34.609% \n",
            "F1 unrelated: 81.155% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htGFjCSZlImW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "1aefa892-593b-4c2c-a517-0f6477f30604"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],lstm_100['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.00      0.00      0.00      1903\n",
            "    disagree       0.05      0.13      0.07       697\n",
            "     discuss       0.39      0.31      0.35      4464\n",
            "   unrelated       0.78      0.85      0.81     18349\n",
            "\n",
            "    accuracy                           0.67     25413\n",
            "   macro avg       0.30      0.32      0.31     25413\n",
            "weighted avg       0.63      0.67      0.65     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpF-VtVkSLcx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "39238c96-bdcd-46c9-e301-edef40688c7e"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],lstm_100['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.669735961909259\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdVYy35ndrnp",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating LSTM 150"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TOuJ-Hvdsc3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "74258e80-7a10-4ffb-8c2c-b3e14ae9789e"
      },
      "source": [
        "report_score(real_stances['Stance'],lstm_150['Stance'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |     1     |    455    |    432    |   1015    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |     3     |    174    |    158    |    362    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |     4     |    486    |   1538    |   2436    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |    17     |   1379    |   1795    |   15158   |\n",
            "-------------------------------------------------------------\n",
            "Score: 5887.0 out of 11651.25\t(50.526767514215216%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50.526767514215216"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pPSfXizj_K9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "4efd1324-94a1-4b9c-d0c0-db0c95b44049"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],lstm_150['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 32.229% \n",
            "F1 agree: 0.104% \n",
            "F1 disagree: 10.906% \n",
            "F1 discuss: 36.676% \n",
            "F1 unrelated: 81.233% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyA5uOzJlLSu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "bf2d08a8-d564-437f-e57e-d359c92270e2"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],lstm_150['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.04      0.00      0.00      1903\n",
            "    disagree       0.07      0.25      0.11       697\n",
            "     discuss       0.39      0.34      0.37      4464\n",
            "   unrelated       0.80      0.83      0.81     18349\n",
            "\n",
            "    accuracy                           0.66     25413\n",
            "   macro avg       0.33      0.36      0.32     25413\n",
            "weighted avg       0.65      0.66      0.65     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rciJ1WiaSTPg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "8c0031b2-9bc7-4722-bcbd-5b4c3a20d291"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],lstm_150['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.6638728209971274\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy-hfod-eIUc",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating Bi-LSTM 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kxJmONEd1dR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "9d7d1122-cb0e-41ae-daa1-f9f6d532e2ce"
      },
      "source": [
        "report_score(real_stances['Stance'],bi_lstm_50['Stance'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    39     |    318    |    309    |   1237    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    14     |    118    |    86     |    479    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    31     |    341    |   1701    |   2391    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |    43     |    639    |   1327    |   16340   |\n",
            "-------------------------------------------------------------\n",
            "Score: 6217.75 out of 11651.25\t(53.365518721167255%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53.365518721167255"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I341ozqbkEou",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "c5d669af-d422-43ba-b7a0-cfe5e7d22acb"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],bi_lstm_50['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 35.595% \n",
            "F1 agree: 3.842% \n",
            "F1 disagree: 11.169% \n",
            "F1 discuss: 43.134% \n",
            "F1 unrelated: 84.235% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vbgbs1hPlNnU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "bc31f6b7-51f6-4f93-e4a1-64c72dc27266"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],bi_lstm_50['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.31      0.02      0.04      1903\n",
            "    disagree       0.08      0.17      0.11       697\n",
            "     discuss       0.50      0.38      0.43      4464\n",
            "   unrelated       0.80      0.89      0.84     18349\n",
            "\n",
            "    accuracy                           0.72     25413\n",
            "   macro avg       0.42      0.37      0.36     25413\n",
            "weighted avg       0.69      0.72      0.69     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AILzV05LYLKx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e9cfc0b7-4abf-438f-b15b-f7878339597f"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],bi_lstm_50['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.7160901900602054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHFzq7yaeRTQ",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating Bi-LSTM 100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCoXy-93d7Pe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "bc053ec8-029c-427d-fa2c-51cdd077ab62"
      },
      "source": [
        "report_score(real_stances['Stance'],bi_lstm_100['Stance'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    41     |    333    |    450    |   1079    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    10     |    85     |    99     |    503    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    37     |    362    |   2043    |   2022    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |    82     |    599    |   1278    |   16390   |\n",
            "-------------------------------------------------------------\n",
            "Score: 6589.25 out of 11651.25\t(56.55401780924794%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56.55401780924794"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "au_0r1o8kIOG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "2a8c19b4-e096-4473-9a02-2d88357fb963"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],bi_lstm_100['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 36.666% \n",
            "F1 agree: 3.956% \n",
            "F1 disagree: 8.189% \n",
            "F1 discuss: 49.028% \n",
            "F1 unrelated: 85.491% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUxeGHCWlQhp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "44d4decb-8231-4be7-8cad-b2b7d80cbcb6"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],bi_lstm_100['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.24      0.02      0.04      1903\n",
            "    disagree       0.06      0.12      0.08       697\n",
            "     discuss       0.53      0.46      0.49      4464\n",
            "   unrelated       0.82      0.89      0.85     18349\n",
            "\n",
            "    accuracy                           0.73     25413\n",
            "   macro avg       0.41      0.37      0.37     25413\n",
            "weighted avg       0.70      0.73      0.71     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP1EXAS3YS3d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "8b0d18eb-7a7e-44ca-9634-9c16246d23ab"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],bi_lstm_100['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.730295518041947\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nJu16-ceUQl",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating Bi-LSTM 150"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-F7tDcrd80q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "ff3070b9-dab7-49bc-d5aa-ebd05efcc722"
      },
      "source": [
        "report_score(real_stances['Stance'],bi_lstm_150['Stance'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    34     |    207    |    305    |   1357    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    24     |    54     |    103    |    516    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    51     |    209    |   1614    |   2590    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |    75     |    387    |   1136    |   16751   |\n",
            "-------------------------------------------------------------\n",
            "Score: 6114.5 out of 11651.25\t(52.47934770947323%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52.47934770947323"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AmrRSw9kLsx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "af372d8e-0af1-4d5d-ee9d-c21dcce5c1db"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],bi_lstm_150['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 34.310% \n",
            "F1 agree: 3.258% \n",
            "F1 disagree: 6.950% \n",
            "F1 discuss: 42.351% \n",
            "F1 unrelated: 84.680% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiYvAKDIlTR5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "88763712-aa48-40a7-d365-4b15540bbe7d"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],bi_lstm_150['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.18      0.02      0.03      1903\n",
            "    disagree       0.06      0.08      0.07       697\n",
            "     discuss       0.51      0.36      0.42      4464\n",
            "   unrelated       0.79      0.91      0.85     18349\n",
            "\n",
            "    accuracy                           0.73     25413\n",
            "   macro avg       0.39      0.34      0.34     25413\n",
            "weighted avg       0.68      0.73      0.69     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1l1BivXYWlt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "af2f8f1e-cd59-424e-a598-6da80fdf3eb7"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],bi_lstm_150['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.726124424507142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zVLRbhP6_Ew",
        "colab_type": "text"
      },
      "source": [
        "## W2V CNN 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cvNh54E7Co5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "1bd96f2b-168b-4fcd-acc1-981ff772f69d"
      },
      "source": [
        "report_score(real_stances['Stance'],w2v_cnn_50['Stance'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    33     |    352    |    532    |    986    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    13     |    90     |    187    |    407    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    51     |    393    |   1938    |   2082    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |    182    |   1215    |   2728    |   14224   |\n",
            "-------------------------------------------------------------\n",
            "Score: 5999.0 out of 11651.25\t(51.48803776418839%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51.48803776418839"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqwqhodJ7Csg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a4ac74e5-6cbb-4dbe-e58b-8e5c0523d143"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],w2v_cnn_50['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 31.962% \n",
            "F1 agree: 3.025% \n",
            "F1 disagree: 6.553% \n",
            "F1 discuss: 39.354% \n",
            "F1 unrelated: 78.917% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jbk7LkGD7C6B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "56e66245-8850-484d-a25d-c4452f615183"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],w2v_cnn_50['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.12      0.02      0.03      1903\n",
            "    disagree       0.04      0.13      0.07       697\n",
            "     discuss       0.36      0.43      0.39      4464\n",
            "   unrelated       0.80      0.78      0.79     18349\n",
            "\n",
            "    accuracy                           0.64     25413\n",
            "   macro avg       0.33      0.34      0.32     25413\n",
            "weighted avg       0.65      0.64      0.64     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTzjx10BYZYr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "a3450000-c4fa-4f50-811e-b6d8110d1866"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],w2v_cnn_50['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.640813756738677\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5m6llvT7DLP",
        "colab_type": "text"
      },
      "source": [
        "## W2V LSTM 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKQz3r6y7GKu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "71aafb5e-0f6d-4d58-d1e9-847cc270435f"
      },
      "source": [
        "report_score(real_stances['Stance'],w2v_lstm_50['Stance'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |     8     |    213    |    281    |   1401    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |     3     |    40     |    86     |    568    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    20     |    226    |   1363    |   2855    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |    35     |    503    |   1348    |   16463   |\n",
            "-------------------------------------------------------------\n",
            "Score: 5734.0 out of 11651.25\t(49.213603690591135%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49.213603690591135"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APq8Tcud7GPi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "fbdc20df-ceda-41b5-df2f-39f08b67f0b1"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],w2v_lstm_50['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 31.198% \n",
            "F1 agree: 0.813% \n",
            "F1 disagree: 4.765% \n",
            "F1 discuss: 36.144% \n",
            "F1 unrelated: 83.071% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkTmyow67GW4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "b485e273-1510-4731-ef0a-837b6dc34099"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],w2v_lstm_50['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.12      0.00      0.01      1903\n",
            "    disagree       0.04      0.06      0.05       697\n",
            "     discuss       0.44      0.31      0.36      4464\n",
            "   unrelated       0.77      0.90      0.83     18349\n",
            "\n",
            "    accuracy                           0.70     25413\n",
            "   macro avg       0.34      0.32      0.31     25413\n",
            "weighted avg       0.65      0.70      0.67     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OV6YIC0YetJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "51408f73-fc13-44d7-d21c-009dc853fa46"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],w2v_lstm_50['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.7033408098217447\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbQVR6ZE7GjD",
        "colab_type": "text"
      },
      "source": [
        "## W2V Bi-LSTM 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkHBwvJ27HAO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "8e5f3bcd-fb57-479c-926c-e71c8b7e3cb5"
      },
      "source": [
        "report_score(real_stances['Stance'],w2v_bi_lstm_50['Stance'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    10     |    430    |    343    |   1120    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |     9     |    112    |    101    |    475    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    18     |    602    |   1552    |   2292    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |    39     |   1152    |   1453    |   15705   |\n",
            "-------------------------------------------------------------\n",
            "Score: 5976.0 out of 11651.25\t(51.29063405214033%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51.29063405214033"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUDzf29m7HJ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a5959d11-1b56-44b6-dd35-a597a6b92561"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],w2v_bi_lstm_50['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 32.627% \n",
            "F1 agree: 1.011% \n",
            "F1 disagree: 7.484% \n",
            "F1 discuss: 39.227% \n",
            "F1 unrelated: 82.786% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DF0p8x_M7HXI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "6debbf4f-e464-46ed-fe09-57e7fdd243c9"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],w2v_bi_lstm_50['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.13      0.01      0.01      1903\n",
            "    disagree       0.05      0.16      0.07       697\n",
            "     discuss       0.45      0.35      0.39      4464\n",
            "   unrelated       0.80      0.86      0.83     18349\n",
            "\n",
            "    accuracy                           0.68     25413\n",
            "   macro avg       0.36      0.34      0.33     25413\n",
            "weighted avg       0.67      0.68      0.67     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_jo1b_VYiT5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "ca3ae6dd-6321-4c54-fd94-c12768a5e9d7"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],w2v_bi_lstm_50['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.6838625900129854\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4tl-nG4yVEJ",
        "colab_type": "text"
      },
      "source": [
        "## Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrosTQZnyVj6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "7d0c05cb-2393-4cf1-8503-383c4135d7ab"
      },
      "source": [
        "report_score(real_stances['Stance'],gradient_boosting['Stance'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    163    |     1     |   1542    |    197    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    43     |     1     |    478    |    175    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    173    |     4     |   3830    |    457    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |     8     |     1     |    306    |   18034   |\n",
            "-------------------------------------------------------------\n",
            "Score: 9062.75 out of 11651.25\t(77.7834996245038%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "77.7834996245038"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJqs99mgz94j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "b66d5e53-c115-4e38-e0cf-c6f1ee97b135"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],gradient_boosting['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 45.893% \n",
            "F1 agree: 14.236% \n",
            "F1 disagree: 0.284% \n",
            "F1 discuss: 72.128% \n",
            "F1 unrelated: 96.926% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmEDtUT3z98d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "6e609b1d-4dbd-4ab7-e9ab-251344e5424e"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],gradient_boosting['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.42      0.09      0.14      1903\n",
            "    disagree       0.14      0.00      0.00       697\n",
            "     discuss       0.62      0.86      0.72      4464\n",
            "   unrelated       0.96      0.98      0.97     18349\n",
            "\n",
            "    accuracy                           0.87     25413\n",
            "   macro avg       0.54      0.48      0.46     25413\n",
            "weighted avg       0.84      0.87      0.84     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q54okKXDYnEf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "0223d209-a6c1-4a69-a3dd-82ee2a4befd5"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],gradient_boosting['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.8668004564592925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-xDoYXR0WR5",
        "colab_type": "text"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tauif9mfz92Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "d74ae19b-bbb3-46ae-a794-9af93eeddc8e"
      },
      "source": [
        "report_score(real_stances['Stance'],random_forest['Stance'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    96     |     0     |   1599    |    208    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    19     |     0     |    490    |    188    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    104    |     0     |   3868    |    492    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |     2     |     0     |    273    |   18074   |\n",
            "-------------------------------------------------------------\n",
            "Score: 9035.5 out of 11651.25\t(77.5496191395773%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "77.5496191395773"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBHsUPwd0ZNT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "ca1eb0b7-5b66-4159-f986-f5993633fa3d"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],random_forest['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 44.566% \n",
            "F1 agree: 9.040% \n",
            "F1 disagree: 0.000% \n",
            "F1 discuss: 72.340% \n",
            "F1 unrelated: 96.883% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7yPoXtN0rBT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "f96b5a95-b923-4e19-8b3b-1a5ca9c30ada"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],random_forest['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.43      0.05      0.09      1903\n",
            "    disagree       0.00      0.00      0.00       697\n",
            "     discuss       0.62      0.87      0.72      4464\n",
            "   unrelated       0.95      0.99      0.97     18349\n",
            "\n",
            "    accuracy                           0.87     25413\n",
            "   macro avg       0.50      0.48      0.45     25413\n",
            "weighted avg       0.83      0.87      0.83     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nht3r4mHYrPw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "f964c464-6c97-4f60-81ac-370b1f36161f"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],random_forest['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.8671939558493684\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8dJsexJ07fq",
        "colab_type": "text"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgfEKRLm02AL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "a3218925-3d24-4ec6-fc67-bd0d39cc5e5c"
      },
      "source": [
        "report_score(real_stances['Stance'],logistic_regression['Stance'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    111    |     0     |   1579    |    213    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    17     |     0     |    485    |    195    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    129    |     0     |   3820    |    515    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |     3     |     0     |    254    |   18092   |\n",
            "-------------------------------------------------------------\n",
            "Score: 9006.5 out of 11651.25\t(77.30071880699495%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "77.30071880699495"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H6lkVpk1MFj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d648aa7d-a53a-4e2f-8b1e-ec731a6e89ae"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],logistic_regression['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 44.792% \n",
            "F1 agree: 10.264% \n",
            "F1 disagree: 0.000% \n",
            "F1 discuss: 72.062% \n",
            "F1 unrelated: 96.842% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vzotgbs1P6F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "3d767e9f-0626-45cd-eff4-7bce35bd2729"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],logistic_regression['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.43      0.06      0.10      1903\n",
            "    disagree       0.00      0.00      0.00       697\n",
            "     discuss       0.62      0.86      0.72      4464\n",
            "   unrelated       0.95      0.99      0.97     18349\n",
            "\n",
            "    accuracy                           0.87     25413\n",
            "   macro avg       0.50      0.48      0.45     25413\n",
            "weighted avg       0.83      0.87      0.83     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klFu7-5sYuvT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "f449747d-362c-4590-f8fd-ccab9926e74b"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],logistic_regression['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.8666037067642545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPJNP7pp1fCG",
        "colab_type": "text"
      },
      "source": [
        "## XGBOOST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewgBjciD1RUv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "6a1b6cb2-b3fa-43ce-893a-6ed9c06fc685"
      },
      "source": [
        "report_score(real_stances['Stance'],xgboost['Stance'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    111    |     1     |   1597    |    194    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    38     |     0     |    478    |    181    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    129    |     0     |   3880    |    455    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |     3     |     0     |    299    |   18047   |\n",
            "-------------------------------------------------------------\n",
            "Score: 9063.5 out of 11651.25\t(77.78993670207059%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "77.78993670207059"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl5MA65z1jmg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "7849b5c7-3350-4d5a-a360-09d901267167"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],xgboost['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 44.881% \n",
            "F1 agree: 10.165% \n",
            "F1 disagree: 0.000% \n",
            "F1 discuss: 72.402% \n",
            "F1 unrelated: 96.959% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ9QAiJH1qG8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "85668d7f-5b19-45d6-858c-422c40de6b68"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],xgboost['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.40      0.06      0.10      1903\n",
            "    disagree       0.00      0.00      0.00       697\n",
            "     discuss       0.62      0.87      0.72      4464\n",
            "   unrelated       0.96      0.98      0.97     18349\n",
            "\n",
            "    accuracy                           0.87     25413\n",
            "   macro avg       0.49      0.48      0.45     25413\n",
            "weighted avg       0.83      0.87      0.83     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHgCmaHYYx5a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "4c2cdc96-8bf9-40a7-c2aa-b8aac7833c35"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],xgboost['Stance']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.8671939558493684\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbigWieRwul2",
        "colab_type": "text"
      },
      "source": [
        "## Bert classifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT-OZ69cwxPP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "d1488ef5-be1f-497d-cd39-de5245e7b72f"
      },
      "source": [
        "report_score(real_stances['Stance'],bert_base['Stance'])"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    750    |    24     |    400    |    729    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    202    |    42     |    113    |    340    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    351    |    39     |   2509    |   1565    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |    343    |    14     |    921    |   17071   |\n",
            "-------------------------------------------------------------\n",
            "Score: 7851.0 out of 11651.25\t(67.38332796910203%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67.38332796910203"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygMCxRC4w84d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "9279f9d1-f708-437e-8157-81f581aa9118"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],bert_base['Stance']))"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 50.492% \n",
            "F1 agree: 42.265% \n",
            "F1 disagree: 10.294% \n",
            "F1 discuss: 59.688% \n",
            "F1 unrelated: 89.720% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_N9iV_Mw88l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "0c37e24e-9481-441d-9f6c-e974784b0758"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],bert_base['Stance']))"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.46      0.39      0.42      1903\n",
            "    disagree       0.35      0.06      0.10       697\n",
            "     discuss       0.64      0.56      0.60      4464\n",
            "   unrelated       0.87      0.93      0.90     18349\n",
            "\n",
            "    accuracy                           0.80     25413\n",
            "   macro avg       0.58      0.49      0.50     25413\n",
            "weighted avg       0.78      0.80      0.79     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QltCU1T0w9cy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "ae8525cb-8b33-42a5-8e90-662937f92bdd"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],bert_base['Stance']))"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.8016369574627159\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeSkgRTPxKdt",
        "colab_type": "text"
      },
      "source": [
        "## Resampled Data for training Gradient Boosting | 50% unrelated taken. Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kMg1oyBxSWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "09e43e1e-c3f0-4bfd-b8ba-d17a2938490e"
      },
      "source": [
        "report_score(real_stances['Stance'],gb_undersample['Stance'])"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    296    |     4     |   1516    |    87     |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    97     |     2     |    524    |    74     |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    407    |    13     |   3869    |    175    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |    85     |    19     |    972    |   17273   |\n",
            "-------------------------------------------------------------\n",
            "Score: 9125.5 out of 11651.25\t(78.32206844759146%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78.32206844759146"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ausFomFNxSei",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "e576fc57-e82c-4a84-80a6-e137bb6870b4"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],gb_undersample['Stance']))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 46.514% \n",
            "F1 agree: 21.234% \n",
            "F1 disagree: 0.544% \n",
            "F1 discuss: 68.206% \n",
            "F1 unrelated: 96.073% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOZeC1dexSlk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "788557c4-55c7-4868-b12b-12881103b5d7"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],gb_undersample['Stance']))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.33      0.16      0.21      1903\n",
            "    disagree       0.05      0.00      0.01       697\n",
            "     discuss       0.56      0.87      0.68      4464\n",
            "   unrelated       0.98      0.94      0.96     18349\n",
            "\n",
            "    accuracy                           0.84     25413\n",
            "   macro avg       0.48      0.49      0.47     25413\n",
            "weighted avg       0.83      0.84      0.83     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iZTmddyxSuM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "37099059-49cb-4508-ebbb-2c57e3c1435c"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],gb_undersample['Stance']))"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.8436626923228269\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeQZGe2_xSzd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFIut_mT1wVg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "90db1dea-4a50-4291-d15a-904f87668c39"
      },
      "source": [
        "# Horizontal Bar plot\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "models=['CNN 50 Truncs','CNN 100 Truncs','CNN 150 Truncs',\n",
        "        'LSTM 50 Truncs','LSTM 100 Truncs','LSTM 150 Truncs',\n",
        "        'BI-LSTM 50 Truncs','BI-LSTM 100 Truncs','BI-LSTM 150 Truncs',\n",
        "        'W2V CNN 50','W2V LSTM 50','W2V BI-LSTM 50',\n",
        "        'Bert Classifier',\n",
        "        'LOGISTIC REGRESSION','RANDOM FOREST 50','GRADIENT BOOSTING','XG BOOST','GRADIENT BOOSTING | undersampled data']\n",
        "\n",
        "accuracies=np.asarray([50.3,47.2,47.5,51.6,48.5,50.5,53.3,56.5,52.4,51.4,49.2,51.2,67.4,77.3,77.5,77.8,77.8,78.3])\n",
        "plt.figure(figsize=(8,7))\n",
        "plt.barh(models,accuracies,color=['firebrick', 'black',\n",
        "                    'purple', 'seagreen', 'skyblue','pink','gray','teal'])\n",
        "plt.xlabel(\"Relative Accuracy\")\n",
        "plt.ylabel('Model')\n",
        "plt.title('Relative Accuracies at Test Set')\n",
        "plt.show()"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
