{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Random_Forest_cosine_sim.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIBdI8ZdCLtZ",
        "colab_type": "text"
      },
      "source": [
        "### Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKDziZErvCNI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "8053a40d-0d4c-4631-df39-d945ef7f7552"
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import nltk\n",
        "import os\n",
        "import re\n",
        "_wnl = nltk.WordNetLemmatizer()\n",
        "from tqdm import tqdm\n",
        "import scipy\n",
        "from csv import DictReader\n",
        "import pandas as pd\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "# sklearn dependencies\n",
        "from sklearn import feature_extraction\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "# Function for reading the dataset\n",
        "class DataSet():\n",
        "    def __init__(self, name=\"train\", path=\"/content/drive/My Drive/641\"):\n",
        "        self.path = path\n",
        "\n",
        "        print(\"Reading dataset\")\n",
        "        bodies = name+\"_bodies.csv\"\n",
        "        stances = name+\"_stances.csv\"\n",
        "        \n",
        "        self.stances = self.read(stances)\n",
        "       \n",
        "        articles = self.read(bodies)\n",
        "       \n",
        "        self.articles = dict()\n",
        "\n",
        "        #make the body ID an integer value\n",
        "        for s in self.stances:\n",
        "            s['Body ID'] = int(s['Body ID'])\n",
        "        \n",
        "        #copy all bodies into a dictionary\n",
        "        for article in articles:\n",
        "            self.articles[int(article['Body ID'])] = article['articleBody']\n",
        "\n",
        "        print(\"Total stances: \" + str(len(self.stances)))\n",
        "        print(\"Total bodies: \" + str(len(self.articles)))\n",
        "\n",
        "    \n",
        "\n",
        "    def read(self,filename):\n",
        "        rows = []\n",
        "        with open(self.path + \"/\" + filename, \"r\", encoding='utf-8') as table:\n",
        "            r = DictReader(table)\n",
        "\n",
        "            for line in r:\n",
        "                rows.append(line)\n",
        "        return rows\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SimEgIk-C1H1",
        "colab_type": "text"
      },
      "source": [
        "### Functions to form various features "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXG88TCotLR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def normalize_word(w):\n",
        "    return _wnl.lemmatize(w).lower()\n",
        "\n",
        "\n",
        "def get_tokenized_lemmas(s):\n",
        "    return [normalize_word(t) for t in nltk.word_tokenize(s)]\n",
        "\n",
        "\n",
        "def clean(s):\n",
        "    # Cleans a string: Lowercasing, trimming, removing non-alphanumeric\n",
        "\n",
        "    return \" \".join(re.findall(r'\\w+', s, flags=re.UNICODE)).lower()\n",
        "\n",
        "\n",
        "def remove_stopwords(l):\n",
        "    # Removes stopwords from a list of tokens\n",
        "    return [w for w in l if w not in feature_extraction.text.ENGLISH_STOP_WORDS]\n",
        "\n",
        "\n",
        "def gen_or_load_feats(feat_fn, headlines, bodies, feature_file):\n",
        "    if not os.path.isfile(feature_file):\n",
        "        feats = feat_fn(headlines, bodies)\n",
        "        np.save(feature_file, feats)\n",
        "\n",
        "    return np.load(feature_file)\n",
        "\n",
        "\n",
        "def word_overlap_features(headlines, bodies):\n",
        "    X = []\n",
        "    for i, (headline, body) in tqdm(enumerate(zip(headlines, bodies))):\n",
        "        clean_headline = clean(headline)\n",
        "        clean_body = clean(body)\n",
        "        clean_headline = get_tokenized_lemmas(clean_headline)\n",
        "        clean_body = get_tokenized_lemmas(clean_body)\n",
        "        features = [\n",
        "            len(set(clean_headline).intersection(clean_body)) / float(len(set(clean_headline).union(clean_body)))]\n",
        "        X.append(features)\n",
        "    return X\n",
        "\n",
        "\n",
        "def refuting_features(headlines, bodies):\n",
        "    _refuting_words = [\n",
        "        'fake',\n",
        "        'fraud',\n",
        "        'hoax',\n",
        "        'false',\n",
        "        'deny', 'denies',\n",
        "        # 'refute',\n",
        "        'not',\n",
        "        'despite',\n",
        "        'nope',\n",
        "        'doubt', 'doubts',\n",
        "        'bogus',\n",
        "        'debunk',\n",
        "        'pranks',\n",
        "        'retract'\n",
        "    ]\n",
        "    X = []\n",
        "    for i, (headline, body) in tqdm(enumerate(zip(headlines, bodies))):\n",
        "        clean_headline = clean(headline)\n",
        "        clean_headline = get_tokenized_lemmas(clean_headline)\n",
        "        features = [1 if word in clean_headline else 0 for word in _refuting_words]\n",
        "        X.append(features)\n",
        "    return X\n",
        "\n",
        "\n",
        "def polarity_features(headlines, bodies):\n",
        "    _refuting_words = [\n",
        "        'fake',\n",
        "        'fraud',\n",
        "        'hoax',\n",
        "        'false',\n",
        "        'deny', 'denies',\n",
        "        'not',\n",
        "        'despite',\n",
        "        'nope',\n",
        "        'doubt', 'doubts',\n",
        "        'bogus',\n",
        "        'debunk',\n",
        "        'pranks',\n",
        "        'retract'\n",
        "    ]\n",
        "\n",
        "    def calculate_polarity(text):\n",
        "        tokens = get_tokenized_lemmas(text)\n",
        "        return sum([t in _refuting_words for t in tokens]) % 2\n",
        "    X = []\n",
        "    for i, (headline, body) in tqdm(enumerate(zip(headlines, bodies))):\n",
        "        clean_headline = clean(headline)\n",
        "        clean_body = clean(body)\n",
        "        features = []\n",
        "        features.append(calculate_polarity(clean_headline))\n",
        "        features.append(calculate_polarity(clean_body))\n",
        "        X.append(features)\n",
        "    return np.array(X)\n",
        "\n",
        "\n",
        "def ngrams(input, n):\n",
        "    input = input.split(' ')\n",
        "    output = []\n",
        "    for i in range(len(input) - n + 1):\n",
        "        output.append(input[i:i + n])\n",
        "    return output\n",
        "\n",
        "\n",
        "def chargrams(input, n):\n",
        "    output = []\n",
        "    for i in range(len(input) - n + 1):\n",
        "        output.append(input[i:i + n])\n",
        "    return output\n",
        "\n",
        "\n",
        "def append_chargrams(features, text_headline, text_body, size):\n",
        "    grams = [' '.join(x) for x in chargrams(\" \".join(remove_stopwords(text_headline.split())), size)]\n",
        "    grams_hits = 0\n",
        "    grams_early_hits = 0\n",
        "    grams_first_hits = 0\n",
        "    for gram in grams:\n",
        "        if gram in text_body:\n",
        "            grams_hits += 1\n",
        "        if gram in text_body[:255]:\n",
        "            grams_early_hits += 1\n",
        "        if gram in text_body[:100]:\n",
        "            grams_first_hits += 1\n",
        "    features.append(grams_hits)\n",
        "    features.append(grams_early_hits)\n",
        "    features.append(grams_first_hits)\n",
        "    return features\n",
        "\n",
        "\n",
        "def append_ngrams(features, text_headline, text_body, size):\n",
        "    grams = [' '.join(x) for x in ngrams(text_headline, size)]\n",
        "    grams_hits = 0\n",
        "    grams_early_hits = 0\n",
        "    for gram in grams:\n",
        "        if gram in text_body:\n",
        "            grams_hits += 1\n",
        "        if gram in text_body[:255]:\n",
        "            grams_early_hits += 1\n",
        "    features.append(grams_hits)\n",
        "    features.append(grams_early_hits)\n",
        "    return features\n",
        "def gramian_feature(headlines, bodies):\n",
        "\tvectorizer = TfidfVectorizer(ngram_range=(1,2), lowercase=True, stop_words='english')#, max_features=1024)\n",
        "\tsim_features = []\n",
        "\tfor i in range(0, len(bodies)):\n",
        "\t\tbody_headline = []\n",
        "\t\tbody_headline.append(bodies[i])\n",
        "\t\tbody_headline.append(headlines[i])\n",
        "\t\ttfidf = vectorizer.fit_transform(body_headline)\n",
        "\n",
        "\t\tsimilarity = (tfidf * tfidf.T).A\n",
        "\t\tsim_features.append(similarity[0][1])\n",
        "\n",
        "\t\n",
        "\tsim_array = np.array(sim_features) \n",
        "\n",
        "\treturn sim_array\n",
        "\n",
        "\n",
        "def hand_features(headlines, bodies):\n",
        "\n",
        "    def binary_co_occurence(headline, body):\n",
        "        # Count how many times a token in the title\n",
        "        # appears in the body text.\n",
        "        bin_count = 0\n",
        "        bin_count_early = 0\n",
        "        for headline_token in clean(headline).split(\" \"):\n",
        "            if headline_token in clean(body):\n",
        "                bin_count += 1\n",
        "            if headline_token in clean(body)[:255]:\n",
        "                bin_count_early += 1\n",
        "        return [bin_count, bin_count_early]\n",
        "\n",
        "    def binary_co_occurence_stops(headline, body):\n",
        "        # Count how many times a token in the title\n",
        "        # appears in the body text. Stopwords in the title\n",
        "        # are ignored.\n",
        "        bin_count = 0\n",
        "        bin_count_early = 0\n",
        "        for headline_token in remove_stopwords(clean(headline).split(\" \")):\n",
        "            if headline_token in clean(body):\n",
        "                bin_count += 1\n",
        "                bin_count_early += 1\n",
        "        return [bin_count, bin_count_early]\n",
        "\n",
        "    def count_grams(headline, body):\n",
        "        # Count how many times an n-gram of the title\n",
        "        # appears in the entire body, and intro paragraph\n",
        "\n",
        "        clean_body = clean(body)\n",
        "        clean_headline = clean(headline)\n",
        "        features = []\n",
        "        features = append_chargrams(features, clean_headline, clean_body, 2)\n",
        "        features = append_chargrams(features, clean_headline, clean_body, 8)\n",
        "        features = append_chargrams(features, clean_headline, clean_body, 4)\n",
        "        features = append_chargrams(features, clean_headline, clean_body, 16)\n",
        "        features = append_ngrams(features, clean_headline, clean_body, 2)\n",
        "        features = append_ngrams(features, clean_headline, clean_body, 3)\n",
        "        features = append_ngrams(features, clean_headline, clean_body, 4)\n",
        "        features = append_ngrams(features, clean_headline, clean_body, 5)\n",
        "        features = append_ngrams(features, clean_headline, clean_body, 6)\n",
        "        return features\n",
        "\n",
        "    X = []\n",
        "    for i, (headline, body) in tqdm(enumerate(zip(headlines, bodies))):\n",
        "        X.append(binary_co_occurence(headline, body)\n",
        "                 + binary_co_occurence_stops(headline, body)\n",
        "                 + count_grams(headline, body))\n",
        "\n",
        "\n",
        "    return X\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntlcxEiDDLsv",
        "colab_type": "text"
      },
      "source": [
        "### Functions to generate splits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRuNhRARuq3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "def generate_hold_out_split (dataset, training = 0.8, base_dir=\"/content/drive/My Drive/641\"):\n",
        "    r = random.Random()\n",
        "    r.seed(1489215)\n",
        "\n",
        "    article_ids = list(dataset.articles.keys())  # get a list of article ids\n",
        "    r.shuffle(article_ids)  # and shuffle that list\n",
        "\n",
        "\n",
        "    training_ids = article_ids[:int(training * len(article_ids))]\n",
        "    hold_out_ids = article_ids[int(training * len(article_ids)):]\n",
        "\n",
        "    # write the split body ids out to files for future use\n",
        "    with open(base_dir+ \"/\"+ \"training_ids.txt\", \"w+\") as f:\n",
        "        f.write(\"\\n\".join([str(id) for id in training_ids]))\n",
        "\n",
        "    with open(base_dir+ \"/\"+ \"hold_out_ids.txt\", \"w+\") as f:\n",
        "        f.write(\"\\n\".join([str(id) for id in hold_out_ids]))\n",
        "\n",
        "\n",
        "\n",
        "def read_ids(file,base):\n",
        "    ids = []\n",
        "    with open(base+\"/\"+file,\"r\") as f:\n",
        "        for line in f:\n",
        "           ids.append(int(line))\n",
        "        return ids\n",
        "\n",
        "\n",
        "def kfold_split(dataset, training = 0.8, n_folds = 10, base_dir=\"/content/drive/My Drive/641\"):\n",
        "    if not (os.path.exists(base_dir+ \"/\"+ \"training_ids.txt\")\n",
        "            and os.path.exists(base_dir+ \"/\"+ \"hold_out_ids.txt\")):\n",
        "        generate_hold_out_split(dataset,training,base_dir)\n",
        "\n",
        "    training_ids = read_ids(\"training_ids.txt\", base_dir)\n",
        "    hold_out_ids = read_ids(\"hold_out_ids.txt\", base_dir)\n",
        "\n",
        "    folds = []\n",
        "    for k in range(n_folds):\n",
        "        folds.append(training_ids[int(k*len(training_ids)/n_folds):int((k+1)*len(training_ids)/n_folds)])\n",
        "\n",
        "    return folds,hold_out_ids\n",
        "\n",
        "\n",
        "def get_stances_for_folds(dataset,folds,hold_out):\n",
        "    stances_folds = defaultdict(list)\n",
        "    stances_hold_out = []\n",
        "    for stance in dataset.stances:\n",
        "        if stance['Body ID'] in hold_out:\n",
        "            stances_hold_out.append(stance)\n",
        "        else:\n",
        "            fold_id = 0\n",
        "            for fold in folds:\n",
        "                if stance['Body ID'] in fold:\n",
        "                    stances_folds[fold_id].append(stance)\n",
        "                fold_id += 1\n",
        "\n",
        "    return stances_folds,stances_hold_out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9hp1K5A7qmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1-wXahADS4t",
        "colab_type": "text"
      },
      "source": [
        "### Functions to generate the score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctcVfMkpvN7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "LABELS = ['agree', 'disagree', 'discuss', 'unrelated']\n",
        "LABELS_RELATED = ['unrelated','related']\n",
        "RELATED = LABELS[0:3]\n",
        "\n",
        "def score_submission(gold_labels, test_labels):\n",
        "    score = 0.0\n",
        "    cm = [[0, 0, 0, 0],\n",
        "          [0, 0, 0, 0],\n",
        "          [0, 0, 0, 0],\n",
        "          [0, 0, 0, 0]]\n",
        "\n",
        "    for i, (g, t) in enumerate(zip(gold_labels, test_labels)):\n",
        "        g_stance, t_stance = g, t\n",
        "        if g_stance == t_stance:\n",
        "            score += 0.25\n",
        "            if g_stance != 'unrelated':\n",
        "                score += 0.50\n",
        "        if g_stance in RELATED and t_stance in RELATED:\n",
        "            score += 0.25\n",
        "\n",
        "        cm[LABELS.index(g_stance)][LABELS.index(t_stance)] += 1\n",
        "\n",
        "    return score, cm\n",
        "\n",
        "\n",
        "def print_confusion_matrix(cm):\n",
        "    lines = []\n",
        "    header = \"|{:^11}|{:^11}|{:^11}|{:^11}|{:^11}|\".format('', *LABELS)\n",
        "    line_len = len(header)\n",
        "    lines.append(\"-\"*line_len)\n",
        "    lines.append(header)\n",
        "    lines.append(\"-\"*line_len)\n",
        "\n",
        "    hit = 0\n",
        "    total = 0\n",
        "    for i, row in enumerate(cm):\n",
        "        hit += row[i]\n",
        "        total += sum(row)\n",
        "        lines.append(\"|{:^11}|{:^11}|{:^11}|{:^11}|{:^11}|\".format(LABELS[i],\n",
        "                                                                   *row))\n",
        "        lines.append(\"-\"*line_len)\n",
        "    print('\\n'.join(lines))\n",
        "\n",
        "\n",
        "def report_score(actual,predicted):\n",
        "    score,cm = score_submission(actual,predicted)\n",
        "    best_score, _ = score_submission(actual,actual)\n",
        "\n",
        "    print_confusion_matrix(cm)\n",
        "    print(\"Score: \" +str(score) + \" out of \" + str(best_score) + \"\\t(\"+str(score*100/best_score) + \"%)\")\n",
        "    return score*100/best_score\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTtqx_CJDi0B",
        "colab_type": "text"
      },
      "source": [
        "### Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjdeIHR5vclZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "ff9199c1-c01e-4256-9d1e-2ba31a55d5e8"
      },
      "source": [
        "\n",
        "\n",
        "def generate_features(stances,dataset,name):\n",
        "    h, b, y = [],[],[]\n",
        "\n",
        "    for stance in stances:\n",
        "        y.append(LABELS.index(stance['Stance']))\n",
        "        h.append(stance['Headline'])\n",
        "        b.append(dataset.articles[stance['Body ID']])\n",
        "\n",
        "    X_overlap = gen_or_load_feats(word_overlap_features, h, b, \"overlap.\"+name+\".npy\")\n",
        "    X_refuting = gen_or_load_feats(refuting_features, h, b, \"refuting.\"+name+\".npy\")\n",
        "    X_polarity = gen_or_load_feats(polarity_features, h, b, \"polarity.\"+name+\".npy\")\n",
        "    X_hand = gen_or_load_feats(hand_features, h, b, \"hand.\"+name+\".npy\")\n",
        "    X_sim=gen_or_load_feats(gramian_feature,h,b,\"sim.\"+name+\".npy\")\n",
        "\n",
        "    X = np.c_[X_hand, X_polarity, X_refuting, X_overlap,X_sim]\n",
        "    X = preprocessing.scale(X)\n",
        "    return X,y\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "#Load the training dataset and generate folds\n",
        "d = DataSet()\n",
        "folds,hold_out = kfold_split(d,n_folds=10)\n",
        "fold_stances, hold_out_stances = get_stances_for_folds(d,folds,hold_out)\n",
        "\n",
        "# Load the competition dataset\n",
        "competition_dataset = DataSet(\"competition_test\")\n",
        "X_competition, y_competition = generate_features(competition_dataset.stances, competition_dataset, \"competition\")\n",
        "    \n",
        "  \n",
        "Xs = dict()\n",
        "ys = dict()\n",
        "\n",
        "# Load/Precompute all features now\n",
        "X_holdout,y_holdout = generate_features(hold_out_stances,d,\"holdout\")\n",
        "for fold in fold_stances:\n",
        "    Xs[fold],ys[fold] = generate_features(fold_stances[fold],d,str(fold))\n",
        "\n",
        "\n",
        "best_score = 0\n",
        "best_fold = None\n",
        "\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading dataset\n",
            "Total stances: 49972\n",
            "Total bodies: 1683\n",
            "Reading dataset\n",
            "Total stances: 25413\n",
            "Total bodies: 904\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyYjAffdlsap",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e2943804-67e4-463d-90ad-1cb37b3f8af5"
      },
      "source": [
        "# Classifier for each fold\n",
        "for fold in fold_stances:\n",
        "    ids = list(range(len(folds)))\n",
        "    del ids[fold]\n",
        "\n",
        "    X_train = np.vstack(tuple([Xs[i] for i in ids]))\n",
        "    y_train = np.hstack(tuple([ys[i] for i in ids]))\n",
        "\n",
        "    X_test = Xs[fold]\n",
        "    y_test = ys[fold]\n",
        "        \n",
        "    #tuned to best parameters     \n",
        "    \"\"\"\n",
        "    n_estimator:[50]\n",
        "    max_depth:[15]\n",
        "    Accuracy: 75.89%\n",
        "\n",
        "    n_estimator:[100]\n",
        "    max_depth:[15]\n",
        "    Accuracy: 76.52%\n",
        "\n",
        "    n_estimator:[200]\n",
        "    max_depth:[15]\n",
        "    Accuracy: 77.54%\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    randomforest=RandomForestClassifier(max_depth=15,n_estimators=200, random_state=42,verbose=True,n_jobs=6)\n",
        "    randomforest.fit(X_train, y_train)\n",
        "        \n",
        "          \n",
        "    predicted = [LABELS[int(a)] for a in randomforest.predict(X_test)]   \n",
        "       \n",
        "        \n",
        "    actual = [LABELS[int(a)] for a in y_test]\n",
        "\n",
        "    fold_score, _ = score_submission(actual, predicted)\n",
        "    max_fold_score, _ = score_submission(actual, actual)\n",
        "\n",
        "    score = fold_score/max_fold_score\n",
        "\n",
        "    print(\"Score for fold \"+ str(fold) + \" was - \" + str(score))\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_fold = randomforest\n",
        "\n",
        "\n",
        "\n",
        "#Run on Holdout set and report the final score on the holdout set\n",
        "predicted = [LABELS[int(a)] for a in best_fold.predict(X_holdout)]\n",
        "    \n",
        "    \n",
        "actual = [LABELS[int(a)] for a in y_holdout]\n",
        "\n",
        "    \n",
        "report_score(actual,predicted)\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n",
        "#Run on competition dataset\n",
        "   \n",
        "predicted = [LABELS[int(a)] for a in best_fold.predict(X_competition)]\n",
        "actual = [LABELS[int(a)] for a in y_competition]\n",
        "    \n",
        "    \n",
        "a=report_score(actual,predicted)\n",
        "print(\"______________________________________________________________________________________________________________________\")\n",
        "# print(a)\n",
        "\n",
        "\n",
        "    \n",
        "# print(predicted)\n",
        "\n",
        "body_id = []\n",
        "headlines = []\n",
        "stances = np.copy(np.array(predicted))\n",
        "\n",
        "for i in range(len(competition_dataset.stances)):\n",
        "    body_id.append(competition_dataset.stances[i]['Body ID'])\n",
        "    headlines.append(competition_dataset.stances[i]['Headline'])\n",
        "test_data = pd.DataFrame(columns=['Headline', 'Body ID', 'Stance'])\n",
        "test_data['Headline'] = headlines\n",
        "test_data['Body ID'] = body_id\n",
        "test_data['Stance'] = stances\n",
        "print(test_data.head())\n",
        "\n",
        "test_data.to_csv('Random_Forest_M15_N200.csv', index=False, encoding='utf-8')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
            "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    1.7s\n",
            "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    7.8s\n",
            "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed:    8.2s finished\n",
            "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
            "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Score for fold 6 was - 0.7901465096236714\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    1.7s\n",
            "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    7.6s\n",
            "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed:    8.0s finished\n",
            "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
            "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Score for fold 0 was - 0.8303505761215985\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
            "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    1.8s\n",
            "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    7.8s\n",
            "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed:    8.3s finished\n",
            "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
            "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Score for fold 7 was - 0.8164333191910621\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    1.7s\n",
            "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    7.8s\n",
            "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed:    8.2s finished\n",
            "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
            "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Score for fold 5 was - 0.7874815905743741\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    1.7s\n",
            "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    7.8s\n",
            "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed:    8.3s finished\n",
            "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
            "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Score for fold 2 was - 0.8362896190753126\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    1.6s\n",
            "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    7.7s\n",
            "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed:    8.1s finished\n",
            "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
            "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Score for fold 8 was - 0.8440634920634921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    1.7s\n",
            "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    7.7s\n",
            "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed:    8.1s finished\n",
            "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
            "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Score for fold 9 was - 0.8113312866313145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
            "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    1.7s\n",
            "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    7.7s\n",
            "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed:    8.1s finished\n",
            "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
            "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Score for fold 3 was - 0.8345702334367832\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    1.6s\n",
            "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    7.7s\n",
            "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed:    8.1s finished\n",
            "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
            "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Score for fold 1 was - 0.8333566140522419\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    1.6s\n",
            "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    7.6s\n",
            "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed:    8.0s finished\n",
            "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
            "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Score for fold 4 was - 0.8082701387895264\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
            "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    92     |     0     |    613    |    57     |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    12     |     0     |    139    |    11     |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    42     |     0     |   1630    |    128    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |     0     |     0     |    61     |   6837    |\n",
            "-------------------------------------------------------------\n",
            "Score: 3632.75 out of 4448.5\t(81.66235809823536%)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=6)]: Done 200 out of 200 | elapsed:    0.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    96     |     0     |   1599    |    208    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    19     |     0     |    490    |    188    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    104    |     0     |   3868    |    492    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |     2     |     0     |    273    |   18074   |\n",
            "-------------------------------------------------------------\n",
            "Score: 9035.5 out of 11651.25\t(77.5496191395773%)\n",
            "______________________________________________________________________________________________________________________\n",
            "                                            Headline  Body ID     Stance\n",
            "0  Ferguson riots: Pregnant woman loses eye after...     2008  unrelated\n",
            "1  Crazy Conservatives Are Sure a Gitmo Detainee ...     1550  unrelated\n",
            "2  A Russian Guy Says His Justin Bieber Ringtone ...        2  unrelated\n",
            "3  Zombie Cat: Buried Kitty Believed Dead, Meows ...     1793  unrelated\n",
            "4  Argentina's President Adopts Boy to End Werewo...       37  unrelated\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh0HmavfJDe7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comp_test=pd.read_csv('/content/drive/My Drive/641/competition_test_stances.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vJI2N6RoO_1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "5ead081e-72c0-4309-ca8d-e2b1e9901469"
      },
      "source": [
        "comp_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Headline</th>\n",
              "      <th>Body ID</th>\n",
              "      <th>Stance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ferguson riots: Pregnant woman loses eye after...</td>\n",
              "      <td>2008</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crazy Conservatives Are Sure a Gitmo Detainee ...</td>\n",
              "      <td>1550</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A Russian Guy Says His Justin Bieber Ringtone ...</td>\n",
              "      <td>2</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Zombie Cat: Buried Kitty Believed Dead, Meows ...</td>\n",
              "      <td>1793</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Argentina's President Adopts Boy to End Werewo...</td>\n",
              "      <td>37</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25408</th>\n",
              "      <td>The success of the Affordable Care Act is a hu...</td>\n",
              "      <td>2582</td>\n",
              "      <td>agree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25409</th>\n",
              "      <td>The success of the Affordable Care Act is a hu...</td>\n",
              "      <td>2583</td>\n",
              "      <td>discuss</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25410</th>\n",
              "      <td>The success of the Affordable Care Act is a hu...</td>\n",
              "      <td>2584</td>\n",
              "      <td>disagree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25411</th>\n",
              "      <td>The success of the Affordable Care Act is a hu...</td>\n",
              "      <td>2585</td>\n",
              "      <td>disagree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25412</th>\n",
              "      <td>The success of the Affordable Care Act is a hu...</td>\n",
              "      <td>2586</td>\n",
              "      <td>agree</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25413 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Headline  Body ID     Stance\n",
              "0      Ferguson riots: Pregnant woman loses eye after...     2008  unrelated\n",
              "1      Crazy Conservatives Are Sure a Gitmo Detainee ...     1550  unrelated\n",
              "2      A Russian Guy Says His Justin Bieber Ringtone ...        2  unrelated\n",
              "3      Zombie Cat: Buried Kitty Believed Dead, Meows ...     1793  unrelated\n",
              "4      Argentina's President Adopts Boy to End Werewo...       37  unrelated\n",
              "...                                                  ...      ...        ...\n",
              "25408  The success of the Affordable Care Act is a hu...     2582      agree\n",
              "25409  The success of the Affordable Care Act is a hu...     2583    discuss\n",
              "25410  The success of the Affordable Care Act is a hu...     2584   disagree\n",
              "25411  The success of the Affordable Care Act is a hu...     2585   disagree\n",
              "25412  The success of the Affordable Care Act is a hu...     2586      agree\n",
              "\n",
              "[25413 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYHLbVH7oZe1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "7b94e652-9e85-4293-db7c-42a12e2aaffc"
      },
      "source": [
        "#Calculating f1 score of individual stances type(Competition set)\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def calculate_f1scores(y_true, y_predicted):\n",
        "    \n",
        "    f1_macro = f1_score(y_true, y_predicted, average='macro')\n",
        "    f1_classwise = f1_score(y_true, y_predicted, average=None, labels=[\"agree\", \"disagree\", \"discuss\", \"unrelated\"])\n",
        "\n",
        "    result = \"F1 macro: {:.3f}\".format(f1_macro * 100) + \"% \\n\"\n",
        "    result += \"F1 agree: {:.3f}\".format(f1_classwise[0] * 100) + \"% \\n\"\n",
        "    result += \"F1 disagree: {:.3f}\".format(f1_classwise[1] * 100) + \"% \\n\"\n",
        "    result += \"F1 discuss: {:.3f}\".format(f1_classwise[2] * 100) + \"% \\n\"\n",
        "    result += \"F1 unrelated: {:.3f}\".format(f1_classwise[3] * 100) + \"% \\n\"\n",
        "    return result\n",
        "print(calculate_f1scores(predicted,actual))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 44.566% \n",
            "F1 agree: 9.040% \n",
            "F1 disagree: 0.000% \n",
            "F1 discuss: 72.340% \n",
            "F1 unrelated: 96.883% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQTdB4-apF-r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "dae91c78-99b9-4311-9d76-849d0afb29b3"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "eval_report = classification_report(predicted,actual)\n",
        "print('Test report', eval_report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.05      0.43      0.09       221\n",
            "    disagree       0.00      0.00      0.00         0\n",
            "     discuss       0.87      0.62      0.72      6230\n",
            "   unrelated       0.99      0.95      0.97     18962\n",
            "\n",
            "    accuracy                           0.87     25413\n",
            "   macro avg       0.48      0.50      0.45     25413\n",
            "weighted avg       0.95      0.87      0.90     25413\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPfvyjmmuPx5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b69b2441-678a-4009-d238-47139165998c"
      },
      "source": [
        "#General Accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(comp_test['Stance'],predicted)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8671939558493684"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    }
  ]
}