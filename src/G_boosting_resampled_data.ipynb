{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "G_boosting_resampled_data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIBdI8ZdCLtZ",
        "colab_type": "text"
      },
      "source": [
        "### Importing libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxDwUFdVowqN",
        "colab_type": "text"
      },
      "source": [
        "### Reading Resampled train stances "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKDziZErvCNI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "1c6328e5-d302-485a-f5a4-6d8fb703bc84"
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import nltk\n",
        "import os\n",
        "import re\n",
        "_wnl = nltk.WordNetLemmatizer()\n",
        "from tqdm import tqdm\n",
        "import scipy\n",
        "from csv import DictReader\n",
        "import pandas as pd\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "# sklearn dependencies\n",
        "from sklearn import feature_extraction\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn import preprocessing\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function for reading the dataset\n",
        "class DataSet():\n",
        "    def __init__(self, name=\"train\", path=\"/content/drive/My Drive/fnc-1\"):\n",
        "        self.path = path\n",
        "\n",
        "        print(\"Reading dataset\")\n",
        "        bodies = name+\"_bodies.csv\"\n",
        "        if name== 'train':\n",
        "          stances = name+\"_stances_resampled.csv\"  \n",
        "        else:\n",
        "          stances = name+\"_stances.csv\"\n",
        "          \n",
        "        self.stances = self.read(stances)\n",
        "       \n",
        "        articles = self.read(bodies)\n",
        "       \n",
        "        self.articles = dict()\n",
        "\n",
        "        #make the body ID an integer value\n",
        "        for s in self.stances:\n",
        "            s['Body ID'] = int(s['Body ID'])\n",
        "        \n",
        "        #copy all bodies into a dictionary\n",
        "        for article in articles:\n",
        "            self.articles[int(article['Body ID'])] = article['articleBody']\n",
        "\n",
        "        print(\"Total stances: \" + str(len(self.stances)))\n",
        "        print(\"Total bodies: \" + str(len(self.articles)))\n",
        "\n",
        "    \n",
        "\n",
        "    def read(self,filename):\n",
        "        rows = []\n",
        "        with open(self.path + \"/\" + filename, \"r\", encoding='utf-8') as table:\n",
        "            r = DictReader(table)\n",
        "\n",
        "            for line in r:\n",
        "                rows.append(line)\n",
        "        return rows\n"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qijfJB73bRhu",
        "colab_type": "text"
      },
      "source": [
        "### Solving the problem of imbalanced data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Et61kn7bQqU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "2f817b4e-353e-4674-e704-63245f6e1d92"
      },
      "source": [
        "train_stances=pd.read_csv('/content/drive/My Drive/fnc-1/train_stances.csv')\n",
        "train_stances.head()"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Headline</th>\n",
              "      <th>Body ID</th>\n",
              "      <th>Stance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Police find mass graves with at least '15 bodi...</td>\n",
              "      <td>712</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
              "      <td>158</td>\n",
              "      <td>agree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Christian Bale passes on role of Steve Jobs, a...</td>\n",
              "      <td>137</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HBO and Apple in Talks for $15/Month Apple TV ...</td>\n",
              "      <td>1034</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Spider burrowed through tourist's stomach and ...</td>\n",
              "      <td>1923</td>\n",
              "      <td>disagree</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Headline  Body ID     Stance\n",
              "0  Police find mass graves with at least '15 bodi...      712  unrelated\n",
              "1  Hundreds of Palestinians flee floods in Gaza a...      158      agree\n",
              "2  Christian Bale passes on role of Steve Jobs, a...      137  unrelated\n",
              "3  HBO and Apple in Talks for $15/Month Apple TV ...     1034  unrelated\n",
              "4  Spider burrowed through tourist's stomach and ...     1923   disagree"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKWumaHZhJ4b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "da95b2fa-abc3-4ae7-e1c8-0fd89f74a322"
      },
      "source": [
        "print(train_stances.shape)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(49972, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kp19-3PYhUCb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e6b939d8-c0ce-4ea9-f854-2d7ce3a30b3d"
      },
      "source": [
        "print(\"Train Data Distribution: \",collections.Counter(train_stances['Stance']))"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Data Distribution:  Counter({'unrelated': 36545, 'discuss': 8909, 'agree': 3678, 'disagree': 840})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn_CY0E-hUF0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "ffbd07e7-9faf-49fb-e9b9-17dc67d93b56"
      },
      "source": [
        "plt.bar(collections.Counter(train_stances['Stance']).keys(),collections.Counter(train_stances['Stance']).values(),color=[\n",
        "                     'seagreen', 'skyblue','pink','gray'])\n",
        "plt.xlabel(\"Stance\")\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Stance Distribution at Train set')\n",
        "plt.show()"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vkPeaCMhdu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_stances_unrelated=train_stances[train_stances['Stance']=='unrelated']\n",
        "train_stances_agree=train_stances[train_stances['Stance']=='agree']\n",
        "train_stances_disagree=train_stances[train_stances['Stance']=='disagree']\n",
        "train_stances_discuss=train_stances[train_stances['Stance']=='discuss']"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViEqjDKRhdy5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "1cec499e-1d4b-4e41-f6b4-f3f1e0656bc3"
      },
      "source": [
        "print(train_stances_unrelated.shape)\n",
        "print(train_stances_agree.shape)\n",
        "print(train_stances_disagree.shape)\n",
        "print(train_stances_discuss.shape)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(36545, 3)\n",
            "(3678, 3)\n",
            "(840, 3)\n",
            "(8909, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Wgmgmj_lekQ",
        "colab_type": "text"
      },
      "source": [
        "- Total stances: 49972\n",
        "  - unrelated: 73.1%\n",
        "  - agree: 7.3%\n",
        "  - disagree:1.6%\n",
        "  - discuss:17.8%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftYBUAWflln3",
        "colab_type": "text"
      },
      "source": [
        "### Taking 50% of unrelated only | undersampling the abundant class \n",
        "##### https://www.kdnuggets.com/2017/06/7-techniques-handle-imbalanced-data.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_8574OLi3oG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_stances_unrelated=train_stances_unrelated.sample(frac=1).reset_index(drop=True)[0:18272]"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xNjMBK4mH18",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "f6dd85e8-f615-407f-cf49-76b3368237d1"
      },
      "source": [
        "train_stances_unrelated"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Headline</th>\n",
              "      <th>Body ID</th>\n",
              "      <th>Stance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Managua explosion not a meteorite, NASA suggests</td>\n",
              "      <td>1795</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Say 'eh-oh!' to the Teletubbies SUN BABY - can...</td>\n",
              "      <td>470</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Senior Western Intelligence Official Confirms ...</td>\n",
              "      <td>1252</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Christian Bale Is Steve Jobs</td>\n",
              "      <td>1839</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This Man Paid Off His Parents' Mortgage for Ch...</td>\n",
              "      <td>1459</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18267</th>\n",
              "      <td>Everyone chill! Banksy has NOT been arrested</td>\n",
              "      <td>1269</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18268</th>\n",
              "      <td>MPs credit sergeant-at-arms for saving lives i...</td>\n",
              "      <td>2410</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18269</th>\n",
              "      <td>Jordan king cites Clint Eastwood in revenge vow</td>\n",
              "      <td>803</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18270</th>\n",
              "      <td>#Hairgate: iPhone 6 users say device pulls out...</td>\n",
              "      <td>304</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18271</th>\n",
              "      <td>Batmobile stolen in Detroit? Good one, joker!</td>\n",
              "      <td>972</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18272 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Headline  Body ID     Stance\n",
              "0       Managua explosion not a meteorite, NASA suggests     1795  unrelated\n",
              "1      Say 'eh-oh!' to the Teletubbies SUN BABY - can...      470  unrelated\n",
              "2      Senior Western Intelligence Official Confirms ...     1252  unrelated\n",
              "3                           Christian Bale Is Steve Jobs     1839  unrelated\n",
              "4      This Man Paid Off His Parents' Mortgage for Ch...     1459  unrelated\n",
              "...                                                  ...      ...        ...\n",
              "18267       Everyone chill! Banksy has NOT been arrested     1269  unrelated\n",
              "18268  MPs credit sergeant-at-arms for saving lives i...     2410  unrelated\n",
              "18269    Jordan king cites Clint Eastwood in revenge vow      803  unrelated\n",
              "18270  #Hairgate: iPhone 6 users say device pulls out...      304  unrelated\n",
              "18271      Batmobile stolen in Detroit? Good one, joker!      972  unrelated\n",
              "\n",
              "[18272 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_XV_f9emSdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_stances_resampled=pd.concat([train_stances_unrelated,train_stances_agree\n",
        "                                   ,train_stances_disagree,train_stances_discuss],axis=0)"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g20j4NstnCXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_stances_resampled=train_stances_resampled.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDCjzlMaZ8oN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "57845d9f-bf65-4e78-a403-1158545ffd2b"
      },
      "source": [
        "train_stances_resampled"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Headline</th>\n",
              "      <th>Body ID</th>\n",
              "      <th>Stance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Developer quits using the app he was hired to ...</td>\n",
              "      <td>2458</td>\n",
              "      <td>discuss</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Meteorite Strikes Nicaraguan Capital, Creates ...</td>\n",
              "      <td>1073</td>\n",
              "      <td>discuss</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dead for 48 minutes, Catholic Priest claims Go...</td>\n",
              "      <td>2240</td>\n",
              "      <td>agree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Spider burrowed into appendix scar, crawled th...</td>\n",
              "      <td>1848</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Internet Tried To Make Axl Rose Its Latest...</td>\n",
              "      <td>144</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31694</th>\n",
              "      <td>Eyewitness: Viral Video That Netted $130K in D...</td>\n",
              "      <td>1429</td>\n",
              "      <td>discuss</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31695</th>\n",
              "      <td>Banksy arrest hoax: US website claims street a...</td>\n",
              "      <td>1437</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31696</th>\n",
              "      <td>US drones hunt Isis leader in Syria</td>\n",
              "      <td>304</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31697</th>\n",
              "      <td>Soldier shot at war memorial in Canada</td>\n",
              "      <td>892</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31698</th>\n",
              "      <td>KFC Marijuana Sales To Begin In Colorado? It’s...</td>\n",
              "      <td>1933</td>\n",
              "      <td>agree</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31699 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Headline  Body ID     Stance\n",
              "0      Developer quits using the app he was hired to ...     2458    discuss\n",
              "1      Meteorite Strikes Nicaraguan Capital, Creates ...     1073    discuss\n",
              "2      Dead for 48 minutes, Catholic Priest claims Go...     2240      agree\n",
              "3      Spider burrowed into appendix scar, crawled th...     1848  unrelated\n",
              "4      The Internet Tried To Make Axl Rose Its Latest...      144  unrelated\n",
              "...                                                  ...      ...        ...\n",
              "31694  Eyewitness: Viral Video That Netted $130K in D...     1429    discuss\n",
              "31695  Banksy arrest hoax: US website claims street a...     1437  unrelated\n",
              "31696                US drones hunt Isis leader in Syria      304  unrelated\n",
              "31697             Soldier shot at war memorial in Canada      892  unrelated\n",
              "31698  KFC Marijuana Sales To Begin In Colorado? It’s...     1933      agree\n",
              "\n",
              "[31699 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRmFdmwUyio9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_stances_resampled.to_csv('/content/drive/My Drive/fnc-1/train_stances_resampled.csv',index=False)"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SimEgIk-C1H1",
        "colab_type": "text"
      },
      "source": [
        "### Functions to form various features "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXG88TCotLR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature Functions(taken from baseline and added cosine similarity)\n",
        "def normalize_word(w):\n",
        "    return _wnl.lemmatize(w).lower()\n",
        "\n",
        "\n",
        "def get_tokenized_lemmas(s):\n",
        "    return [normalize_word(t) for t in nltk.word_tokenize(s)]\n",
        "\n",
        "\n",
        "def clean(s):\n",
        "    # Cleans a string: Lowercasing, trimming, removing non-alphanumeric\n",
        "\n",
        "    return \" \".join(re.findall(r'\\w+', s, flags=re.UNICODE)).lower()\n",
        "\n",
        "\n",
        "def remove_stopwords(l):\n",
        "    # Removes stopwords from a list of tokens\n",
        "    return [w for w in l if w not in feature_extraction.text.ENGLISH_STOP_WORDS]\n",
        "\n",
        "\n",
        "def gen_or_load_feats(feat_fn, headlines, bodies, feature_file):\n",
        "  # if not os.path.isfile(feature_file):\n",
        "    feats = feat_fn(headlines, bodies)\n",
        "    np.save(feature_file, feats)\n",
        "    return np.load(feature_file)\n",
        "\n",
        "def word_overlap_features(headlines, bodies):\n",
        "    X = []\n",
        "    for i, (headline, body) in tqdm(enumerate(zip(headlines, bodies))):\n",
        "        clean_headline = clean(headline)\n",
        "        clean_body = clean(body)\n",
        "        clean_headline = get_tokenized_lemmas(clean_headline)\n",
        "        clean_body = get_tokenized_lemmas(clean_body)\n",
        "        features = [\n",
        "            len(set(clean_headline).intersection(clean_body)) / float(len(set(clean_headline).union(clean_body)))]\n",
        "        X.append(features)\n",
        "    return X\n",
        "\n",
        "\n",
        "def refuting_features(headlines, bodies):\n",
        "    _refuting_words = [\n",
        "        'fake',\n",
        "        'fraud',\n",
        "        'hoax',\n",
        "        'false',\n",
        "        'deny', 'denies',\n",
        "        # 'refute',\n",
        "        'not',\n",
        "        'despite',\n",
        "        'nope',\n",
        "        'doubt', 'doubts',\n",
        "        'bogus',\n",
        "        'debunk',\n",
        "        'pranks',\n",
        "        'retract'\n",
        "    ]\n",
        "    X = []\n",
        "    for i, (headline, body) in tqdm(enumerate(zip(headlines, bodies))):\n",
        "        clean_headline = clean(headline)\n",
        "        clean_headline = get_tokenized_lemmas(clean_headline)\n",
        "        features = [1 if word in clean_headline else 0 for word in _refuting_words]\n",
        "        X.append(features)\n",
        "    return X\n",
        "\n",
        "\n",
        "def polarity_features(headlines, bodies):\n",
        "    _refuting_words = [\n",
        "        'fake',\n",
        "        'fraud',\n",
        "        'hoax',\n",
        "        'false',\n",
        "        'deny', 'denies',\n",
        "        'not',\n",
        "        'despite',\n",
        "        'nope',\n",
        "        'doubt', 'doubts',\n",
        "        'bogus',\n",
        "        'debunk',\n",
        "        'pranks',\n",
        "        'retract'\n",
        "    ]\n",
        "\n",
        "    def calculate_polarity(text):\n",
        "        tokens = get_tokenized_lemmas(text)\n",
        "        return sum([t in _refuting_words for t in tokens]) % 2\n",
        "    X = []\n",
        "    for i, (headline, body) in tqdm(enumerate(zip(headlines, bodies))):\n",
        "        clean_headline = clean(headline)\n",
        "        clean_body = clean(body)\n",
        "        features = []\n",
        "        features.append(calculate_polarity(clean_headline))\n",
        "        features.append(calculate_polarity(clean_body))\n",
        "        X.append(features)\n",
        "    return np.array(X)\n",
        "\n",
        "\n",
        "def ngrams(input, n):\n",
        "    input = input.split(' ')\n",
        "    output = []\n",
        "    for i in range(len(input) - n + 1):\n",
        "        output.append(input[i:i + n])\n",
        "    return output\n",
        "\n",
        "\n",
        "def chargrams(input, n):\n",
        "    output = []\n",
        "    for i in range(len(input) - n + 1):\n",
        "        output.append(input[i:i + n])\n",
        "    return output\n",
        "\n",
        "\n",
        "def append_chargrams(features, text_headline, text_body, size):\n",
        "    grams = [' '.join(x) for x in chargrams(\" \".join(remove_stopwords(text_headline.split())), size)]\n",
        "    grams_hits = 0\n",
        "    grams_early_hits = 0\n",
        "    grams_first_hits = 0\n",
        "    for gram in grams:\n",
        "        if gram in text_body:\n",
        "            grams_hits += 1\n",
        "        if gram in text_body[:255]:\n",
        "            grams_early_hits += 1\n",
        "        if gram in text_body[:100]:\n",
        "            grams_first_hits += 1\n",
        "    features.append(grams_hits)\n",
        "    features.append(grams_early_hits)\n",
        "    features.append(grams_first_hits)\n",
        "    return features\n",
        "\n",
        "\n",
        "def append_ngrams(features, text_headline, text_body, size):\n",
        "    grams = [' '.join(x) for x in ngrams(text_headline, size)]\n",
        "    grams_hits = 0\n",
        "    grams_early_hits = 0\n",
        "    for gram in grams:\n",
        "        if gram in text_body:\n",
        "            grams_hits += 1\n",
        "        if gram in text_body[:255]:\n",
        "            grams_early_hits += 1\n",
        "    features.append(grams_hits)\n",
        "    features.append(grams_early_hits)\n",
        "    return features\n",
        "\n",
        "def cosine_similarity_h(headlines, bodies):\n",
        "\tvectorizer = TfidfVectorizer(ngram_range=(1,2), lowercase=True, stop_words='english')#, max_features=1024)\n",
        "\n",
        "\tcos_sim_features = []\n",
        "\tfor i in range(0, len(bodies)):\n",
        "\t\tbody_headline = []\n",
        "\t\tbody_headline.append(bodies[i])\n",
        "\t\tbody_headline.append(headlines[i])\n",
        "\t\ttfidf = vectorizer.fit_transform(body_headline)\n",
        "\n",
        "\t\tcosine_similarity = (tfidf * tfidf.T).A\n",
        "\t\tcos_sim_features.append(cosine_similarity[0][1])\n",
        "\n",
        "\t\n",
        "\tcos_sim_array = np.array(cos_sim_features) \n",
        "\n",
        "\treturn cos_sim_array\n",
        "\n",
        "def hand_features(headlines, bodies):\n",
        "\n",
        "    def binary_co_occurence(headline, body):\n",
        "        # Count how many times a token in the title\n",
        "        # appears in the body text.\n",
        "        bin_count = 0\n",
        "        bin_count_early = 0\n",
        "        for headline_token in clean(headline).split(\" \"):\n",
        "            if headline_token in clean(body):\n",
        "                bin_count += 1\n",
        "            if headline_token in clean(body)[:255]:\n",
        "                bin_count_early += 1\n",
        "        return [bin_count, bin_count_early]\n",
        "\n",
        "    def binary_co_occurence_stops(headline, body):\n",
        "        # Count how many times a token in the title\n",
        "        # appears in the body text. Stopwords in the title\n",
        "        # are ignored.\n",
        "        bin_count = 0\n",
        "        bin_count_early = 0\n",
        "        for headline_token in remove_stopwords(clean(headline).split(\" \")):\n",
        "            if headline_token in clean(body):\n",
        "                bin_count += 1\n",
        "                bin_count_early += 1\n",
        "        return [bin_count, bin_count_early]\n",
        "\n",
        "    def count_grams(headline, body):\n",
        "        # Count how many times an n-gram of the title\n",
        "        # appears in the entire body, and intro paragraph\n",
        "\n",
        "        clean_body = clean(body)\n",
        "        clean_headline = clean(headline)\n",
        "        features = []\n",
        "        features = append_chargrams(features, clean_headline, clean_body, 2)\n",
        "        features = append_chargrams(features, clean_headline, clean_body, 8)\n",
        "        features = append_chargrams(features, clean_headline, clean_body, 4)\n",
        "        features = append_chargrams(features, clean_headline, clean_body, 16)\n",
        "        features = append_ngrams(features, clean_headline, clean_body, 2)\n",
        "        features = append_ngrams(features, clean_headline, clean_body, 3)\n",
        "        features = append_ngrams(features, clean_headline, clean_body, 4)\n",
        "        features = append_ngrams(features, clean_headline, clean_body, 5)\n",
        "        features = append_ngrams(features, clean_headline, clean_body, 6)\n",
        "        return features\n",
        "\n",
        "    X = []\n",
        "    for i, (headline, body) in tqdm(enumerate(zip(headlines, bodies))):\n",
        "        X.append(binary_co_occurence(headline, body)\n",
        "                 + binary_co_occurence_stops(headline, body)\n",
        "                 + count_grams(headline, body))\n",
        "\n",
        "\n",
        "    return X\n"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntlcxEiDDLsv",
        "colab_type": "text"
      },
      "source": [
        "### Functions to generate splits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRuNhRARuq3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Functions to generate splits\n",
        "\n",
        "def generate_hold_out_split (dataset, training = 0.8, base_dir=\"/content/drive/My Drive/fnc-1/\"):\n",
        "    r = random.Random()\n",
        "    r.seed(1489215)\n",
        "\n",
        "    article_ids = list(dataset.articles.keys())  # get a list of article ids\n",
        "    r.shuffle(article_ids)  # and shuffle that list\n",
        "\n",
        "\n",
        "    training_ids = article_ids[:int(training * len(article_ids))]\n",
        "    hold_out_ids = article_ids[int(training * len(article_ids)):]\n",
        "\n",
        "    # write the split body ids out to files for future use\n",
        "    with open(base_dir+ \"/\"+ \"training_ids.txt\", \"w+\") as f:\n",
        "        f.write(\"\\n\".join([str(id) for id in training_ids]))\n",
        "\n",
        "    with open(base_dir+ \"/\"+ \"hold_out_ids.txt\", \"w+\") as f:\n",
        "        f.write(\"\\n\".join([str(id) for id in hold_out_ids]))\n",
        "\n",
        "\n",
        "\n",
        "def read_ids(file,base):\n",
        "    ids = []\n",
        "    with open(base+\"/\"+file,\"r\") as f:\n",
        "        for line in f:\n",
        "           ids.append(int(line))\n",
        "        return ids\n",
        "\n",
        "\n",
        "def kfold_split(dataset, training = 0.8, n_folds = 10, base_dir=\"/content/drive/My Drive/fnc-1\"):\n",
        "    if not (os.path.exists(base_dir+ \"/\"+ \"training_ids.txt\")\n",
        "            and os.path.exists(base_dir+ \"/\"+ \"hold_out_ids.txt\")):\n",
        "        generate_hold_out_split(dataset,training,base_dir)\n",
        "\n",
        "    training_ids = read_ids(\"training_ids.txt\", base_dir)\n",
        "    hold_out_ids = read_ids(\"hold_out_ids.txt\", base_dir)\n",
        "\n",
        "    folds = []\n",
        "    for k in range(n_folds):\n",
        "        folds.append(training_ids[int(k*len(training_ids)/n_folds):int((k+1)*len(training_ids)/n_folds)])\n",
        "\n",
        "    return folds,hold_out_ids\n",
        "\n",
        "\n",
        "def get_stances_for_folds(dataset,folds,hold_out):\n",
        "    stances_folds = defaultdict(list)\n",
        "    stances_hold_out = []\n",
        "    for stance in dataset.stances:\n",
        "        if stance['Body ID'] in hold_out:\n",
        "            stances_hold_out.append(stance)\n",
        "        else:\n",
        "            fold_id = 0\n",
        "            for fold in folds:\n",
        "                if stance['Body ID'] in fold:\n",
        "                    stances_folds[fold_id].append(stance)\n",
        "                fold_id += 1\n",
        "\n",
        "    return stances_folds,stances_hold_out\n"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1-wXahADS4t",
        "colab_type": "text"
      },
      "source": [
        "### Functions to generate the score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctcVfMkpvN7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Score functions\n",
        "LABELS = ['agree', 'disagree', 'discuss', 'unrelated']\n",
        "LABELS_RELATED = ['unrelated','related']\n",
        "RELATED = LABELS[0:3]\n",
        "\n",
        "def score_submission(gold_labels, test_labels):\n",
        "    score = 0.0\n",
        "    cm = [[0, 0, 0, 0],\n",
        "          [0, 0, 0, 0],\n",
        "          [0, 0, 0, 0],\n",
        "          [0, 0, 0, 0]]\n",
        "\n",
        "    for i, (g, t) in enumerate(zip(gold_labels, test_labels)):\n",
        "        g_stance, t_stance = g, t\n",
        "        if g_stance == t_stance:\n",
        "            score += 0.25\n",
        "            if g_stance != 'unrelated':\n",
        "                score += 0.50\n",
        "        if g_stance in RELATED and t_stance in RELATED:\n",
        "            score += 0.25\n",
        "\n",
        "        cm[LABELS.index(g_stance)][LABELS.index(t_stance)] += 1\n",
        "\n",
        "    return score, cm\n",
        "\n",
        "# function for printing confusion Matrix\n",
        "def print_confusion_matrix(cm):\n",
        "    lines = []\n",
        "    header = \"|{:^11}|{:^11}|{:^11}|{:^11}|{:^11}|\".format('', *LABELS)\n",
        "    line_len = len(header)\n",
        "    lines.append(\"-\"*line_len)\n",
        "    lines.append(header)\n",
        "    lines.append(\"-\"*line_len)\n",
        "\n",
        "    hit = 0\n",
        "    total = 0\n",
        "    for i, row in enumerate(cm):\n",
        "        hit += row[i]\n",
        "        total += sum(row)\n",
        "        lines.append(\"|{:^11}|{:^11}|{:^11}|{:^11}|{:^11}|\".format(LABELS[i],\n",
        "                                                                   *row))\n",
        "        lines.append(\"-\"*line_len)\n",
        "    print('\\n'.join(lines))\n",
        "\n",
        "\n",
        "def report_score(actual,predicted):\n",
        "    score,cm = score_submission(actual,predicted)\n",
        "    best_score, _ = score_submission(actual,actual)\n",
        "\n",
        "    print_confusion_matrix(cm)\n",
        "    print(\"Score: \" +str(score) + \" out of \" + str(best_score) + \"\\t(\"+str(score*100/best_score) + \"%)\")\n",
        "    return score*100/best_score\n",
        "\n",
        "\n"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTtqx_CJDi0B",
        "colab_type": "text"
      },
      "source": [
        "### Generating Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjdeIHR5vclZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916
        },
        "outputId": "553acd2b-f953-4651-c602-156469bb7590"
      },
      "source": [
        "\n",
        "\n",
        "def generate_features(stances,dataset,name):\n",
        "    h, b, y = [],[],[]\n",
        "\n",
        "    for stance in stances:\n",
        "        y.append(LABELS.index(stance['Stance']))\n",
        "        h.append(stance['Headline'])\n",
        "        b.append(dataset.articles[stance['Body ID']])\n",
        "\n",
        "    X_overlap = gen_or_load_feats(word_overlap_features, h, b, \"overlap.\"+name+\".npy\")\n",
        "    X_refuting = gen_or_load_feats(refuting_features, h, b, \"refuting.\"+name+\".npy\")\n",
        "    X_polarity = gen_or_load_feats(polarity_features, h, b, \"polarity.\"+name+\".npy\")\n",
        "    X_hand = gen_or_load_feats(hand_features, h, b, \"hand.\"+name+\".npy\")\n",
        "    X_cosine=gen_or_load_feats(cosine_similarity_h,h,b,\"cosine.\"+name+\".npy\")\n",
        "\n",
        "    X = np.c_[X_hand, X_polarity, X_refuting, X_overlap,X_cosine]\n",
        "    X = preprocessing.scale(X)\n",
        "    return X,y\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "#Load the training dataset and generate folds\n",
        "d = DataSet()\n",
        "folds,hold_out = kfold_split(d,n_folds=10)\n",
        "fold_stances, hold_out_stances = get_stances_for_folds(d,folds,hold_out)\n",
        "\n",
        "# Load the competition dataset\n",
        "competition_dataset = DataSet(\"competition_test\")\n",
        "X_competition, y_competition = generate_features(competition_dataset.stances, competition_dataset, \"competition\")\n",
        "    \n",
        "  \n",
        "Xs = dict()\n",
        "ys = dict()\n",
        "\n",
        "# Load/Precompute all features now\n",
        "X_holdout,y_holdout = generate_features(hold_out_stances,d,\"holdout\")\n",
        "for fold in fold_stances:\n",
        "    Xs[fold],ys[fold] = generate_features(fold_stances[fold],d,str(fold))\n",
        "\n",
        "\n",
        "best_score = 0\n",
        "best_fold = None\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "# print(predicted)\n",
        "\n",
        "\n"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading dataset\n",
            "Total stances: 31699\n",
            "Total bodies: 1683\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Reading dataset\n",
            "Total stances: 25413\n",
            "Total bodies: 904\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25413it [01:28, 287.29it/s]\n",
            "25413it [00:05, 4888.25it/s]\n",
            "25413it [01:29, 282.58it/s]\n",
            "25413it [01:34, 268.84it/s]\n",
            "6143it [00:22, 273.35it/s]\n",
            "6143it [00:01, 4867.26it/s]\n",
            "6143it [00:22, 267.55it/s]\n",
            "6143it [00:24, 248.77it/s]\n",
            "2528it [00:09, 273.12it/s]\n",
            "2528it [00:00, 5009.29it/s]\n",
            "2528it [00:09, 266.10it/s]\n",
            "2528it [00:09, 254.88it/s]\n",
            "2847it [00:10, 271.88it/s]\n",
            "2847it [00:00, 5141.40it/s]\n",
            "2847it [00:10, 261.60it/s]\n",
            "2847it [00:11, 250.97it/s]\n",
            "2959it [00:11, 266.81it/s]\n",
            "2959it [00:00, 4875.83it/s]\n",
            "2959it [00:11, 261.51it/s]\n",
            "2959it [00:11, 246.65it/s]\n",
            "2395it [00:09, 265.98it/s]\n",
            "2395it [00:00, 4997.53it/s]\n",
            "2395it [00:09, 259.93it/s]\n",
            "2395it [00:09, 246.33it/s]\n",
            "2498it [00:08, 281.75it/s]\n",
            "2498it [00:00, 5014.32it/s]\n",
            "2498it [00:08, 288.82it/s]\n",
            "2498it [00:09, 266.00it/s]\n",
            "2603it [00:09, 284.38it/s]\n",
            "2603it [00:00, 5102.10it/s]\n",
            "2603it [00:09, 280.17it/s]\n",
            "2603it [00:09, 266.45it/s]\n",
            "2499it [00:09, 257.39it/s]\n",
            "2499it [00:00, 5176.26it/s]\n",
            "2499it [00:09, 251.62it/s]\n",
            "2499it [00:10, 239.72it/s]\n",
            "2530it [00:09, 274.74it/s]\n",
            "2530it [00:00, 5036.70it/s]\n",
            "2530it [00:09, 270.45it/s]\n",
            "2530it [00:09, 253.61it/s]\n",
            "2275it [00:08, 265.48it/s]\n",
            "2275it [00:00, 5059.58it/s]\n",
            "2275it [00:08, 262.24it/s]\n",
            "2275it [00:09, 245.33it/s]\n",
            "2422it [00:07, 306.24it/s]\n",
            "2422it [00:00, 5090.73it/s]\n",
            "2422it [00:08, 297.51it/s]\n",
            "2422it [00:08, 279.30it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngEaQBn2Pzcj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "32cd5b9d-ef62-400d-9480-cab40a5b73fb"
      },
      "source": [
        "# Classifier for each fold\n",
        "for fold in fold_stances:\n",
        "    ids = list(range(len(folds)))\n",
        "    del ids[fold]\n",
        "\n",
        "    X_train = np.vstack(tuple([Xs[i] for i in ids]))\n",
        "    y_train = np.hstack(tuple([ys[i] for i in ids]))\n",
        "\n",
        "    X_test = Xs[fold]\n",
        "    y_test = ys[fold]\n",
        "            \n",
        "            \n",
        "    gradientboosting = GradientBoostingClassifier( n_estimators=100, random_state=42,verbose=True,subsample=0.9)\n",
        "    gradientboosting.fit(X_train, y_train)\n",
        "            \n",
        "              \n",
        "    predicted = [LABELS[int(a)] for a in gradientboosting.predict(X_test)]   \n",
        "          \n",
        "            \n",
        "    actual = [LABELS[int(a)] for a in y_test]\n",
        "\n",
        "    fold_score, _ = score_submission(actual, predicted)\n",
        "    max_fold_score, _ = score_submission(actual, actual)\n",
        "\n",
        "    score = fold_score/max_fold_score\n",
        "\n",
        "    print(\"Score for fold \"+ str(fold) + \" was - \" + str(score))\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_fold = gradientboosting\n",
        "\n",
        "\n",
        "\n",
        "#Run on Holdout set and report the final score on the holdout set\n",
        "predicted = [LABELS[int(a)] for a in best_fold.predict(X_holdout)]\n",
        "    \n",
        "    \n",
        "actual = [LABELS[int(a)] for a in y_holdout]\n",
        "\n",
        "    \n",
        "report_score(actual,predicted)\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "#Run on competition dataset\n",
        "   \n",
        "predicted = [LABELS[int(a)] for a in best_fold.predict(X_competition)]\n",
        "actual = [LABELS[int(a)] for a in y_competition]\n",
        "    \n",
        "    \n",
        "a=report_score(actual,predicted)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss      OOB Improve   Remaining Time \n",
            "         1       18685.0352         264.6474           32.22s\n",
            "         2       16929.2196         197.1368           31.59s\n",
            "         3       15569.1233         147.4879           31.70s\n",
            "         4       14478.9138         118.4680           31.18s\n",
            "         5       13562.1310          98.3605           30.57s\n",
            "         6       12778.9238          81.1998           30.26s\n",
            "         7       12209.8036          64.6610           29.97s\n",
            "         8       11703.1468          54.7491           29.80s\n",
            "         9       11288.3237          46.3221           29.61s\n",
            "        10       10923.6287          38.9961           29.43s\n",
            "        20        9122.5592           7.5908           25.94s\n",
            "        30        8575.7122           2.8342           22.59s\n",
            "        40        8253.7819           0.3899           19.28s\n",
            "        50        8125.1535          -0.0561           15.99s\n",
            "        60        8012.6254          -0.0954           12.76s\n",
            "        70        7761.4553          -0.6123            9.55s\n",
            "        80        7645.8474          -0.4157            6.36s\n",
            "        90        7638.1982          -0.3529            3.18s\n",
            "       100        7475.5433          -0.5701            0.00s\n",
            "Score for fold 6 was - 0.7409616101379053\n",
            "      Iter       Train Loss      OOB Improve   Remaining Time \n",
            "         1       18619.5007         253.2856           31.26s\n",
            "         2       16843.2450         190.6008           30.56s\n",
            "         3       15500.9038         144.5075           30.06s\n",
            "         4       14459.2478         116.1055           29.92s\n",
            "         5       13554.2442          95.2831           29.68s\n",
            "         6       12850.0174          77.9039           29.28s\n",
            "         7       12224.9544          65.5217           28.86s\n",
            "         8       11726.1952          53.6327           28.61s\n",
            "         9       11341.8711          46.1812           28.34s\n",
            "        10       10903.9417          36.9731           27.98s\n",
            "        20        9161.3202           9.4376           24.59s\n",
            "        30        8549.2828           3.8671           21.53s\n",
            "        40        8298.6159           1.0029           18.61s\n",
            "        50        8048.5473           0.0688           15.52s\n",
            "        60        7894.3623           0.4053           12.43s\n",
            "        70        7751.1720           0.1634            9.32s\n",
            "        80        7691.0576          -0.2177            6.21s\n",
            "        90        7523.4770          -0.0527            3.11s\n",
            "       100        7455.5993          -0.4668            0.00s\n",
            "Score for fold 8 was - 0.807502467917078\n",
            "      Iter       Train Loss      OOB Improve   Remaining Time \n",
            "         1       18511.6058         252.1691           30.66s\n",
            "         2       16815.3432         183.8272           30.43s\n",
            "         3       15458.6885         142.8856           29.89s\n",
            "         4       14294.9684         118.4387           29.70s\n",
            "         5       13425.1806          93.5681           29.36s\n",
            "         6       12704.3753          77.7704           29.07s\n",
            "         7       12158.2170          64.3563           28.86s\n",
            "         8       11666.5748          55.2394           28.54s\n",
            "         9       11296.4775          45.6248           28.21s\n",
            "        10       10823.9462          36.2568           27.89s\n",
            "        20        9044.6169           8.3790           24.52s\n",
            "        30        8518.4278           2.8528           21.48s\n",
            "        40        8227.7949           0.4659           18.50s\n",
            "        50        8027.1956          -0.0096           15.55s\n",
            "        60        7829.1756           0.3323           12.45s\n",
            "        70        7765.4025          -0.0036            9.34s\n",
            "        80        7722.5299          -0.4321            6.23s\n",
            "        90        7534.6632           0.0121            3.12s\n",
            "       100        7470.7282          -0.3480            0.00s\n",
            "Score for fold 0 was - 0.7984195847536412\n",
            "      Iter       Train Loss      OOB Improve   Remaining Time \n",
            "         1       18865.8732         259.7070           30.79s\n",
            "         2       17059.4056         192.3072           30.46s\n",
            "         3       15682.8818         149.9245           30.76s\n",
            "         4       14601.2704         118.9003           30.42s\n",
            "         5       13739.0465          99.1324           30.12s\n",
            "         6       12971.0486          79.7592           29.96s\n",
            "         7       12358.1248          67.9449           29.75s\n",
            "         8       11820.7131          55.4528           29.46s\n",
            "         9       11402.0075          45.1989           29.21s\n",
            "        10       11013.9361          38.6761           28.87s\n",
            "        20        9255.0844           9.1081           25.29s\n",
            "        30        8662.5629           3.2171           22.28s\n",
            "        40        8302.2631           0.9189           19.22s\n",
            "        50        8209.3346           0.4072           16.18s\n",
            "        60        7947.7826          -0.3567           13.04s\n",
            "        70        7907.8437           0.2413            9.83s\n",
            "        80        7737.3457          -0.3256            6.57s\n",
            "        90        7666.2454          -0.4460            3.29s\n",
            "       100        7555.4347          -0.2701            0.00s\n",
            "Score for fold 2 was - 0.8120447681648606\n",
            "      Iter       Train Loss      OOB Improve   Remaining Time \n",
            "         1       18767.2625         257.6246           33.87s\n",
            "         2       16984.2230         191.4256           33.24s\n",
            "         3       15732.1611         147.8826           32.62s\n",
            "         4       14526.8828         118.8950           32.20s\n",
            "         5       13682.5503          97.3539           31.60s\n",
            "         6       12890.7082          78.5623           30.96s\n",
            "         7       12352.4930          65.6639           30.58s\n",
            "         8       11850.9451          55.6801           30.16s\n",
            "         9       11400.3778          45.0602           29.67s\n",
            "        10       10975.2926          37.9680           29.24s\n",
            "        20        9237.7148           8.1377           25.44s\n",
            "        30        8636.2921           2.9002           22.12s\n",
            "        40        8333.8892           0.5451           18.98s\n",
            "        50        8141.6389           0.3848           15.85s\n",
            "        60        7995.9246          -0.2005           12.71s\n",
            "        70        7940.8654          -0.1333            9.55s\n",
            "        80        7751.1009          -0.5907            6.36s\n",
            "        90        7702.0265           0.3806            3.18s\n",
            "       100        7539.6983          -0.5103            0.00s\n",
            "Score for fold 4 was - 0.7759336099585062\n",
            "      Iter       Train Loss      OOB Improve   Remaining Time \n",
            "         1       18714.7124         251.9106           32.23s\n",
            "         2       16950.4846         187.9041           31.26s\n",
            "         3       15618.7252         150.2752           30.88s\n",
            "         4       14491.3152         119.8587           30.53s\n",
            "         5       13628.3427          95.0356           30.10s\n",
            "         6       12944.0138          77.9778           29.73s\n",
            "         7       12284.3390          66.8184           29.38s\n",
            "         8       11776.6743          55.7420           28.99s\n",
            "         9       11329.4141          45.5760           28.61s\n",
            "        10       10971.5265          37.9090           28.39s\n",
            "        20        9202.8195           7.2980           25.04s\n",
            "        30        8594.4177           3.2639           21.88s\n",
            "        40        8288.9854           0.2707           18.74s\n",
            "        50        8057.8526           0.1590           15.62s\n",
            "        60        7916.7619          -0.6175           12.53s\n",
            "        70        7827.7400          -0.0714            9.42s\n",
            "        80        7702.8818          -0.7012            6.28s\n",
            "        90        7623.2209          -0.7734            3.14s\n",
            "       100        7564.7006          -0.8324            0.00s\n",
            "Score for fold 3 was - 0.7974220519073332\n",
            "      Iter       Train Loss      OOB Improve   Remaining Time \n",
            "         1       18697.3666         259.6386           30.99s\n",
            "         2       16899.9804         185.5014           30.57s\n",
            "         3       15534.8230         148.6186           30.44s\n",
            "         4       14473.0482         119.7223           30.36s\n",
            "         5       13628.8500          96.6773           29.98s\n",
            "         6       12880.1449          77.8580           29.63s\n",
            "         7       12247.8664          66.0551           29.40s\n",
            "         8       11714.6635          54.1787           29.12s\n",
            "         9       11332.0610          46.3349           28.85s\n",
            "        10       10960.7469          37.7788           28.61s\n",
            "        20        9130.1954           8.6602           25.29s\n",
            "        30        8542.0729           2.0016           22.15s\n",
            "        40        8261.7552           1.6967           18.97s\n",
            "        50        8080.0820           0.2946           15.90s\n",
            "        60        7973.3587           0.0588           12.73s\n",
            "        70        7870.9807           0.0125            9.56s\n",
            "        80        7718.4736          -0.3449            6.37s\n",
            "        90        7671.4962          -0.5606            3.18s\n",
            "       100        7506.7638          -0.6193            0.00s\n",
            "Score for fold 9 was - 0.7804710331786144\n",
            "      Iter       Train Loss      OOB Improve   Remaining Time \n",
            "         1       18692.1232         252.5569           31.27s\n",
            "         2       16966.0692         191.3334           30.82s\n",
            "         3       15649.3425         149.5454           31.06s\n",
            "         4       14561.3081         117.1631           30.64s\n",
            "         5       13661.6667          97.1407           30.25s\n",
            "         6       12914.2773          80.1672           29.92s\n",
            "         7       12356.8705          65.5883           29.67s\n",
            "         8       11753.5500          54.3564           29.28s\n",
            "         9       11422.2433          46.7191           29.10s\n",
            "        10       10998.4423          37.8954           28.78s\n",
            "        20        9259.5120           8.3446           25.31s\n",
            "        30        8621.4031           3.1200           22.01s\n",
            "        40        8352.5331           1.5274           18.95s\n",
            "        50        8095.3618           0.6404           15.80s\n",
            "        60        7986.2308          -0.0761           12.68s\n",
            "        70        7807.1418          -0.0593            9.50s\n",
            "        80        7687.0135          -0.5643            6.33s\n",
            "        90        7612.7017          -0.2202            3.16s\n",
            "       100        7563.6379           0.0605            0.00s\n",
            "Score for fold 1 was - 0.7978761061946903\n",
            "      Iter       Train Loss      OOB Improve   Remaining Time \n",
            "         1       18741.1064         263.0572           31.82s\n",
            "         2       17013.1647         193.2325           32.05s\n",
            "         3       15583.3850         154.9383           31.35s\n",
            "         4       14449.1750         125.0117           30.97s\n",
            "         5       13594.1364          98.4979           30.72s\n",
            "         6       12838.9674          80.7447           30.28s\n",
            "         7       12186.3935          64.2831           29.93s\n",
            "         8       11693.3821          57.5302           29.69s\n",
            "         9       11223.7723          45.2746           29.31s\n",
            "        10       10863.7721          38.7781           28.93s\n",
            "        20        9005.3080           7.4859           25.52s\n",
            "        30        8464.7057           1.9212           22.26s\n",
            "        40        8146.5585           1.1431           19.07s\n",
            "        50        7964.5083           0.1134           15.94s\n",
            "        60        7811.9598           0.0399           12.77s\n",
            "        70        7728.5801          -0.4566            9.58s\n",
            "        80        7582.0076           0.0583            6.40s\n",
            "        90        7503.6112          -0.3436            3.20s\n",
            "       100        7431.2469          -0.5322            0.00s\n",
            "Score for fold 5 was - 0.7546239210850801\n",
            "      Iter       Train Loss      OOB Improve   Remaining Time \n",
            "         1       18793.9400         262.8706           31.44s\n",
            "         2       16978.2799         194.0599           30.91s\n",
            "         3       15577.5890         149.7517           30.47s\n",
            "         4       14515.1966         120.9764           30.09s\n",
            "         5       13583.1267          98.3968           29.80s\n",
            "         6       12875.0789          79.0574           29.57s\n",
            "         7       12250.8505          67.7863           29.34s\n",
            "         8       11660.6422          56.0693           29.04s\n",
            "         9       11260.1321          46.1744           28.66s\n",
            "        10       10961.3300          38.3012           28.32s\n",
            "        20        9147.6468           7.5781           25.01s\n",
            "        30        8533.7920           2.6103           21.89s\n",
            "        40        8177.3655           1.1805           18.81s\n",
            "        50        7984.0355           0.2032           15.70s\n",
            "        60        7841.0165           0.1790           12.58s\n",
            "        70        7788.0740           0.0126            9.43s\n",
            "        80        7674.2084           0.0377            6.30s\n",
            "        90        7554.6805           0.1161            3.17s\n",
            "       100        7389.1698           0.0531            0.00s\n",
            "Score for fold 7 was - 0.7968476357267951\n",
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    103    |     4     |    618    |    37     |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    14     |     2     |    143    |     3     |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    60     |     4     |   1641    |    95     |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |     2     |     2     |    51     |   3364    |\n",
            "-------------------------------------------------------------\n",
            "Score: 2797.75 out of 3578.75\t(78.17673768774013%)\n",
            "\n",
            "\n",
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    269    |     9     |   1533    |    92     |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    93     |     6     |    521    |    77     |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    328    |    11     |   3952    |    173    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |    68     |     8     |    948    |   17325   |\n",
            "-------------------------------------------------------------\n",
            "Score: 9182.0 out of 11651.25\t(78.80699495762258%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZRdgLDIn_ZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "data = {'Iterations':  [1, 2,3,4,5,6,7,8,9,10,20,30,40,50,60,70,80,90,100],\n",
        "        'Loss': [22194.4070,19779.9174,17959.4557,16603.5056,15511.8594, 14602.8131,13910.4883,13208.1117,12633.8252,12271.9072,10183.7280,9568.5745,9206.9733,9001.6804,8825.1934,\n",
        "                8716.2480, 8578.4964,8487.2534,8403.3948],\n",
        "        \n",
        "        }\n",
        "df_bert = pd.DataFrame (data, columns = ['Iterations','Loss'])"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAQYg3Iepj_2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "c6c954fe-2976-4aff-ccf5-4a1ec0f467c9"
      },
      "source": [
        "# Plotting train loss vs Iterations\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(df_bert['Loss'])\n",
        "plt.xlabel('Iterations')\n",
        "plt.xticks([1,3,5,7,9,11,13,15,17,20])\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train Loss')\n",
        "plt.legend(['Training Loss'])\n",
        "plt.savefig('Gradient_loss.png')\n",
        "plt.show()"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEWCAYAAABbgYH9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXwV1f3/8dcnOwmEBAiLCbKJIIuyRMQV3BBbK7baSouKPxfUat3aunXR2vZbl1atdd+qVetSV/x+BQSroljQoOxrBJQgSyAsYQ/J5/fHndArBkhC7p0s7+fjMY/MPTNnzmfMJR9n5sw55u6IiIjUtYSwAxARkcZJCUZERGJCCUZERGJCCUZERGJCCUZERGJCCUZERGJCCUYkhsxsnJmNDjsOkTCY3oMR+SYz2xz1MR3YAZQHny9z9+fjFMcy4BJ3nxSP9kTqWlLYAYjUN+7evHJ9X3/kzSzJ3XfFMzaRhkS3yESqycyGmlmRmd1oZquAv5tZtpn9r5kVm9n6YD0vqs77ZnZJsH6hmX1kZn8O9l1qZqfXIo5UM7vPzL4OlvvMLDXY1iaIYYOZlZjZh2aWEGy70cxWmFmpmS00s5Pr6D+NSJWUYERqpj3QCugEjCHyb+jvweeDgW3AA/uofxSwEGgD3AU8aWZWwxh+BQwG+gFHAIOAXwfbfg4UATlAO+AWwM2sB3AVcKS7twBOA5bVsF2RGlGCEamZCuBWd9/h7tvcfZ27v+ruW929FPgjMGQf9b9098fdvRx4BuhAJBHUxCjgdndf4+7FwO+A84NtZcExO7l7mbt/6JEHreVAKtDLzJLdfZm7f1HDdkVqRAlGpGaK3X175QczSzezR83sSzPbBEwGsswscS/1V1WuuPvWYLX5Xvbdm4OAL6M+fxmUAdwNFALvmNkSM7spaKsQuBa4DVhjZi+a2UGIxJASjEjN7Nnt8udAD+Aod88ETgjKa3rbqya+JnJLrtLBQRnuXuruP3f3rsCZwPWVz1rc/Z/uflxQ14E7YxijiBKMyAFqQeS5ywYzawXcWsfHTzaztKglCXgB+LWZ5ZhZG+C3wHMAZnaGmR0SPNfZSOTWWIWZ9TCzk4LOANuDmCvqOFaRb1CCETkw9wHNgLXAVGB8HR//bSLJoHK5DfgDUADMAmYDnwVlAN2BScBm4D/AQ+7+HpHnL3cEca4C2gI313GsIt+gFy1FRCQmdAUjIiIxoQQjIiIxoQQjIiIxoQQjIiIx0eQGu2zTpo137tw57DBERBqU6dOnr3X3nJrUaXIJpnPnzhQUFIQdhohIg2JmX+5/r2/SLTIREYkJJRgREYkJJRgREYmJJvcMRkTql7KyMoqKiti+ffv+d5aYS0tLIy8vj+Tk5AM+lhKMiISqqKiIFi1a0LlzZ2o+95rUJXdn3bp1FBUV0aVLlwM+nm6RiUiotm/fTuvWrZVc6gEzo3Xr1nV2NakEIyKhU3KpP+ryd6EEUw3vLVzDEx8uCTsMEZEGJWYJxsw6mtl7ZjbPzOaa2TVB+d1mtsDMZpnZ62aWFVXnZjMrNLOFZnZaVPnwoKywcgrYoLyLmU0Lyl8ys5RYnMvEeau5a/xC1pTqIaRIY7Nu3Tr69etHv379aN++Pbm5ubs/79y5c591CwoKuPrqq/fbxjHHHFMnsb7//vucccYZdXKseIjlFcwu4Ofu3gsYDFxpZr2AiUAfdz8cWEQw6VGwbSTQGxgOPGRmicHc5g8CpwO9gB8H+0Jkytd73f0QYD1wcSxO5NLju1JWUcHfpyyLxeFFJEStW7dmxowZzJgxg8svv5zrrrtu9+eUlBR27dq117r5+fncf//9+23j448/rsuQG4yYJRh3X+nunwXrpcB8INfd33H3yt/YVCAvWB8BvOjuO9x9KVAIDAqWQndf4u47gReBEcGUsCcBrwT1nwHOisW5dGmTwel92vPc1C8p3V4WiyZEpB658MILufzyyznqqKO44YYb+OSTTzj66KPp378/xxxzDAsXLgS+eUVx2223cdFFFzF06FC6du36jcTTvHnz3fsPHTqUc845h549ezJq1CgqJ318++236dmzJwMHDuTqq6+u0ZXKCy+8QN++fenTpw833ngjAOXl5Vx44YX06dOHvn37cu+99wJw//3306tXLw4//HBGjhx54P+x9iEu3ZTNrDPQH5i2x6aLgJeC9VwiCadSUVAGsHyP8qOA1sCGqGQVvf+e7Y8BxgAcfPDBtTkFLjuhG2/PXsULn3zFmBO61eoYIrJvv3trLvO+3lSnx+x1UCa3fq93jesVFRXx8ccfk5iYyKZNm/jwww9JSkpi0qRJ3HLLLbz66qvfqrNgwQLee+89SktL6dGjB1dcccW33if5/PPPmTt3LgcddBDHHnssU6ZMIT8/n8suu4zJkyfTpUsXfvzjH1c7zq+//pobb7yR6dOnk52dzbBhw3jjjTfo2LEjK1asYM6cOQBs2LABgDvuuIOlS5eSmpq6uyxWYv6Q38yaA68C17r7pqjyXxG5jfZ8rGNw98fcPd/d83NyajQY6G5HdMzi6K6tefKjpezcVVHHEYpIffPDH/6QxMREADZu3MgPf/hD+vTpw3XXXcfcuXOrrPPd736X1NRU2rRpQ9u2bVm9evW39hk0aBB5eXkkJCTQr18/li1bxoIFC+jatevud09qkmA+/fRThg4dSk5ODklJSYwaNYrJkyfTtWtXlixZws9+9jPGjx9PZmYmAIcffjijRo3iueeeIykpttcYMT26mSUTSS7Pu/trUeUXAmcAJ3vl9SGsADpGVc8LythL+Togy8ySgquY6P1j4rIhXbnw75/yxowV/Ci/4/4riEiN1OZKI1YyMjJ2r//mN7/hxBNP5PXXX2fZsmUMHTq0yjqpqam71xMTE6t8flOdfepCdnY2M2fOZMKECTzyyCO8/PLLPPXUU/zf//0fkydP5q233uKPf/wjs2fPjlmiiWUvMgOeBOa7+z1R5cOBG4Az3X1rVJWxwEgzSzWzLkB34BPgU6B70GMshUhHgLFBYnoPOCeoPxp4M1bnAzDk0Bx6tm/BY5OXUFHh+68gIo3Cxo0byc2N3IF/+umn6/z4PXr0YMmSJSxbtgyAl156ad8VogwaNIgPPviAtWvXUl5ezgsvvMCQIUNYu3YtFRUVnH322fzhD3/gs88+o6KiguXLl3PiiSdy5513snHjRjZv3lzn51MplrfIjgXOB04ysxnB8h3gAaAFMDEoewTA3ecCLwPzgPHAle5eHlydXAVMINJR4OVgX4AbgevNrJDIM5knY3g+mBmXD+lG4ZrNvLtgTSybEpF65IYbbuDmm2+mf//+MbniaNasGQ899BDDhw9n4MCBtGjRgpYtW1a577vvvkteXt7uZdmyZdxxxx2ceOKJHHHEEQwcOJARI0awYsUKhg4dSr9+/TjvvPP405/+RHl5Oeeddx59+/alf//+XH311WRlZVXZTl2w/96hahry8/P9QCYcKyuvYOjd79OhZRqvXFE3fdtFmrL58+dz2GGHhR1G6DZv3kzz5s1xd6688kq6d+/OddddF0osVf1OzGy6u+fX5Dh6k7+GkhMTuOT4LhR8uZ6CZSVhhyMijcTjjz9Ov3796N27Nxs3buSyyy4LO6QDpgRTC+ce2ZGs9GQe+UDDx4hI3ah8wXPevHk8//zzpKenhx3SAVOCqYX0lCQuOLozk+avpnBNadjhiDR4Te1WfX1Wl78LJZhaGn10J9KSE3hUVzEiByQtLY1169YpydQDlfPBpKWl1cnxNOFYLbVunsqP8jvywidf8fNhPWjfsm5+ISJNTV5eHkVFRRQXF4cdivDfGS3rghLMAbj0+K48N/VLnpqylFu+o14wIrWRnJxcJ7MnSv2jW2QHoGOrdL57+EH8c9pXbNymQTBFRKIpwRygy07oyuYdu3h+2pdhhyIiUq8owRygPrktOb57G/4+ZRnby8rDDkdEpN5QgqkDlw/pRnHpDl7/PKZjbYqINChKMHXgmG6t6ZObyeOTl1CuQTBFRAAlmDpROQjmkrVbmDhvVdjhiIjUC0owdWR47/Yc3Cqdhz9YohfGRERQgqkzSYkJXHpCV2Yu38C0pRoEU0RECaYO/XBgHq0zUnj0gy/CDkVEJHRKMHUoLTmRC4/pzHsLi1mwalPY4YiIhEoJpo6df3Qn0lMSeUyDYIpIE6cEU8ey0lMYeeTBjJ35NSs2bAs7HBGR0CjBxMDFx0cG7nvyw6UhRyIiEh4lmBjIzWrGmUccxIuffsWGrTvDDkdEJBQxSzBm1tHM3jOzeWY218yuCcpbmdlEM1sc/MwOys3M7jezQjObZWYDoo41Oth/sZmNjiofaGazgzr3m5nF6nxqasyQrmzdWc6z/9EgmCLSNMXyCmYX8HN37wUMBq40s17ATcC77t4deDf4DHA60D1YxgAPQyQhAbcCRwGDgFsrk1Kwz6VR9YbH8HxqpGf7TE7skcPTH2sQTBFpmmKWYNx9pbt/FqyXAvOBXGAE8Eyw2zPAWcH6COAfHjEVyDKzDsBpwER3L3H39cBEYHiwLdPdp3rk1fl/RB2rXrh8SDfWbdnJv6YXhR2KiEjcxeUZjJl1BvoD04B27r4y2LQKaBes5wLLo6oVBWX7Ki+qoryq9seYWYGZFcRzWtZBXVrRr2OWBsEUkSYp5gnGzJoDrwLXuvs33j4Mrjxi/pfX3R9z93x3z8/JyYl1c7tVDoL5VclWxs1Zuf8KIiKNSEwTjJklE0kuz7v7a0Hx6uD2FsHPNUH5CqBjVPW8oGxf5XlVlNcrp/ZqR9c2GTz43he6ihGRJiWWvcgMeBKY7+73RG0aC1T2BBsNvBlVfkHQm2wwsDG4lTYBGGZm2cHD/WHAhGDbJjMbHLR1QdSx6o3EBOPaUw9l/spN/FPTKotIExLLK5hjgfOBk8xsRrB8B7gDONXMFgOnBJ8B3gaWAIXA48BPAdy9BPg98Gmw3B6UEezzRFDnC2BcDM+n1r53eAeOPaQ1d01YyJrS7WGHIyISF9bU5i7Jz8/3goKCuLe7pHgzw+/7kO/0bc99I/vHvX0RkQNhZtPdPb8mdfQmf5x0zWnO5UO68saMr/m4cG3Y4YiIxJwSTBz99MRDOLhVOr9+cw47dunlSxFp3JRg4igtOZHbR/RmSfEWHp+s4fxFpHFTgomzoT3a8t2+Hfjbvwv5at3WsMMREYkZJZgQ/OaMXiQlGL8dO4em1slCRJoOJZgQtG+ZxvXDevD+wmLGz1kVdjgiIjGhBBOS0Ud3oleHTH731jw279gVdjgiInVOCSYkSYkJ/OH7fVhdup37Ji4KOxwRkTqnBBOiAQdnM/LIg/n7x8uY9/Wm/VcQEWlAlGBCduPwHmQ1S+bXb8ymQoNhikgjogQTsqz0FG75zmF89tUGXipYvv8KIiINhBJMPfCDAbkc1aUVd4xbwLrNO8IOR0SkTijB1ANmxh/O6sOWHbv407gFYYcjIlInlGDqie7tWnDpCV15ZXoRnywt2X8FEZF6TgmmHrn6pO7kZjXj12/MZueuirDDERE5IEow9UizlMhgmItWb+bJj5aGHY6IyAFRgqlnTj6sHcN6teP+dxdTtF6DYYpIw6UEUw/demZvAG4bOy/kSEREak8Jph7KzWrGtad0Z9L81UyctzrscEREaiVmCcbMnjKzNWY2J6qsn5lNNbMZZlZgZoOCcjOz+82s0MxmmdmAqDqjzWxxsIyOKh9oZrODOvebmcXqXMJw0XFd6NGuBbeNncvWnRoMU0QanlhewTwNDN+j7C7gd+7eD/ht8BngdKB7sIwBHgYws1bArcBRwCDgVjPLDuo8DFwaVW/Pthq05GAwzBUbtnH/u4VhhyMiUmMxSzDuPhnY84UOBzKD9ZbA18H6COAfHjEVyDKzDsBpwER3L3H39cBEYHiwLdPdp3pkxq5/AGfF6lzCcmTnVvwoP48nPlzCwlWlYYcjIlIj8X4Gcy1wt5ktB/4M3ByU5wLRA3EVBWX7Ki+qorxKZjYmuCVXUFxcfMAnEU83nX4YzdOSuOX12ZSV690YEWk44p1grgCuc/eOwHXAk/Fo1N0fc/d8d8/PycmJR5N1plVGCr87szfTv1zP7W+pV5mINBzxTjCjgdeC9X8Rea4CsALoGLVfXlC2r/K8KsobpRH9crnshK48O/VLnpv6ZdjhiIhUS7wTzNfAkGD9JGBxsD4WuCDoTTYY2OjuK4EJwDAzyw4e7g8DJgTbNpnZ4KD32AXAm3E9kzi7YXhPTurZltvGzuU/X6wLOxwRkf2KZTflF4D/AD3MrMjMLibS6+svZjYT+B8iPcYA3gaWAIXA48BPAdy9BPg98Gmw3B6UEezzRFDnC2BcrM6lPkhMMP46sh+d22RwxfPT+Wqd3vIXkfrNIp2wmo78/HwvKCgIO4xaW7Z2CyMenEK7zFReveIYWqQlhx2SiDQBZjbd3fNrUkdv8jcwndtk8PCoAXxRvIXrXppBuaZZFpF6SgmmATrmkDbc+r1eTJq/hj+/szDscEREqpQUdgBSO+cP7sSCVaU8/P4X9GjXgrP67/U1IBGRUOgKpoEyM353Zm+O6tKKG16dxedfrQ87JBGRb1CCacCSExN4+LyBtMtM5bJnp7Nq4/awQxIR2U0JpoFrlZHCExccyZYduxjzbAHby8rDDklEBFCCaRR6tG/BfSP7M3vFRn75yiyaWtdzEamflGAaiVN7teMXw3rw1syveej9L8IOR0REvcgak58O7cai1aXcPWEh3ds2Z1jv9mGHJCJNmK5gGhEz486zD+eIvJZc+9IMFqzaFHZIItKEKcE0MmnJiTx6fj7NU5O45JkC1m3eEXZIItJEKcE0Qu1bpvHYBfmsKd3BFc9/xs5dmqhMROJPCaaR6tcxi7vPOZxPlpZw69i56lkmInGnh/yN2Ih+ubuHk+nZvgWjj+kcdkgi0oQowTRyvxzWg8WrN3PbW3NplpLIj/I77r+SiEgd0C2yRi4hwXjgJ/057pA23PDKLP457auwQxKRJkIJpglIS07k8QvyOalnW255fTbPfLws7JBEpAlQgmki0pITeeS8gQzr1Y5bx87liQ+XhB2SiDRySjBNSEpSAg+OGsB3+3bgD/83n4feLww7JBFpxPSQv4lJTkzgryP7kZRo3DV+IWW7nGtO6R52WCLSCMXsCsbMnjKzNWY2Z4/yn5nZAjOba2Z3RZXfbGaFZrbQzE6LKh8elBWa2U1R5V3MbFpQ/pKZpcTqXBqbpMQE7vlRP34wIJd7Jy3iL+8s1HsyIlLnYnmL7GlgeHSBmZ0IjACOcPfewJ+D8l7ASKB3UOchM0s0s0TgQeB0oBfw42BfgDuBe939EGA9cHEMz6XRSUww/nzOEYw8siN/+3chd4xfoCQjInUqZrfI3H2ymXXeo/gK4A533xHssyYoHwG8GJQvNbNCYFCwrdDdlwCY2YvACDObD5wE/CTY5xngNuDh2JxN45SQYPzP9/uSnJjAox8soWyX85szDsPMwg5NRBqBeD/kPxQ4Pri19YGZHRmU5wLLo/YrCsr2Vt4a2ODuu/Yor5KZjTGzAjMrKC4urqNTaRwSEozbR/Tm/x3bmaemLOW3b86lokJXMiJy4OL9kD8JaAUMBo4EXjazrrFu1N0fAx4DyM/P11/PPZgZvz2jFymJCTw6eQm7Kir441l9SUjQlYyI1F61EoyZZQDb3L3CzA4FegLj3L2shu0VAa955Gb/J2ZWAbQBVgDRY5jkBWXspXwdkGVmScFVTPT+Ugtmxk2n9yQ5MYEH3iukrNy58+zDSVSSEZFaqu4tsslAmpnlAu8A5xN5iF9TbwAnAgSJKgVYC4wFRppZqpl1AboDnwCfAt2DHmMpRDoCjA0S1HvAOcFxRwNv1iIeiWJm/OK0Hlx3yqG8Mr2I61+ewa5yDfUvIrVT3Vtk5u5bzexi4CF3v8vMZuyzgtkLwFCgjZkVAbcCTwFPBV2XdwKjg2Qx18xeBuYBu4Ar3b08OM5VwAQgEXjK3ecGTdwIvGhmfwA+B56s9lnLPl1zSneSEo27JyxkV7lz38h+JCfqnVwRqZlqJxgzOxoYxX+7Ayfuq4K7/3gvm87by/5/BP5YRfnbwNtVlC/hvz3NpI5deeIhpCQm8Me351NWXsEDPxlASpKSjIhUX3X/YlwL3Ay87u5zgwfz78UuLKkPLj2hK7d9rxfvzFvNmGcL2Lxj1/4riYgErKYv15lZAtDc3TfFJqTYys/P94KCgrDDaFD+Oe0rfvPmHLrlZPD4Bfl0ap0RdkgiEmdmNt3d82tSp1pXMGb2TzPLDHqTzQHmmdkvaxOkNDw/Oepgnvl/g1i9aQdnPjCFjxavDTskEWkAqnuLrFdwxXIWMA7oQqQnmTQRx3Vvw9irjqVdZioXPDWNJz9aqqFlRGSfqptgks0smUiCGRu8/6K/Lk1Mp9YZvPbTYzm1Vzt+/7/z+MW/ZrG9rDzssESknqpugnkUWAZkAJPNrBPQIJ/ByIFpnprEw6MGcs3J3Xn1syJGPjaV1Zu2hx2WiNRDNX7Iv7vif9+ib1D0kL/ujJ+zkutfnknz1CQePX8g/Q/ODjskEYmRWD7kb2lm91QOGGlmfyFyNSNN2PA+HXjtp8eQmpzAuY9O5ZXpRWGHJCL1SHVvkT0FlAI/CpZNwN9jFZQ0HD3bZzL2yuPI75zNL/41k9vfmqfhZUQEqH6C6ebut7r7kmD5HRDzUZClYcjOSOGZiwZx4TGRIf8v/PunbNi6M+ywRCRk1U0w28zsuMoPZnYssC02IUlDlJyYwG1n9uausw/nk6UlnPnAFBatLg07LBEJUXUTzOXAg2a2zMyWAQ8Al8UsKmmwfnRkR14YM5itO8v5/oNTmDB3VdghiUhIqpVg3H2mux8BHA4c7u79iUxZLPItAztl89bPjqVb2+Zc9ux0/jppsWbJFGmCajQ8rrtvihqD7PoYxCONRIeWzXj5sqP5fv9c7p20iMufm86aUr0vI9KUHMj465rqUPYpLTmRe350BL/+7mG8v7CYk//yAc9O/VJXMyJNxIEkGP2VkP0yMy45vivjrj2evrkt+c0bc/jBwx8z9+uNYYcmIjG2zwRjZqVmtqmKpRQ4KE4xSiPQLac5z19yFPeeewTLS7Zy5gNT+MP/zmOL5pgRabT2OaOlu7eIVyDS+JkZ3++fx0k92nHH+AU88dFS/m/2Sm47szen9W4fdngiUsc0B67EXcv0ZP70g768esXRtGyWzGXPTueSZwooWr817NBEpA4pwUhoBnZqxVs/O45bvtOTKYVrOfWeyTw2+QvKNNSMSKMQswRjZk+Z2Rozm1PFtp+bmZtZm+Czmdn9ZlZoZrPMbEDUvqPNbHGwjI4qH2hms4M695uZerU1QMmJCYw5oRsTrz+BYw9pzf+8vYDv/e0jpn+5PuzQROQAxfIK5mlg+J6FZtYRGAZ8FVV8OtA9WMYADwf7tgJuBY4CBgG3mlnlmPAPA5dG1ftWW9Jw5GWn8/gF+Tx6/kA2bivj7Ic/5ubXZrNxa1nYoYlILcUswbj7ZKCkik33AjfwzW7OI4B/eMRUIMvMOgCnARPdvcTd1wMTgeHBtkx3n+qRCW3+QWS2TWnAzIzTerdn0vVDuOS4LrxcsJyT73mfNz5foemZRRqguD6DMbMRwAp3n7nHplxgedTnoqBsX+VFVZTvrd0xlXPZFBcXH8AZSDxkpCbx6zN6MfaqY8nNTufal2Zw3pPTWLp2S9ihiUgNxC3BmFk6cAvw23i1WcndH3P3fHfPz8nJiXfzUku9D2rJa1ccw+/P6sOs5Rs57b7J/O3dxezcpU4AIg1BPK9gugFdgJnBiMx5wGdm1h5YAXSM2jcvKNtXeV4V5dLIJCYY5w/uxLs/H8Kph7XjLxMX8d37P6RgWVV3X0WkPolbgnH32e7e1t07u3tnIre1Brj7KmAscEHQm2wwsNHdVwITgGFmlh083B8GTAi2bTKzwUHvsQuAN+N1LhJ/bTPTeHDUAJ66MJ+tO8s555H/qBOASD0Xy27KLwD/AXqYWZGZXbyP3d8GlgCFwOPATwHcvQT4PfBpsNwelBHs80RQ5wtgXCzOQ+qXk3q2453rTuDS47vw0qdfcfI9H/DWzK/VCUCkHrKm9g8zPz/fCwoKwg5D6sCcFRu5+bXZzF6xkaE9cvj9iD50bJUedlgijZKZTXf3/JrU0Zv80mD1yW3JG1cey2/P6MUnS0sYdm9kJIBdGglApF5QgpEGLTHBuOi4Lky6fgjHHtImMhLAA1OYuXxD2KGJNHlKMNIoHJTVjMcvGMgj5w2gZMsOznpoCreNnctmTQcgEholGGk0zIzhfTow8fohnD+4E8/8Zxmn/OUDJsxdFXZoIk2SEow0Oplpydw+og+vXnEMWen/nQ5g0erSsEMTaVKUYKTRGnBwNm/97DhuOr0nU5es47T7JnPti59ryBmROFE3ZWkS1m/ZyaOTl/DMx8vYWV7B2QNy+dlJ3dWtWaSaatNNWQlGmpTi0h08/P4XPDftS9ydc4/syFUndqd9y7SwQxOp15RgqkEJRgBWbtzGg+8V8tKnyzEzzjuqE1cM7UZOi9SwQxOpl5RgqkEJRqItL9nK/e8u5rXPV5CSmMCFx3ZmzPFdyc5ICTs0kXpFCaYalGCkKkuKN/PXdxczdubXZKQkcdFxXbjk+C5kpiWHHZpIvaAEUw1KMLIvi1aXcu/ERYybs4qWzZIZc0JXLjymMxmpSWGHJhIqJZhqUIKR6pizYiP3TlzEuwvW0DojhUuO78qZ/Q4iN6tZ2KGJhEIJphqUYKQmPv9qPfdMXMSHi9cCcEReS4b36cDpfdrTuU1GyNGJxI8STDUowUhtLF27hfFzVjF+zkpmFm0EoGf7FpzepwOn921P97bNicx9J9I4KcFUgxKMHKgVG7btTjYFX67HHbrmZDC8d3tO79OBPrmZSjbS6CjBVIMSjNSlNaXbmTB3NePnrGTqkhLKK5y87GaRZNO3Pf07ZpOQoGQjDZ8STDUowUisrN+yk4nzVzN+zio+WryWneUVtMtM5bTe7fnBgDz6dcwKO0SRWlOCqQYlGGZINiMAABMUSURBVImHTdvLeG/BGsbNXsX7i9ZQVu6Mu+Z4Dm3XIuzQRGqlXk2ZbGZPmdkaM5sTVXa3mS0ws1lm9rqZZUVtu9nMCs1soZmdFlU+PCgrNLObosq7mNm0oPwlM9Or11JvZKYlM6JfLo+cP5ApN55EenIid41fGHZYInEVy+H6nwaG71E2Eejj7ocDi4CbAcysFzAS6B3UecjMEs0sEXgQOB3oBfw42BfgTuBedz8EWA9cHMNzEam11s1TuXxoNybNX03BspKwwxGJm5glGHefDJTsUfaOu1fOYTsVyAvWRwAvuvsOd18KFAKDgqXQ3Ze4+07gRWCERbronAS8EtR/BjgrVucicqD+37GdyWmRyp3jF9DUbktL0xXmhGMXAeOC9VxgedS2oqBsb+WtgQ1RyaqyvEpmNsbMCsysoLi4uI7CF6m+9JQkrjm5O58uW8+/F6wJOxyRuAglwZjZr4BdwPPxaM/dH3P3fHfPz8nJiUeTIt9y7pEd6dImg7vGL6S8Qlcx0vjFPcGY2YXAGcAo/++9ghVAx6jd8oKyvZWvA7LMLGmPcpF6KzkxgZ8PO5SFq0t543N9XaXxi2uCMbPhwA3Ame6+NWrTWGCkmaWaWRegO/AJ8CnQPegxlkKkI8DYIDG9B5wT1B8NvBmv8xCpre/06UDf3JbcM3ERO3aVhx2OSEzFspvyC8B/gB5mVmRmFwMPAC2AiWY2w8weAXD3ucDLwDxgPHClu5cHz1iuAiYA84GXg30BbgSuN7NCIs9knozVuYjUlYQE48bhPVmxYRvPTf0q7HBEYkovWoqE4LwnpjFv5SY++OVQWmhSM2kA6tWLliKydzcO70nJlp08PnlJ2KGIxIwSjEgI+ua15LuHd+CJj5ZSXLoj7HBEYkIJRiQkvxjWg527KvjbvxeHHYpITCjBiISkS5sMzj2yI/+c9hVfrtsSdjgidU4JRiRE15zcneTEBP7yzqKwQxGpc0owIiFqm5nGRcd1ZuzMr5mzYmPY4YjUKSUYkZBdNqQbWenJ3DVBw/lL46IEIxKyzLRkrhx6CJMXFfPxF2vDDkekzijBiNQD5x/diYNapnHn+IUazl8aDSUYkXogLTmRa089lJnLNzB+zqqwwxGpE0owIvXE2QPy6N62OXe/s5Bd5RVhhyNywJRgROqJxATjl6f1YEnxFv41vSjscEQOmBKMSD1yaq92DOyUzX2TFrFtp4bzl4ZNCUakHjGLDOe/etMOnv54WdjhiBwQJRiRemZQl1ac1LMtD79fyMatZWGHI1JrSjAi9dANw3tQumMXD31QGHYoIrWmBCNSD/Vsn8n3++Xy9JRlrNy4LexwRGpFCUaknrru1ENxh79O0nD+0jApwYjUUx1bpTNq8MG8XLCcwjWbww5HpMaUYETqsatOPIT0lCTuHL+AigoNISMNS8wSjJk9ZWZrzGxOVFkrM5toZouDn9lBuZnZ/WZWaGazzGxAVJ3Rwf6LzWx0VPlAM5sd1LnfzCxW5yISltbNU7liaDcmzlvNiAenaDBMaVBieQXzNDB8j7KbgHfdvTvwbvAZ4HSge7CMAR6GSEICbgWOAgYBt1YmpWCfS6Pq7dmWSKNwxZBu3HvuEZRs2clPHp/GRU9/yqLVpWGHJbJfMUsw7j4ZKNmjeATwTLD+DHBWVPk/PGIqkGVmHYDTgInuXuLu64GJwPBgW6a7T/XI0LP/iDqWSKOSkGB8v38e7/58CDed3pNPl5Uw/L7J3PTqLNZs2h52eCJ7Fe9nMO3cfWWwvgpoF6znAsuj9isKyvZVXlRFeZXMbIyZFZhZQXFx8YGdgUhI0pITuXxINz745YmMPqYzr35WxJC73+eeiYvYsmNX2OGJfEtoD/mDK4+4PLV098fcPd/d83NycuLRpEjMtMpI4dbv9WbS9UM4qWdb7n93MUPufp/np32pUZilXol3glkd3N4i+LkmKF8BdIzaLy8o21d5XhXlIk1Gp9YZPDhqAK//9Bi6tEnnV6/PYfhfP2TSvNWatEzqhXgnmLFAZU+w0cCbUeUXBL3JBgMbg1tpE4BhZpYdPNwfBkwItm0ys8FB77ELoo4l0qT0Pzibly87mkfPH0hFhXPJPwoY+dhUZhVtCDs0aeJi2U35BeA/QA8zKzKzi4E7gFPNbDFwSvAZ4G1gCVAIPA78FMDdS4DfA58Gy+1BGcE+TwR1vgDGxepcROo7M+O03u2ZcN0J/H5EbwrXbObMB6Zw9Qufs7xka9jhSRNlTe1SOj8/3wsKCsIOQySmSreX8egHS3jioyVUVMCowQdz9oA8eh+UiV4Zk9ows+nunl+jOkowIo3Xyo3buOedRbz2+QrKK5y87GYM792e0/u2p3/HbBISlGykepRgqkEJRpqiki07mTRvNePmrOSjwrWUlTvtMlM5rXd7hvduz6AurUhK1MhRsndKMNWgBCNN3abtZfx7/hrGzVnJB4uK2V5WQauMFE49rB3D+7bn2G5tSElSspFvUoKpBiUYkf/aunMXHywsZtycVfx7wRo279hFi7QkTjmsHaf1bs+QQ3NolpIYdphSDyjBVIMSjEjVtpeVM6VwLePmrGLivNVs3FZGs+RETuyZw6m92tE3N4subTJI1HObJqk2CSYpVsGISMOSlpzIyYe14+TD2lFWXsG0JSWMm7OSCXNX8/bsVcE+CfRo14LDOmTuXnp2aEFmWnLI0Ut9pCsYEdmn8gpn/spNwVIa+blqExu2lu3eJy+72e6E06tDJAF1zE5XL7VGRFcwIlLnEhOMPrkt6ZPbcneZu7Nq0/bdSWdekIAmzV9N5f+zNk9Nokf7FhwWJJxDcprTrW1zWmek6F2cJkJXMCJSZ7btLGfh6tKoK55IAtocNdpzVnoy3XKaBwknI7Letjl52el6vlOP6QpGRELVLCWRfh2z6Ncxa3eZu7NiwzYK12zmi+ItfFG8mcI1m3l3wWpeKti5e7+UpAS6tokknG5tm9MtJ1jPaa6ebA2UEoyIxJSZkZedTl52OkN7fHPbhq07+aJ4M1+s2UJh8Wa+WLOZuV9vZNyclVRE3Vw5qGUabTPTaNsilbaZqbRt8e311s1TdQVUzyjBiEhostJTGNipFQM7tfpG+faycr5ct3X31c6ytVtYU7qDZeu28Mmykm90MKiUYNC6eWok8bQIEk9msJ6ZRm5WMzpmp5PZLEnPgOJECUZE6p205ER6tG9Bj/Ytqty+Y1c5xaU7WFO6gzWbdlBcun33+ppgfc7Xm1i3ecc3roQg0vkgL7sZuVnNIj+zmwVXWJGyVuqEUGeUYESkwUlNStx9221fyiucdZt3sHrTDlZs2ErR+m27lxUbtvHJshJKt39zuulmyYlB0qlMQukclJVGm+aptMpIoXVGCtkZKSRr7Lb9UoIRkUYrMcEiz24y0+ib17LKfTZuK2PF+m0Urd/Kig1B8lm/jaINW5m5fAPrq7gdB5CZlkSrjJRgSaV1RgqtmkcSUKsgCVWut85IbZIdFZRgRKRJa9ksmZbNkul1UGaV2zfv2MXKDdtYt2UnJVt2Rn5u3knJlh2UbC2jZMsOitZvZVbRBkq27GTXnvfkAqlJCbTKSCErPYXs9GSy01PISk/eZ1lmWsN+XqQEIyKyD81Tk+jergXdq7Gvu7Np+y5KtkQS0LrNkaRUsnUnG7aWUbJlJxu27mT91rLdoyFs2LrzW8+JKiUmGFnNkslKT+b+H/en90FVX4XVV0owIiJ1xMx2XxF1aZNRrToVFc6m7WWs31rG+q2RBFSypSxIRJFktGHrzgY53psSjIhIiBISjKz0yC2xLlQvKTUU6gYhIiIxEUqCMbPrzGyumc0xsxfMLM3MupjZNDMrNLOXzCwl2Dc1+FwYbO8cdZybg/KFZnZaGOciIiJVi3uCMbNc4Gog3937AInASOBO4F53PwRYD1wcVLkYWB+U3xvsh5n1Cur1BoYDD5lZ0+sHKCJST4V1iywJaGZmSUA6sBI4CXgl2P4McFawPiL4TLD9ZIv02xsBvOjuO9x9KVAIDIpT/CIish9xTzDuvgL4M/AVkcSyEZgObHD3yldqi4DcYD0XWB7U3RXs3zq6vIo632BmY8yswMwKiouL6/aERESkSmHcIssmcvXRBTgIyCByiytm3P0xd8939/ycnJxYNiUiIoEwbpGdAix192J3LwNeA44FsoJbZgB5wIpgfQXQESDY3hJYF11eRR0REQlZGAnmK2CwmaUHz1JOBuYB7wHnBPuMBt4M1scGnwm2/9sj03COBUYGvcy6AN2BT+J0DiIish+hTJlsZr8DzgV2AZ8DlxB5fvIi0CooO8/dd5hZGvAs0B8oAUa6+5LgOL8CLgqOc627j6tG28XAl3V+UvvXBlgbQrtqX+2rfbVfF3q4e9XzJ+xFKAmmKTKzgprOZ6321b7aV/v1RW3OQW/yi4hITCjBiIhITCjBxM9jal/tq32134DV+Bz0DEZERGJCVzAiIhITSjAiIhITSjAxZmZPmdkaM5sTUvtpZvaJmc0Mpkj4XQgxLDOz2WY2w8wK4tx2j6DdymWTmV0b5xiuCaammBuPtqv6zpnZD4P2K8wspt1l99L+781sVvA7eMfMDopz+7eZ2Yqo78F34tz+S1FtLzOzGbFq/0CZWUcze8/M5gXfmWuC8lZmNtHMFgc/s/d7MHfXEsMFOAEYAMwJqX0DmgfrycA0YHCcY1gGtKkHv4tEYBXQKY5t9gHmEBk1PAmYBBwS4za/9Z0DDgN6AO8TmSoj3u1nRq1fDTwS5/ZvA34Rp9/5Pv/NA38BfhuPWGoZfwdgQLDeAlgE9ALuAm4Kym8C7tzfsXQFE2PuPpnICARhte/uvjn4mBwsTbVnx8nAF+4ez5EcDgOmuftWj4wG/gHwg1g2WNV3zt3nu/vCWLa7n/Y3RX3MIIbfwXrwb26v7QfDY/0IeCGuQdWAu69098+C9VJgPpGRVqKnTomeUmWvlGCaADNLDC7J1wAT3X1anENw4B0zm25mY+LcdrSRxP8f9hzgeDNrbWbpwHf45iCtTYaZ/dHMlgOjgN+GEMJVwW26p6p1eyc2jgdWu/vikNqvkWAG4f5E7ny0c/eVwaZVQLv91VeCaQLcvdzd+xEZcXqQmfWJcwjHufsA4HTgSjM7Ic7tE0zBfSbwr3i26+7ziczC+g4wHpgBlMczhvrC3X/l7h2B54Gr4tz8w0A3oB+Reaj+Euf2K/2Yenz1Es3MmgOvEhnnMfoKFI/cJ9vvVagSTBPi7huIjFod0/l3qmh3RfBzDfA64cw8ejrwmbuvjnfD7v6kuw909xOITAe+KN4x1DPPA2fHs0F3Xx38j1YF8DghfAeD6UZ+ALwU77ZrysySiSSX5939taB4tZl1CLZ3IHJHZJ+UYBo5M8sxs6xgvRlwKrAgju1nmFmLynVgGJHbRvEW2v85mlnb4OfBRP7A/DOMOMJkZt2jPo4gjt/BoP0OUR+/TzjfwVOABe5eFELb1RY8J3oSmO/u90Rtip46JXpKlb0Lu8dCY1+I/FFbCZQRmdb54ji3fziR6Q9mEflHFdfeK0BXYGawzAV+FcLvIIPIJHUtQ/oOfEhkzqOZwMlxaO9b3zkif1SLgB3AamBCnNt/Nfj+zQLeAnLj3P6zwOyg/bFAh3i2H5Q/DVwexnewhvEfR+T21ywit3RnEHl22Bp4F1hMpDdkq/0dS0PFiIhITOgWmYiIxIQSjIiIxIQSjIiIxIQSjIiIxIQSjIiIxIQSjEgNmNnm4GdnM/tJHR/7lj0+f1yXxxeJNyUYkdrpDNQowQRvcu/LNxKMux9Tw5hE6hUlGJHauYPIIJYzzOy6YEDRu83s02BAxcsAzGyomX1oZmOJvGyJmb0RDPw5t3LwTzO7A2gWHO/5oKzyasmCY88J5tU5N+rY75vZK2a2wMyeD97CxszuCObzmGVmf477fx0RIvNTiEjN3URkfpEzAIJEsdHdjzSzVGCKmb0T7DsA6OPuS4PPF7l7STB0z6dm9qq732RmV3lkUNI9/YDIII1HAG2COpODbf2B3sDXwBTgWDObT+TN/Z7u7pVDBYnEm65gROrGMOCCYFqEaUSG1agcf+uTqOQCcLWZzQSmEhm6vzv7dhzwgkcGa1xNZE6ZI6OOXeSRQRxnELl1txHYDjxpZj8Ath7w2YnUghKMSN0w4Gfu3i9Yurh75RXMlt07mQ0lMujh0e5+BJFx4tIOoN0dUevlQJJHJjYbBLwCnEFkmgCRuFOCEamdUiLTyVaaAFwRDHOOmR0ajB69p5bAenffamY9gcFR28oq6+/hQ+Dc4DlPDpEpeT/ZW2DBPB4t3f1t4Doit9ZE4k7PYERqZxZQHtzqehr4K5HbU58FD9qLqXpK2fHA5cFzkoVEbpNVegyYZWafufuoqPLXgaOJjMbswA3uvipIUFVpAbxpZmlErqyur90pihwYjaYsIiIxoVtkIiISE0owIiISE0owIiISE0owIiISE0owIiISE0owIiISE0owIiISE/8fl938anUc1CAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVSj0M3ms5dg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comp_test=pd.read_csv('/content/drive/My Drive/fnc-1/competition_test_stances.csv')"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLlbonFrsRnp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "ab7f8298-d3f7-4698-9c29-042d6f7583fa"
      },
      "source": [
        "#General Loss\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(comp_test['Stance'],predicted)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8480698854916775"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHhexcLk6p3v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "6d808028-149f-4455-ad0e-34ebb8553a8f"
      },
      "source": [
        "#Generating answers.csv\n",
        "body_id = []\n",
        "headlines = []\n",
        "stances = np.copy(np.array(predicted))\n",
        "\n",
        "for i in range(len(competition_dataset.stances)):\n",
        "    body_id.append(competition_dataset.stances[i]['Body ID'])\n",
        "    headlines.append(competition_dataset.stances[i]['Headline'])\n",
        "test_data = pd.DataFrame(columns=['Headline', 'Body ID', 'Stance'])\n",
        "test_data['Headline'] = headlines\n",
        "test_data['Body ID'] = body_id\n",
        "test_data['Stance'] = stances\n",
        "print(test_data.head())\n",
        "\n",
        "test_data.to_csv('gradientboost_100.csv', index=False, encoding='utf-8')\n"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                            Headline  Body ID     Stance\n",
            "0  Ferguson riots: Pregnant woman loses eye after...     2008  unrelated\n",
            "1  Crazy Conservatives Are Sure a Gitmo Detainee ...     1550  unrelated\n",
            "2  A Russian Guy Says His Justin Bieber Ringtone ...        2  unrelated\n",
            "3  Zombie Cat: Buried Kitty Believed Dead, Meows ...     1793  unrelated\n",
            "4  Argentina's President Adopts Boy to End Werewo...       37  unrelated\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFB-fXWMQqwn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "73beb3f7-4a6f-4b95-c80c-77a476d3f53b"
      },
      "source": [
        "#Calculating f1 score of individual stances type(Competition set)\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def calculate_f1scores(y_true, y_predicted):\n",
        "    \n",
        "    f1_macro = f1_score(y_true, y_predicted, average='macro')\n",
        "    f1_classwise = f1_score(y_true, y_predicted, average=None, labels=[\"agree\", \"disagree\", \"discuss\", \"unrelated\"])\n",
        "\n",
        "    result = \"F1 macro: {:.3f}\".format(f1_macro * 100) + \"% \\n\"\n",
        "    result += \"F1 agree: {:.3f}\".format(f1_classwise[0] * 100) + \"% \\n\"\n",
        "    result += \"F1 disagree: {:.3f}\".format(f1_classwise[1] * 100) + \"% \\n\"\n",
        "    result += \"F1 discuss: {:.3f}\".format(f1_classwise[2] * 100) + \"% \\n\"\n",
        "    result += \"F1 unrelated: {:.3f}\".format(f1_classwise[3] * 100) + \"% \\n\"\n",
        "    return result\n",
        "print(calculate_f1scores(predicted,actual))"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 46.823% \n",
            "F1 agree: 20.218% \n",
            "F1 disagree: 1.642% \n",
            "F1 discuss: 69.224% \n",
            "F1 unrelated: 96.207% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmQT6ieurblj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "3061403d-38b0-4982-d510-cba18b471c78"
      },
      "source": [
        "# calculating precision,recall,f1-score,support for Competition set\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "eval_report = classification_report(predicted,actual)\n",
        "print('Test report', eval_report)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.14      0.35      0.20       758\n",
            "    disagree       0.01      0.18      0.02        34\n",
            "     discuss       0.89      0.57      0.69      6954\n",
            "   unrelated       0.94      0.98      0.96     17667\n",
            "\n",
            "    accuracy                           0.85     25413\n",
            "   macro avg       0.49      0.52      0.47     25413\n",
            "weighted avg       0.90      0.85      0.86     25413\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}