{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exploratory_analysis_and_metrics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJU2LUKTYt5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z9ptcywXfWX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "89d6da26-de11-448a-ab01-c5ea8659157e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Vp4oawva6bS",
        "colab_type": "text"
      },
      "source": [
        "### Importing predicted test data csv's"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5Al8Zbsa1DT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_50=pd.read_csv('/content/drive/My Drive/fnc-1/cnn_50.csv')\n",
        "cnn_100=pd.read_csv('/content/drive/My Drive/fnc-1/cnn_100.csv')\n",
        "cnn_150=pd.read_csv('/content/drive/My Drive/fnc-1/cnn_150.csv')\n",
        "\n",
        "lstm_50=pd.read_csv('/content/drive/My Drive/fnc-1/lstm_50.csv')\n",
        "lstm_100=pd.read_csv('/content/drive/My Drive/fnc-1/lstm_100.csv')\n",
        "lstm_150=pd.read_csv('/content/drive/My Drive/fnc-1/lstm_150.csv')\n",
        "\n",
        "bi_lstm_50=pd.read_csv('/content/drive/My Drive/fnc-1/bi_lstm_50.csv')\n",
        "bi_lstm_100=pd.read_csv('/content/drive/My Drive/fnc-1/bi_lstm_100.csv')\n",
        "bi_lstm_150=pd.read_csv('/content/drive/My Drive/fnc-1/bi_lstm_150.csv')\n",
        "\n",
        "\n",
        "bi_lstm_2_nets=pd.read_csv('/content/drive/My Drive/fnc-1/bi_lstm_2_nets.csv')\n",
        "# w2v embeddings\n",
        "\n",
        "w2v_cnn_50=pd.read_csv('/content/drive/My Drive/fnc-1/w2v_cnn_50.csv')\n",
        "w2v_lstm_50=pd.read_csv('/content/drive/My Drive/fnc-1/w2v_lstm_50.csv')\n",
        "w2v_bi_lstm_50=pd.read_csv('/content/drive/My Drive/fnc-1/w2v_bi_lstm_50.csv')\n",
        "\n",
        "gradient_boosting=pd.read_csv('/content/drive/My Drive/fnc-1/gradientboost.csv')\n",
        "logistic_regression=pd.read_csv('/content/drive/My Drive/fnc-1/logistic_regression.csv')\n",
        "random_forest=pd.read_csv('/content/drive/My Drive/fnc-1/Random_Forest.csv')\n",
        "xgboost=pd.read_csv('/content/drive/My Drive/fnc-1/XGBoost.csv')\n",
        "\n",
        "bert_base=pd.read_csv('/content/drive/My Drive/fnc-1/bert_base.csv')\n",
        "\n",
        "gb_undersample=pd.read_csv('/content/drive/My Drive/fnc-1/gb_undersampled.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHr1dLtebCH_",
        "colab_type": "text"
      },
      "source": [
        "### Importing Real labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tw8zKoYazUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "real_bodies=pd.read_csv('/content/drive/My Drive/fnc-1/competition_test_bodies.csv')\n",
        "real_stances=pd.read_csv('/content/drive/My Drive/fnc-1/competition_test_stances.csv')\n",
        "\n",
        "# Importing train stances\n",
        "real_train_stances=pd.read_csv('/content/drive/My Drive/fnc-1/train_stances.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19VXQtCfbWsy",
        "colab_type": "text"
      },
      "source": [
        "## Exploratory analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6j0TJ4zcdWiQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "3f94df87-ffd9-4505-d52e-ebebbb37ace0"
      },
      "source": [
        "real_stances.head(3)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Headline</th>\n",
              "      <th>Body ID</th>\n",
              "      <th>Stance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ferguson riots: Pregnant woman loses eye after...</td>\n",
              "      <td>2008</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crazy Conservatives Are Sure a Gitmo Detainee ...</td>\n",
              "      <td>1550</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A Russian Guy Says His Justin Bieber Ringtone ...</td>\n",
              "      <td>2</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Headline  Body ID     Stance\n",
              "0  Ferguson riots: Pregnant woman loses eye after...     2008  unrelated\n",
              "1  Crazy Conservatives Are Sure a Gitmo Detainee ...     1550  unrelated\n",
              "2  A Russian Guy Says His Justin Bieber Ringtone ...        2  unrelated"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGQwvS4DbcGb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "0e004b1e-dab9-43e9-f356-e41b77420eb3"
      },
      "source": [
        "real_stances['Stance'].unique()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['unrelated', 'agree', 'discuss', 'disagree'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvLt0Qrtc2xq",
        "colab_type": "text"
      },
      "source": [
        "### Test data distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4ryGPE7b3J6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "31f4e5b5-6111-4e62-c018-f9e15050c2a5"
      },
      "source": [
        "import collections\n",
        "test_data_dist=collections.Counter(real_stances['Stance'])\n",
        "print(\"Test Data Distribution: \",collections.Counter(real_stances['Stance']))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Data Distribution:  Counter({'unrelated': 18349, 'discuss': 4464, 'agree': 1903, 'disagree': 697})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waMTw75Qc5Zb",
        "colab_type": "text"
      },
      "source": [
        "## Train Data distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkK54cVMdeYh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "ddf8a31b-12e5-4d7b-a3e3-bf3638270dce"
      },
      "source": [
        "real_train_stances.head(3)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Headline</th>\n",
              "      <th>Body ID</th>\n",
              "      <th>Stance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Police find mass graves with at least '15 bodi...</td>\n",
              "      <td>712</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
              "      <td>158</td>\n",
              "      <td>agree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Christian Bale passes on role of Steve Jobs, a...</td>\n",
              "      <td>137</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Headline  Body ID     Stance\n",
              "0  Police find mass graves with at least '15 bodi...      712  unrelated\n",
              "1  Hundreds of Palestinians flee floods in Gaza a...      158      agree\n",
              "2  Christian Bale passes on role of Steve Jobs, a...      137  unrelated"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNOow1WhklaH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "b0cf2b39-9297-4bc1-d308-8d63b95458f7"
      },
      "source": [
        "real_train_stances.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49972, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0o9_7UQ0c2Lg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "545317e2-ab35-4324-de4e-852471fd8c86"
      },
      "source": [
        "train_data_dist=collections.Counter(real_train_stances['Stance'])\n",
        "print(\"Train Data Distribution: \",collections.Counter(real_train_stances['Stance']))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Data Distribution:  Counter({'unrelated': 36545, 'discuss': 8909, 'agree': 3678, 'disagree': 840})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADy2y9SIdsgV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "9ede66a1-cbb3-4144-bd0c-7f806a332cc1"
      },
      "source": [
        "plt.bar(train_data_dist.keys(),train_data_dist.values(),color=[\n",
        "                     'seagreen', 'skyblue','pink','gray'])\n",
        "plt.xlabel(\"Stance\")\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Stance Distribution at Train set')\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TumXMOrcq-on",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7a9Y1wqkeuk",
        "colab_type": "text"
      },
      "source": [
        "- Total stances: 49972\n",
        "  - unrelated: 73.1%\n",
        "  - agree: 7.3%\n",
        "  - disagree:1.6%\n",
        "  - discuss:17.8%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOCzZbzLe8TN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "b4635c47-7091-4772-867b-159e180f6469"
      },
      "source": [
        "plt.bar(test_data_dist.keys(),test_data_dist.values(),color=[\n",
        "                     'seagreen', 'skyblue','pink','gray'])\n",
        "plt.xlabel(\"Stance\")\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Stance Distribution at Test set')\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrkAeoJRdcD5",
        "colab_type": "text"
      },
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDzOSIJ8cUsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Adapted from https://github.com/FakeNewsChallenge/fnc-1/blob/master/scorer.py\n",
        "#Original credit - @bgalbraith\n",
        "\n",
        "LABELS = ['agree', 'disagree', 'discuss', 'unrelated']\n",
        "LABELS_RELATED = ['unrelated','related']\n",
        "RELATED = LABELS[0:3]\n",
        "\n",
        "def score_submission(gold_labels, test_labels):\n",
        "    score = 0.0\n",
        "    cm = [[0, 0, 0, 0],\n",
        "          [0, 0, 0, 0],\n",
        "          [0, 0, 0, 0],\n",
        "          [0, 0, 0, 0]]\n",
        "\n",
        "    for i, (g, t) in enumerate(zip(gold_labels, test_labels)):\n",
        "        g_stance, t_stance = g, t\n",
        "        if g_stance == t_stance:\n",
        "            score += 0.25\n",
        "            if g_stance != 'unrelated':\n",
        "                score += 0.50\n",
        "        if g_stance in RELATED and t_stance in RELATED:\n",
        "            score += 0.25\n",
        "\n",
        "        cm[LABELS.index(g_stance)][LABELS.index(t_stance)] += 1\n",
        "\n",
        "    return score, cm\n",
        "\n",
        "\n",
        "def print_confusion_matrix(cm):\n",
        "    lines = []\n",
        "    header = \"|{:^11}|{:^11}|{:^11}|{:^11}|{:^11}|\".format('', *LABELS)\n",
        "    line_len = len(header)\n",
        "    lines.append(\"-\"*line_len)\n",
        "    lines.append(header)\n",
        "    lines.append(\"-\"*line_len)\n",
        "\n",
        "    hit = 0\n",
        "    total = 0\n",
        "    for i, row in enumerate(cm):\n",
        "        hit += row[i]\n",
        "        total += sum(row)\n",
        "        lines.append(\"|{:^11}|{:^11}|{:^11}|{:^11}|{:^11}|\".format(LABELS[i],\n",
        "                                                                   *row))\n",
        "        lines.append(\"-\"*line_len)\n",
        "    print('\\n'.join(lines))\n",
        "\n",
        "\n",
        "def report_score(actual,predicted):\n",
        "    score,cm = score_submission(actual,predicted)\n",
        "    best_score, _ = score_submission(actual,actual)\n",
        "\n",
        "    print_confusion_matrix(cm)\n",
        "    print(\"Score: \" +str(score) + \" out of \" + str(best_score) + \"\\t(\"+str(score*100/best_score) + \"%)\")\n",
        "    return score*100/best_score\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBjyXyc6jLzq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def calculate_f1_scores(y_true, y_predicted):\n",
        "    \n",
        "    f1_macro = f1_score(y_true, y_predicted, average='macro')\n",
        "    f1_classwise = f1_score(y_true, y_predicted, average=None, labels=[\"agree\", \"disagree\", \"discuss\", \"unrelated\"])\n",
        "\n",
        "    resultstring = \"F1 macro: {:.3f}\".format(f1_macro * 100) + \"% \\n\"\n",
        "    resultstring += \"F1 agree: {:.3f}\".format(f1_classwise[0] * 100) + \"% \\n\"\n",
        "    resultstring += \"F1 disagree: {:.3f}\".format(f1_classwise[1] * 100) + \"% \\n\"\n",
        "    resultstring += \"F1 discuss: {:.3f}\".format(f1_classwise[2] * 100) + \"% \\n\"\n",
        "    resultstring += \"F1 unrelated: {:.3f}\".format(f1_classwise[3] * 100) + \"% \\n\"\n",
        "    return resultstring"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_E5yRDYjQB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def class_repo(labels_test,preds_test):\n",
        "    eval_report = classification_report(labels_test, preds_test)\n",
        "    print('Test report', eval_report)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bC_WE3uYdG5a",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating CNN 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muWIkwvScn2j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "fec85f0f-068d-4ac8-aac6-8559145e69bb"
      },
      "source": [
        "report_score(real_stances['Stance'],cnn_50['Stance'])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    65     |    449    |    397    |    992    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    30     |    132    |    101    |    434    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    153    |    551    |   1505    |   2255    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |    310    |   1323    |   1751    |   14965   |\n",
            "-------------------------------------------------------------\n",
            "Score: 5863.5 out of 11651.25\t(50.32507241712263%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50.32507241712263"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5q0AChljifv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "1b1356be-f070-483a-f03a-867909471f10"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],cnn_50['Stance']))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 32.797% \n",
            "F1 agree: 5.282% \n",
            "F1 disagree: 8.376% \n",
            "F1 discuss: 36.627% \n",
            "F1 unrelated: 80.903% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-ly-CjakUUB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "d0bbf0df-377d-451e-ce5e-99ac42772e21"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],cnn_50['Stance']))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.12      0.03      0.05      1903\n",
            "    disagree       0.05      0.19      0.08       697\n",
            "     discuss       0.40      0.34      0.37      4464\n",
            "   unrelated       0.80      0.82      0.81     18349\n",
            "\n",
            "    accuracy                           0.66     25413\n",
            "   macro avg       0.34      0.34      0.33     25413\n",
            "weighted avg       0.66      0.66      0.65     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2_7Naw9RQ64",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "ec052ef1-1a3e-4bfd-dbd1-c45d44da6ede"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],cnn_50['Stance']))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.6558454334395781\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgR2KQstdZHR",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating CNN 100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bQrr1oJdRBb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "29bff20b-81df-403b-e7b3-9b626172e81c"
      },
      "source": [
        "report_score(real_stances['Stance'],cnn_100['Stance'])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    21     |    330    |    352    |   1200    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    11     |    78     |    108    |    500    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    36     |    402    |   1089    |   2937    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |    117    |    882    |   1333    |   16017   |\n",
            "-------------------------------------------------------------\n",
            "Score: 5502.0 out of 11651.25\t(47.22240102993241%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47.22240102993241"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOZkSuW8jyP3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "0e04e2c2-cc55-4894-cb1e-ab98de3900e5"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],cnn_100['Stance']))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 30.081% \n",
            "F1 agree: 2.011% \n",
            "F1 disagree: 6.530% \n",
            "F1 discuss: 29.649% \n",
            "F1 unrelated: 82.132% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxyQyo1ukdd_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "8c0a60a8-03e1-4ce1-f980-2c7b11f21ca7"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],cnn_100['Stance']))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.11      0.01      0.02      1903\n",
            "    disagree       0.05      0.11      0.07       697\n",
            "     discuss       0.38      0.24      0.30      4464\n",
            "   unrelated       0.78      0.87      0.82     18349\n",
            "\n",
            "    accuracy                           0.68     25413\n",
            "   macro avg       0.33      0.31      0.30     25413\n",
            "weighted avg       0.64      0.68      0.65     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1TU1ZCWSAFR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "2548b881-e6b4-4933-cda3-c1748a2a57ed"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],cnn_100['Stance']))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.6770157006256641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sM9A2UaGdgb_",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating CNN 150"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VglVFQMBdd3p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "1919a3e7-7856-4b38-cec5-46f40d260d80"
      },
      "source": [
        "report_score(real_stances['Stance'],cnn_150['Stance'])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    49     |    259    |    396    |   1199    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    21     |    99     |    106    |    471    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    90     |    288    |   1424    |   2662    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |    250    |    984    |   2386    |   14729   |\n",
            "-------------------------------------------------------------\n",
            "Score: 5544.25 out of 11651.25\t(47.585023066194616%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47.585023066194616"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPNubdtsj1yD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "98bf83e5-8555-4810-ab49-7e95734f8566"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],cnn_150['Stance']))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 30.985% \n",
            "F1 agree: 4.237% \n",
            "F1 disagree: 8.509% \n",
            "F1 discuss: 32.452% \n",
            "F1 unrelated: 78.744% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnHVXH4JlAS8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "2d6a26b9-b2e6-4bec-dfd0-38ca068bade2"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],cnn_150['Stance']))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.12      0.03      0.04      1903\n",
            "    disagree       0.06      0.14      0.09       697\n",
            "     discuss       0.33      0.32      0.32      4464\n",
            "   unrelated       0.77      0.80      0.79     18349\n",
            "\n",
            "    accuracy                           0.64     25413\n",
            "   macro avg       0.32      0.32      0.31     25413\n",
            "weighted avg       0.63      0.64      0.63     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1p67LkygSDX6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "5ff4b003-fd2b-43f0-91e5-7a46e864c57e"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],cnn_150['Stance']))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.6414433557627985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3D5nkdDdluk",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating LSTM 50 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUKOxeBxdjN2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "4abe1e22-e986-49cf-aa5b-cdd5ec5b328a"
      },
      "source": [
        "report_score(real_stances['Stance'],lstm_50['Stance'])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    33     |    336    |    267    |   1267    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    12     |    119    |    82     |    484    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    18     |    337    |   1545    |   2564    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |    82     |    643    |   1385    |   16239   |\n",
            "-------------------------------------------------------------\n",
            "Score: 6019.75 out of 11651.25\t(51.6661302435361%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51.6661302435361"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbhKTfEij3pz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "80f88001-e6d2-488f-87fb-90c53ac07941"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],lstm_50['Stance']))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 34.444% \n",
            "F1 agree: 3.223% \n",
            "F1 disagree: 11.163% \n",
            "F1 discuss: 39.907% \n",
            "F1 unrelated: 83.485% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onBBj6tulEcy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "0101932b-da23-4d44-f288-f7f59f92b4b6"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],lstm_50['Stance']))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.23      0.02      0.03      1903\n",
            "    disagree       0.08      0.17      0.11       697\n",
            "     discuss       0.47      0.35      0.40      4464\n",
            "   unrelated       0.79      0.89      0.83     18349\n",
            "\n",
            "    accuracy                           0.71     25413\n",
            "   macro avg       0.39      0.35      0.34     25413\n",
            "weighted avg       0.67      0.71      0.68     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3SdJHdRSH-x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "c67b3695-f11a-4507-b1ae-755df19e2e96"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],lstm_50['Stance']))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.7057805060402156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGjC-rmrdqFV",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating LSTM 100 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8mGrn2gdq9Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "b5969464-f7ca-48da-be64-17763e13cb37"
      },
      "source": [
        "report_score(real_stances['Stance'],lstm_100['Stance'])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |     0     |    281    |    348    |   1274    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |     0     |    90     |    94     |    513    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |     0     |    446    |   1375    |   2643    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |     0     |   1129    |   1665    |   15555   |\n",
            "-------------------------------------------------------------\n",
            "Score: 5646.0 out of 11651.25\t(48.45831992275507%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48.45831992275507"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SxDsUdqj8z7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "ea8fd999-8038-4dbe-de19-c4c686d773de"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],lstm_100['Stance']))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 30.644% \n",
            "F1 agree: 0.000% \n",
            "F1 disagree: 6.810% \n",
            "F1 discuss: 34.609% \n",
            "F1 unrelated: 81.155% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htGFjCSZlImW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "3f640f70-8a81-442d-dbad-898eb50f1204"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],lstm_100['Stance']))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.00      0.00      0.00      1903\n",
            "    disagree       0.05      0.13      0.07       697\n",
            "     discuss       0.39      0.31      0.35      4464\n",
            "   unrelated       0.78      0.85      0.81     18349\n",
            "\n",
            "    accuracy                           0.67     25413\n",
            "   macro avg       0.30      0.32      0.31     25413\n",
            "weighted avg       0.63      0.67      0.65     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpF-VtVkSLcx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "d5485281-b160-481d-aee4-41c4344515be"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],lstm_100['Stance']))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.669735961909259\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdVYy35ndrnp",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating LSTM 150"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TOuJ-Hvdsc3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "48fddf00-729c-4430-a1cf-7f933961a02f"
      },
      "source": [
        "report_score(real_stances['Stance'],lstm_150['Stance'])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |     1     |    455    |    432    |   1015    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |     3     |    174    |    158    |    362    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |     4     |    486    |   1538    |   2436    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |    17     |   1379    |   1795    |   15158   |\n",
            "-------------------------------------------------------------\n",
            "Score: 5887.0 out of 11651.25\t(50.526767514215216%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50.526767514215216"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pPSfXizj_K9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "ee19ea20-a9c5-4a01-ffcb-434453299ab4"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],lstm_150['Stance']))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 32.229% \n",
            "F1 agree: 0.104% \n",
            "F1 disagree: 10.906% \n",
            "F1 discuss: 36.676% \n",
            "F1 unrelated: 81.233% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyA5uOzJlLSu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "1d9f98f8-af61-4b63-a7d5-ed8e50af9f5a"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],lstm_150['Stance']))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.04      0.00      0.00      1903\n",
            "    disagree       0.07      0.25      0.11       697\n",
            "     discuss       0.39      0.34      0.37      4464\n",
            "   unrelated       0.80      0.83      0.81     18349\n",
            "\n",
            "    accuracy                           0.66     25413\n",
            "   macro avg       0.33      0.36      0.32     25413\n",
            "weighted avg       0.65      0.66      0.65     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rciJ1WiaSTPg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "c1b9ddb6-21f6-4ad9-df96-898ae29be38d"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],lstm_150['Stance']))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.6638728209971274\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy-hfod-eIUc",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating Bi-LSTM 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kxJmONEd1dR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "33f649df-7d3c-4fd8-ecd4-add3de7e3e85"
      },
      "source": [
        "report_score(real_stances['Stance'],bi_lstm_50['Stance'])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    39     |    318    |    309    |   1237    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    14     |    118    |    86     |    479    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    31     |    341    |   1701    |   2391    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |    43     |    639    |   1327    |   16340   |\n",
            "-------------------------------------------------------------\n",
            "Score: 6217.75 out of 11651.25\t(53.365518721167255%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53.365518721167255"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I341ozqbkEou",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "309b23a4-daa4-4bd4-a774-d7ed8f001904"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],bi_lstm_50['Stance']))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 35.595% \n",
            "F1 agree: 3.842% \n",
            "F1 disagree: 11.169% \n",
            "F1 discuss: 43.134% \n",
            "F1 unrelated: 84.235% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vbgbs1hPlNnU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "410b78e9-78ae-4609-b427-5b82abf7f6da"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],bi_lstm_50['Stance']))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.31      0.02      0.04      1903\n",
            "    disagree       0.08      0.17      0.11       697\n",
            "     discuss       0.50      0.38      0.43      4464\n",
            "   unrelated       0.80      0.89      0.84     18349\n",
            "\n",
            "    accuracy                           0.72     25413\n",
            "   macro avg       0.42      0.37      0.36     25413\n",
            "weighted avg       0.69      0.72      0.69     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AILzV05LYLKx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "f7901686-b167-41ec-b51c-b906a123bb07"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],bi_lstm_50['Stance']))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.7160901900602054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHFzq7yaeRTQ",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating Bi-LSTM 100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCoXy-93d7Pe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "7ce2c741-af90-4c0a-9200-c2f34664f82f"
      },
      "source": [
        "report_score(real_stances['Stance'],bi_lstm_100['Stance'])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    41     |    333    |    450    |   1079    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    10     |    85     |    99     |    503    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    37     |    362    |   2043    |   2022    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |    82     |    599    |   1278    |   16390   |\n",
            "-------------------------------------------------------------\n",
            "Score: 6589.25 out of 11651.25\t(56.55401780924794%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56.55401780924794"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "au_0r1o8kIOG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "866ca246-0db0-4e1d-8576-27c995e781c8"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],bi_lstm_100['Stance']))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 36.666% \n",
            "F1 agree: 3.956% \n",
            "F1 disagree: 8.189% \n",
            "F1 discuss: 49.028% \n",
            "F1 unrelated: 85.491% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUxeGHCWlQhp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "79044395-f0d6-40f8-8a78-082507dd25cf"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],bi_lstm_100['Stance']))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.24      0.02      0.04      1903\n",
            "    disagree       0.06      0.12      0.08       697\n",
            "     discuss       0.53      0.46      0.49      4464\n",
            "   unrelated       0.82      0.89      0.85     18349\n",
            "\n",
            "    accuracy                           0.73     25413\n",
            "   macro avg       0.41      0.37      0.37     25413\n",
            "weighted avg       0.70      0.73      0.71     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP1EXAS3YS3d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "0ce2fa32-7f0b-43c9-d190-0c44faa276d2"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],bi_lstm_100['Stance']))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.730295518041947\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nJu16-ceUQl",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating Bi-LSTM 150"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-F7tDcrd80q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "136cbe85-ff83-4e40-9353-a59d6baa6675"
      },
      "source": [
        "report_score(real_stances['Stance'],bi_lstm_150['Stance'])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    34     |    207    |    305    |   1357    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    24     |    54     |    103    |    516    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    51     |    209    |   1614    |   2590    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |    75     |    387    |   1136    |   16751   |\n",
            "-------------------------------------------------------------\n",
            "Score: 6114.5 out of 11651.25\t(52.47934770947323%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52.47934770947323"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AmrRSw9kLsx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "3f2dfe0e-7f0b-4185-9b2d-97a03d79d869"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],bi_lstm_150['Stance']))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 34.310% \n",
            "F1 agree: 3.258% \n",
            "F1 disagree: 6.950% \n",
            "F1 discuss: 42.351% \n",
            "F1 unrelated: 84.680% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiYvAKDIlTR5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "c0771eb3-3413-43ed-dc02-cfbaa564b1e8"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],bi_lstm_150['Stance']))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.18      0.02      0.03      1903\n",
            "    disagree       0.06      0.08      0.07       697\n",
            "     discuss       0.51      0.36      0.42      4464\n",
            "   unrelated       0.79      0.91      0.85     18349\n",
            "\n",
            "    accuracy                           0.73     25413\n",
            "   macro avg       0.39      0.34      0.34     25413\n",
            "weighted avg       0.68      0.73      0.69     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1l1BivXYWlt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "57cd4b49-3ddd-4f80-81be-efef784d372f"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],bi_lstm_150['Stance']))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.726124424507142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zVLRbhP6_Ew",
        "colab_type": "text"
      },
      "source": [
        "## W2V CNN 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cvNh54E7Co5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "33534262-ee70-41f6-ac0a-810cdbb60ce1"
      },
      "source": [
        "report_score(real_stances['Stance'],w2v_cnn_50['Stance'])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    33     |    352    |    532    |    986    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    13     |    90     |    187    |    407    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    51     |    393    |   1938    |   2082    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |    182    |   1215    |   2728    |   14224   |\n",
            "-------------------------------------------------------------\n",
            "Score: 5999.0 out of 11651.25\t(51.48803776418839%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51.48803776418839"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqwqhodJ7Csg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "dc37c932-3390-4df5-84d8-d193c4f72390"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],w2v_cnn_50['Stance']))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 31.962% \n",
            "F1 agree: 3.025% \n",
            "F1 disagree: 6.553% \n",
            "F1 discuss: 39.354% \n",
            "F1 unrelated: 78.917% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jbk7LkGD7C6B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "23da6be4-0d9c-4b08-c0ce-4df1858869af"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],w2v_cnn_50['Stance']))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.12      0.02      0.03      1903\n",
            "    disagree       0.04      0.13      0.07       697\n",
            "     discuss       0.36      0.43      0.39      4464\n",
            "   unrelated       0.80      0.78      0.79     18349\n",
            "\n",
            "    accuracy                           0.64     25413\n",
            "   macro avg       0.33      0.34      0.32     25413\n",
            "weighted avg       0.65      0.64      0.64     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTzjx10BYZYr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "12df6bd7-7e40-4a62-c038-862214e161f1"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],w2v_cnn_50['Stance']))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.640813756738677\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5m6llvT7DLP",
        "colab_type": "text"
      },
      "source": [
        "## W2V LSTM 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKQz3r6y7GKu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "86ef02f4-acb3-4834-d584-ee3aee3a6645"
      },
      "source": [
        "report_score(real_stances['Stance'],w2v_lstm_50['Stance'])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |     8     |    213    |    281    |   1401    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |     3     |    40     |    86     |    568    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    20     |    226    |   1363    |   2855    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |    35     |    503    |   1348    |   16463   |\n",
            "-------------------------------------------------------------\n",
            "Score: 5734.0 out of 11651.25\t(49.213603690591135%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49.213603690591135"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APq8Tcud7GPi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "745d4f23-ef05-42c7-86e4-95b53cdaf311"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],w2v_lstm_50['Stance']))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 31.198% \n",
            "F1 agree: 0.813% \n",
            "F1 disagree: 4.765% \n",
            "F1 discuss: 36.144% \n",
            "F1 unrelated: 83.071% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkTmyow67GW4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "637cfd84-d3f4-440f-d24b-9c80f81fde2a"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],w2v_lstm_50['Stance']))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.12      0.00      0.01      1903\n",
            "    disagree       0.04      0.06      0.05       697\n",
            "     discuss       0.44      0.31      0.36      4464\n",
            "   unrelated       0.77      0.90      0.83     18349\n",
            "\n",
            "    accuracy                           0.70     25413\n",
            "   macro avg       0.34      0.32      0.31     25413\n",
            "weighted avg       0.65      0.70      0.67     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OV6YIC0YetJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "92a9fc4f-89d6-4549-87c4-872bd90f9cbd"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],w2v_lstm_50['Stance']))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.7033408098217447\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbQVR6ZE7GjD",
        "colab_type": "text"
      },
      "source": [
        "## W2V Bi-LSTM 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkHBwvJ27HAO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "a18a33e1-2822-4e2c-9af3-a7a643118fe8"
      },
      "source": [
        "report_score(real_stances['Stance'],w2v_bi_lstm_50['Stance'])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    10     |    430    |    343    |   1120    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |     9     |    112    |    101    |    475    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    18     |    602    |   1552    |   2292    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |    39     |   1152    |   1453    |   15705   |\n",
            "-------------------------------------------------------------\n",
            "Score: 5976.0 out of 11651.25\t(51.29063405214033%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51.29063405214033"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUDzf29m7HJ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "6c0474a3-85e9-431a-e779-a4d023920ed8"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],w2v_bi_lstm_50['Stance']))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 32.627% \n",
            "F1 agree: 1.011% \n",
            "F1 disagree: 7.484% \n",
            "F1 discuss: 39.227% \n",
            "F1 unrelated: 82.786% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DF0p8x_M7HXI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "d0881fb1-106c-4e7f-e706-66a168cd625c"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],w2v_bi_lstm_50['Stance']))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.13      0.01      0.01      1903\n",
            "    disagree       0.05      0.16      0.07       697\n",
            "     discuss       0.45      0.35      0.39      4464\n",
            "   unrelated       0.80      0.86      0.83     18349\n",
            "\n",
            "    accuracy                           0.68     25413\n",
            "   macro avg       0.36      0.34      0.33     25413\n",
            "weighted avg       0.67      0.68      0.67     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_jo1b_VYiT5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "460e92b0-cf6b-492e-bc0a-2f9f14acd77e"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],w2v_bi_lstm_50['Stance']))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.6838625900129854\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4tl-nG4yVEJ",
        "colab_type": "text"
      },
      "source": [
        "## Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrosTQZnyVj6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "4120d511-97d3-461a-8207-7a79e9b6b9c3"
      },
      "source": [
        "report_score(real_stances['Stance'],gradient_boosting['Stance'])"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    163    |     1     |   1542    |    197    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    43     |     1     |    478    |    175    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    173    |     4     |   3830    |    457    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |     8     |     1     |    306    |   18034   |\n",
            "-------------------------------------------------------------\n",
            "Score: 9062.75 out of 11651.25\t(77.7834996245038%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "77.7834996245038"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJqs99mgz94j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "cfa6426a-9af1-4c25-e07e-5801d89ddfcf"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],gradient_boosting['Stance']))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 45.893% \n",
            "F1 agree: 14.236% \n",
            "F1 disagree: 0.284% \n",
            "F1 discuss: 72.128% \n",
            "F1 unrelated: 96.926% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmEDtUT3z98d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "65f56c2c-15f0-4cce-e99f-3eb884a9e582"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],gradient_boosting['Stance']))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.42      0.09      0.14      1903\n",
            "    disagree       0.14      0.00      0.00       697\n",
            "     discuss       0.62      0.86      0.72      4464\n",
            "   unrelated       0.96      0.98      0.97     18349\n",
            "\n",
            "    accuracy                           0.87     25413\n",
            "   macro avg       0.54      0.48      0.46     25413\n",
            "weighted avg       0.84      0.87      0.84     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q54okKXDYnEf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "a9754c1f-f38c-47a6-eb66-c925f83f2f4c"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],gradient_boosting['Stance']))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.8668004564592925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-xDoYXR0WR5",
        "colab_type": "text"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tauif9mfz92Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "71327944-6444-4255-c3c6-96cccc9dc9b3"
      },
      "source": [
        "report_score(real_stances['Stance'],random_forest['Stance'])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    96     |     0     |   1599    |    208    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    19     |     0     |    490    |    188    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    104    |     0     |   3868    |    492    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |     2     |     0     |    273    |   18074   |\n",
            "-------------------------------------------------------------\n",
            "Score: 9035.5 out of 11651.25\t(77.5496191395773%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "77.5496191395773"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBHsUPwd0ZNT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "4fd3bc5a-252a-4cdd-e1ba-c797a2d9a1d2"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],random_forest['Stance']))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 44.566% \n",
            "F1 agree: 9.040% \n",
            "F1 disagree: 0.000% \n",
            "F1 discuss: 72.340% \n",
            "F1 unrelated: 96.883% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7yPoXtN0rBT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "b3510d7d-e747-4a2f-bc3a-83890c3c9b43"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],random_forest['Stance']))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.43      0.05      0.09      1903\n",
            "    disagree       0.00      0.00      0.00       697\n",
            "     discuss       0.62      0.87      0.72      4464\n",
            "   unrelated       0.95      0.99      0.97     18349\n",
            "\n",
            "    accuracy                           0.87     25413\n",
            "   macro avg       0.50      0.48      0.45     25413\n",
            "weighted avg       0.83      0.87      0.83     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nht3r4mHYrPw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "09749e2f-7a44-41a8-cdf1-4eea396813b9"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],random_forest['Stance']))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.8671939558493684\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8dJsexJ07fq",
        "colab_type": "text"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgfEKRLm02AL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "09256d69-e247-4b52-9ae1-f5507ed0045e"
      },
      "source": [
        "report_score(real_stances['Stance'],logistic_regression['Stance'])"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    111    |     0     |   1579    |    213    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    17     |     0     |    485    |    195    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    129    |     0     |   3820    |    515    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |     3     |     0     |    254    |   18092   |\n",
            "-------------------------------------------------------------\n",
            "Score: 9006.5 out of 11651.25\t(77.30071880699495%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "77.30071880699495"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H6lkVpk1MFj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "e16755b7-0c27-4878-a5a0-8a1eefac3ae6"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],logistic_regression['Stance']))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 44.792% \n",
            "F1 agree: 10.264% \n",
            "F1 disagree: 0.000% \n",
            "F1 discuss: 72.062% \n",
            "F1 unrelated: 96.842% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vzotgbs1P6F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "e9abeb68-aa2d-49c9-d329-e5de595dcdbe"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],logistic_regression['Stance']))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.43      0.06      0.10      1903\n",
            "    disagree       0.00      0.00      0.00       697\n",
            "     discuss       0.62      0.86      0.72      4464\n",
            "   unrelated       0.95      0.99      0.97     18349\n",
            "\n",
            "    accuracy                           0.87     25413\n",
            "   macro avg       0.50      0.48      0.45     25413\n",
            "weighted avg       0.83      0.87      0.83     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klFu7-5sYuvT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "a15412c5-709e-45e9-83f6-8983469a4b6d"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],logistic_regression['Stance']))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.8666037067642545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPJNP7pp1fCG",
        "colab_type": "text"
      },
      "source": [
        "## XGBOOST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewgBjciD1RUv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "b7c28c94-2e34-488f-a957-1897a39610cf"
      },
      "source": [
        "report_score(real_stances['Stance'],xgboost['Stance'])"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    111    |     1     |   1597    |    194    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    38     |     0     |    478    |    181    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    129    |     0     |   3880    |    455    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |     3     |     0     |    299    |   18047   |\n",
            "-------------------------------------------------------------\n",
            "Score: 9063.5 out of 11651.25\t(77.78993670207059%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "77.78993670207059"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl5MA65z1jmg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "2704895f-a7c1-400d-962d-9f89a85a0657"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],xgboost['Stance']))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 44.881% \n",
            "F1 agree: 10.165% \n",
            "F1 disagree: 0.000% \n",
            "F1 discuss: 72.402% \n",
            "F1 unrelated: 96.959% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ9QAiJH1qG8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "a353c426-493d-4b41-bc04-b5b216267687"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],xgboost['Stance']))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.40      0.06      0.10      1903\n",
            "    disagree       0.00      0.00      0.00       697\n",
            "     discuss       0.62      0.87      0.72      4464\n",
            "   unrelated       0.96      0.98      0.97     18349\n",
            "\n",
            "    accuracy                           0.87     25413\n",
            "   macro avg       0.49      0.48      0.45     25413\n",
            "weighted avg       0.83      0.87      0.83     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHgCmaHYYx5a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "99051766-7660-4f31-b3a4-5554bc19e2a7"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],xgboost['Stance']))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.8671939558493684\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbigWieRwul2",
        "colab_type": "text"
      },
      "source": [
        "## Bert classifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT-OZ69cwxPP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "111da041-3c84-4aa5-87f6-e804faa8c952"
      },
      "source": [
        "report_score(real_stances['Stance'],bert_base['Stance'])"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    750    |    24     |    400    |    729    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    202    |    42     |    113    |    340    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    351    |    39     |   2509    |   1565    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |    343    |    14     |    921    |   17071   |\n",
            "-------------------------------------------------------------\n",
            "Score: 7851.0 out of 11651.25\t(67.38332796910203%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67.38332796910203"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygMCxRC4w84d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "e23ac698-a9a8-499e-e31b-a8d4195e8b28"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],bert_base['Stance']))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 50.492% \n",
            "F1 agree: 42.265% \n",
            "F1 disagree: 10.294% \n",
            "F1 discuss: 59.688% \n",
            "F1 unrelated: 89.720% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_N9iV_Mw88l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "af7f3829-ef36-491b-da71-58a27359c74a"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],bert_base['Stance']))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.46      0.39      0.42      1903\n",
            "    disagree       0.35      0.06      0.10       697\n",
            "     discuss       0.64      0.56      0.60      4464\n",
            "   unrelated       0.87      0.93      0.90     18349\n",
            "\n",
            "    accuracy                           0.80     25413\n",
            "   macro avg       0.58      0.49      0.50     25413\n",
            "weighted avg       0.78      0.80      0.79     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QltCU1T0w9cy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "f304b6e5-6629-4269-e789-b41daddbc1bc"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],bert_base['Stance']))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.8016369574627159\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeSkgRTPxKdt",
        "colab_type": "text"
      },
      "source": [
        "## Resampled Data for training Gradient Boosting | 50% unrelated taken. Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kMg1oyBxSWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "390fc0c4-85a7-42ec-b7e1-ac633fd7ee41"
      },
      "source": [
        "report_score(real_stances['Stance'],gb_undersample['Stance'])"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    269    |     9     |   1533    |    92     |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    93     |     6     |    521    |    77     |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    328    |    11     |   3952    |    173    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |    68     |     8     |    948    |   17325   |\n",
            "-------------------------------------------------------------\n",
            "Score: 9182.0 out of 11651.25\t(78.80699495762258%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78.80699495762258"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ausFomFNxSei",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "99bf8169-c1ab-4c74-c0e5-269bdfc2045e"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],gb_undersample['Stance']))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 46.823% \n",
            "F1 agree: 20.218% \n",
            "F1 disagree: 1.642% \n",
            "F1 discuss: 69.224% \n",
            "F1 unrelated: 96.207% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOZeC1dexSlk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "205a69e7-5d9f-4d23-a22a-583ed7a40876"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],gb_undersample['Stance']))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.35      0.14      0.20      1903\n",
            "    disagree       0.18      0.01      0.02       697\n",
            "     discuss       0.57      0.89      0.69      4464\n",
            "   unrelated       0.98      0.94      0.96     18349\n",
            "\n",
            "    accuracy                           0.85     25413\n",
            "   macro avg       0.52      0.49      0.47     25413\n",
            "weighted avg       0.84      0.85      0.83     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iZTmddyxSuM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "64626562-dcad-4435-e31a-46ff4d207370"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],gb_undersample['Stance']))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.8480698854916775\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9G7n5BJKcASC",
        "colab_type": "text"
      },
      "source": [
        "## Bidirectional 2 Nets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woeHGGykcDUW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "2c01db40-c80d-444d-8990-7568153a3c54"
      },
      "source": [
        "report_score(real_stances['Stance'],bi_lstm_2_nets['Stance'])"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    883    |    43     |    828    |    149    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    183    |    78     |    291    |    145    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    512    |    62     |   3543    |    347    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |    84     |    47     |    314    |   17904   |\n",
            "-------------------------------------------------------------\n",
            "Score: 9459.75 out of 11651.25\t(81.19085934985516%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81.19085934985516"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0gv7oB3cDZE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "6ee47fa0-2b03-425a-e0f8-9f2fa726a354"
      },
      "source": [
        "print(calculate_f1_scores(real_stances['Stance'],bi_lstm_2_nets['Stance']))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 macro: 59.621% \n",
            "F1 agree: 49.537% \n",
            "F1 disagree: 16.828% \n",
            "F1 discuss: 75.064% \n",
            "F1 unrelated: 97.056% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu4kjaG8cDSC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "0296b38a-1ded-4421-94d9-eff6342c67b7"
      },
      "source": [
        "print(class_repo(real_stances['Stance'],bi_lstm_2_nets['Stance']))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test report               precision    recall  f1-score   support\n",
            "\n",
            "       agree       0.53      0.46      0.50      1903\n",
            "    disagree       0.34      0.11      0.17       697\n",
            "     discuss       0.71      0.79      0.75      4464\n",
            "   unrelated       0.97      0.98      0.97     18349\n",
            "\n",
            "    accuracy                           0.88     25413\n",
            "   macro avg       0.64      0.59      0.60     25413\n",
            "weighted avg       0.87      0.88      0.87     25413\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz2z0zdXcJXS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "30f7ef78-d70a-4476-f855-5f463a0fcf9d"
      },
      "source": [
        "print(\" Accuracy is: \",accuracy_score(real_stances['Stance'],bi_lstm_2_nets['Stance']))"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy is:  0.8817534332821784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFIut_mT1wVg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "be5a2f47-b2eb-41fe-ef62-8275fd3a5610"
      },
      "source": [
        "# Horizontal Bar plot\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "models=['CNN 50 Truncs','CNN 100 Truncs','CNN 150 Truncs',\n",
        "        'LSTM 50 Truncs','LSTM 100 Truncs','LSTM 150 Truncs',\n",
        "        'BI-LSTM 50 Truncs','BI-LSTM 100 Truncs','BI-LSTM 150 Truncs',\n",
        "        'W2V CNN 50','W2V LSTM 50','W2V BI-LSTM 50',\n",
        "        'Bert Classifier',\n",
        "        'LOGISTIC REGRESSION','RANDOM FOREST 50','GRADIENT BOOSTING','XG BOOST','GRADIENT BOOSTING | undersampled data','Bi-LSTM 2 Nets']\n",
        "\n",
        "accuracies=np.asarray([50.3,47.2,47.5,51.6,48.5,50.5,53.3,56.5,52.4,51.4,49.2,51.2,67.4,77.3,77.5,77.8,77.8,79.0,81.2])\n",
        "plt.figure(figsize=(8,7))\n",
        "plt.barh(models,accuracies,color=['firebrick', 'black',\n",
        "                    'purple', 'seagreen', 'skyblue','pink','gray','teal'])\n",
        "plt.xlabel(\"Relative Accuracy\")\n",
        "plt.ylabel('Model')\n",
        "plt.title('Relative Accuracies at Test Set')\n",
        "plt.show()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}